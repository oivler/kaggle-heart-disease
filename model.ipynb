{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicting Heart Disease\n",
        "\n",
        "## Score: .95371"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict, KFold\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import catboost as cb\n",
        "from catboost import CatBoostClassifier\n",
        "#%pip install torch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "DATA_DIR = Path(\"playground-series-s6e2\")\n",
        "OUTPUT_DIR = Path(\".\")\n",
        "n_splits = 5\n",
        "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (630000, 15)\n",
            "Test: (270000, 14)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Chest pain type</th>\n",
              "      <th>BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FBS over 120</th>\n",
              "      <th>EKG results</th>\n",
              "      <th>Max HR</th>\n",
              "      <th>Exercise angina</th>\n",
              "      <th>ST depression</th>\n",
              "      <th>Slope of ST</th>\n",
              "      <th>Number of vessels fluro</th>\n",
              "      <th>Thallium</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>152</td>\n",
              "      <td>239</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>325</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>160</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>134</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>140</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  Age  Sex  Chest pain type   BP  Cholesterol  FBS over 120  EKG results  \\\n",
              "0   0   58    1                4  152          239             0            0   \n",
              "1   1   52    1                1  125          325             0            2   \n",
              "2   2   56    0                2  160          188             0            2   \n",
              "3   3   44    0                3  134          229             0            2   \n",
              "4   4   58    1                4  140          234             0            2   \n",
              "\n",
              "   Max HR  Exercise angina  ST depression  Slope of ST  \\\n",
              "0     158                1            3.6            2   \n",
              "1     171                0            0.0            1   \n",
              "2     151                0            0.0            1   \n",
              "3     150                0            1.0            2   \n",
              "4     125                1            3.8            2   \n",
              "\n",
              "   Number of vessels fluro  Thallium Heart Disease  \n",
              "0                        2         7      Presence  \n",
              "1                        0         3       Absence  \n",
              "2                        0         3       Absence  \n",
              "3                        0         3       Absence  \n",
              "4                        3         3      Presence  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR / \"test.csv\")\n",
        "print(f\"Train: {train.shape}\")\n",
        "print(f\"Test: {test.shape}\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features: 32 columns\n",
            "Target distribution: {0: 347546, 1: 282454}\n"
          ]
        }
      ],
      "source": [
        "target_col = \"Heart Disease\"\n",
        "id_col = \"id\"\n",
        "feature_cols = [c for c in train.columns if c not in (id_col, target_col)]\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(train[target_col])\n",
        "\n",
        "X_train = train[feature_cols].copy()\n",
        "X_test = test[feature_cols].copy()\n",
        "\n",
        "for col in feature_cols:\n",
        "    if X_train[col].isna().any() or X_test[col].isna().any():\n",
        "        med = X_train[col].median()\n",
        "        X_train[col] = X_train[col].fillna(med)\n",
        "        X_test[col] = X_test[col].fillna(med)\n",
        "\n",
        "X_train[\"chol_exercise\"] = X_train[\"Cholesterol\"] * X_train[\"Exercise angina\"]\n",
        "X_test[\"chol_exercise\"] = X_test[\"Cholesterol\"] * X_test[\"Exercise angina\"]\n",
        "X_train[\"st_slope\"] = X_train[\"ST depression\"] * X_train[\"Slope of ST\"]\n",
        "X_test[\"st_slope\"] = X_test[\"ST depression\"] * X_test[\"Slope of ST\"]\n",
        "X_train[\"hr_age\"] = X_train[\"Max HR\"] * X_train[\"Age\"]\n",
        "X_test[\"hr_age\"] = X_test[\"Max HR\"] * X_test[\"Age\"]\n",
        "X_train[\"bp_age\"] = X_train[\"BP\"] * X_train[\"Age\"]\n",
        "X_test[\"bp_age\"] = X_test[\"BP\"] * X_test[\"Age\"]\n",
        "\n",
        "te_cols = [\"Chest pain type\", \"Slope of ST\", \"Thallium\"]\n",
        "global_mean = float(y.mean())\n",
        "m = 20\n",
        "for col in te_cols:\n",
        "    agg = pd.DataFrame({\"_y\": y}).groupby(X_train[col])[\"_y\"].agg([\"mean\", \"count\"])\n",
        "    smoothed = (agg[\"count\"] * agg[\"mean\"] + m * global_mean) / (agg[\"count\"] + m)\n",
        "    X_train[col + \"_te\"] = X_train[col].map(smoothed).fillna(global_mean)\n",
        "    X_test[col + \"_te\"] = X_test[col].map(smoothed).fillna(global_mean)\n",
        "\n",
        "scaler_feat = StandardScaler()\n",
        "X_tr_s = scaler_feat.fit_transform(X_train)\n",
        "X_te_s = scaler_feat.transform(X_test)\n",
        "kmeans = KMeans(n_clusters=12, random_state=42, n_init=10)\n",
        "kmeans.fit(X_tr_s)\n",
        "for i in range(kmeans.n_clusters):\n",
        "    d_tr = np.linalg.norm(X_tr_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    d_te = np.linalg.norm(X_te_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    X_train[f\"dist_c{i}\"] = d_tr\n",
        "    X_test[f\"dist_c{i}\"] = d_te\n",
        "\n",
        "print(f\"Features: {len(X_train.columns)} columns\")\n",
        "print(f\"Target distribution: {pd.Series(y).value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best OOF AUC: 0.95507, params: {'depth': 6, 'lr': 0.05, 'min_data_in_leaf': 15}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\"depth\": [4, 5, 6], \"lr\": [0.03, 0.04, 0.05], \"min_data_in_leaf\": [15, 25, 35]}\n",
        "n_est = 800\n",
        "best_auc, best_params = 0, None\n",
        "for depth in param_grid[\"depth\"]:\n",
        "    for lr in param_grid[\"lr\"]:\n",
        "        for min_leaf in param_grid[\"min_data_in_leaf\"]:\n",
        "            m = cb.CatBoostClassifier(iterations=n_est, depth=depth, learning_rate=lr, min_data_in_leaf=min_leaf, subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "            oof = cross_val_predict(m, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "            auc = roc_auc_score(y, oof)\n",
        "            if auc > best_auc:\n",
        "                best_auc, best_params = auc, {\"depth\": depth, \"lr\": lr, \"min_data_in_leaf\": min_leaf}\n",
        "print(f\"Best OOF AUC: {best_auc:.5f}, params: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV AUC: 0.95517 (blend w_xgb=0.4)\n"
          ]
        }
      ],
      "source": [
        "model = cb.CatBoostClassifier(iterations=n_est, depth=best_params[\"depth\"], learning_rate=best_params[\"lr\"], min_data_in_leaf=best_params[\"min_data_in_leaf\"], subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "oof_cb = cross_val_predict(model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=n_est, max_depth=5, learning_rate=0.05, min_child_weight=20, subsample=0.75, colsample_bytree=0.75, random_state=42, eval_metric=\"auc\")\n",
        "oof_xgb = cross_val_predict(xgb_model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "best_w, best_auc = 0.0, roc_auc_score(y, oof_cb)\n",
        "for w in [0, 0.1, 0.2, 0.3, 0.4]:\n",
        "    oof_blend = (1 - w) * oof_cb + w * oof_xgb\n",
        "    auc = roc_auc_score(y, oof_blend)\n",
        "    if auc > best_auc:\n",
        "        best_auc, best_w = auc, w\n",
        "oof = (1 - best_w) * oof_cb + best_w * oof_xgb\n",
        "print(f\"CV AUC: {best_auc:.5f} (blend w_xgb={best_w})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train, y)\n",
        "xgb_model.fit(X_train, y)\n",
        "test_cb = model.predict_proba(X_test)[:, 1]\n",
        "test_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
        "test_proba = (1 - best_w) * test_cb + best_w * test_xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher model using 13 shared columns from original dataset\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 180000, number of negative: 420000\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009721 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 668\n",
            "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300000 -> initscore=-0.847298\n",
            "[LightGBM] [Info] Start training from score -0.847298\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 180000, number of negative: 420000\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009116 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 672\n",
            "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300000 -> initscore=-0.847298\n",
            "[LightGBM] [Info] Start training from score -0.847298\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 180000, number of negative: 420000\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010740 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 671\n",
            "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300000 -> initscore=-0.847298\n",
            "[LightGBM] [Info] Start training from score -0.847298\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Adversarial AUC (train vs test): 0.50147\n",
            "Sample weights (train-like vs test-like) -> min=0.350, max=2.793, mean=1.000\n",
            "FOLD 1/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90499\n",
            "[1999]\tvalidation_0-auc:0.95529\n",
            "FOLD 2/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90580\n",
            "[1993]\tvalidation_0-auc:0.95553\n",
            "FOLD 3/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90708\n",
            "[1999]\tvalidation_0-auc:0.95614\n",
            "FOLD 4/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90562\n",
            "[1999]\tvalidation_0-auc:0.95501\n",
            "FOLD 5/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90558\n",
            "[1995]\tvalidation_0-auc:0.95526\n",
            "FOLD 1/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6722531\ttest: 0.6722912\tbest: 0.6722912 (0)\ttotal: 111ms\tremaining: 3m 42s\n",
            "1999:\tlearn: 0.2672328\ttest: 0.2679992\tbest: 0.2679989 (1998)\ttotal: 3m 24s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2679989206\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 2/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6721028\ttest: 0.6720728\tbest: 0.6720728 (0)\ttotal: 127ms\tremaining: 4m 14s\n",
            "1999:\tlearn: 0.2674485\ttest: 0.2670857\tbest: 0.2670855 (1998)\ttotal: 3m 23s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2670855316\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 3/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6721301\ttest: 0.6720268\tbest: 0.6720268 (0)\ttotal: 109ms\tremaining: 3m 38s\n",
            "1999:\tlearn: 0.2679563\ttest: 0.2652816\tbest: 0.2652816 (1999)\ttotal: 3m 22s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2652815866\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 4/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6722785\ttest: 0.6722816\tbest: 0.6722816 (0)\ttotal: 114ms\tremaining: 3m 48s\n",
            "1999:\tlearn: 0.2671157\ttest: 0.2686748\tbest: 0.2686748 (1999)\ttotal: 3m 27s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2686748328\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 5/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6723373\ttest: 0.6722380\tbest: 0.6722380 (0)\ttotal: 112ms\tremaining: 3m 44s\n",
            "1999:\tlearn: 0.2673284\ttest: 0.2678700\tbest: 0.2678700 (1999)\ttotal: 3m 18s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2678699846\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 1/5 - LGBMClassifier\n",
            "FOLD 2/5 - LGBMClassifier\n",
            "FOLD 3/5 - LGBMClassifier\n",
            "FOLD 4/5 - LGBMClassifier\n",
            "FOLD 5/5 - LGBMClassifier\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955446\n",
            "XGBClassifier CV AUC mean: 0.955447, std: +-0.00038\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955555\n",
            "CatBoostClassifier CV AUC mean: 0.955556, std: +-0.00038\n",
            "\n",
            "LGBMClassifier OOF AUC: 0.954821\n",
            "LGBMClassifier CV AUC mean: 0.954823, std: +-0.00038\n",
            "\n",
            "Stack (LR meta, 3 models) OOF AUC: 0.955555\n",
            "Submission: 3-model blend. test_proba shape: (270000,)\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import inspect\n",
        "\n",
        "SEED = 42\n",
        "NSPLITS = 5\n",
        "USE_LR_STACK = False  # True = LR meta-learner; False = tuned weight blend (same ~.9537, simpler)\n",
        "DROP_BP_MAX_HR = True   # True = drop raw bp/max_hr (only derived features); try for a bump\n",
        "\n",
        "# Reload data Kaggle-style (lowercase columns, id as index)\n",
        "path = DATA_DIR\n",
        "dfs = []\n",
        "for fl in (\"train.csv\", \"test.csv\"):\n",
        "    df = pd.read_csv(path / fl, index_col=0)\n",
        "    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns.tolist()]\n",
        "    dfs.append(df)\n",
        "train, test = dfs\n",
        "\n",
        "ystr = train.columns[-1]\n",
        "base_features = [c for c in train.columns if c != ystr]\n",
        "\n",
        "cols2comb = [\n",
        "    \"exercise_angina\", \"thallium\", \"chest_pain_type\",\n",
        "    \"slope_of_st\", \"sex\", \"st_depression\", \"number_of_vessels_fluro\",\n",
        "    \"ekg_results\", \"fbs_over_120\",\n",
        "]\n",
        "\n",
        "statmetrics = [\"mean\", \"count\"]\n",
        "\n",
        "X = train.drop(columns=ystr)\n",
        "y = (train[ystr] == \"Presence\").astype(int)\n",
        "\n",
        "X_test = test.copy()\n",
        "\n",
        "# Teacher model from original clinical dataset -> prior feature\n",
        "orig_path = DATA_DIR.parent / \"original-data\" / \"Heart_Disease_Prediction.csv\"\n",
        "orig_df = pd.read_csv(orig_path)\n",
        "orig_df.columns = [c.strip().lower().replace(\" \", \"_\") for c in orig_df.columns]\n",
        "orig_ystr = orig_df.columns[-1]\n",
        "orig_X = orig_df.drop(columns=orig_ystr)\n",
        "orig_y = (orig_df[orig_ystr] == \"Presence\").astype(int)\n",
        "\n",
        "common_cols = sorted(set(orig_X.columns) & set(X.columns))\n",
        "print(f\"Teacher model using {len(common_cols)} shared columns from original dataset\")\n",
        "\n",
        "teacher = cb.CatBoostClassifier(\n",
        "    iterations=400,\n",
        "    depth=4,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.9,\n",
        "    colsample_bylevel=0.9,\n",
        "    random_seed=SEED,\n",
        "    verbose=0,\n",
        ")\n",
        "teacher.fit(orig_X[common_cols], orig_y)\n",
        "\n",
        "X[\"teacher_pred\"] = teacher.predict_proba(X[common_cols])[:, 1]\n",
        "X_test[\"teacher_pred\"] = teacher.predict_proba(X_test[common_cols])[:, 1]\n",
        "\n",
        "# Adversarial validation: train vs test\n",
        "adv_X = pd.concat([X, X_test], axis=0).reset_index(drop=True)\n",
        "adv_y = np.concatenate([\n",
        "    np.zeros(len(X), dtype=int),\n",
        "    np.ones(len(X_test), dtype=int),\n",
        "])\n",
        "adv_skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "oof_adv = np.zeros(len(adv_y), dtype=float)\n",
        "for tr_adv, val_adv in adv_skf.split(adv_X, adv_y):\n",
        "    adv_clf = lgb.LGBMClassifier(\n",
        "        objective=\"binary\",\n",
        "        metric=\"auc\",\n",
        "        learning_rate=0.05,\n",
        "        n_estimators=400,\n",
        "        num_leaves=31,\n",
        "        feature_fraction=0.9,\n",
        "        bagging_fraction=0.9,\n",
        "        bagging_freq=1,\n",
        "        min_data_in_leaf=30,\n",
        "        random_state=SEED,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    adv_clf.fit(adv_X.iloc[tr_adv], adv_y[tr_adv])\n",
        "    oof_adv[val_adv] = adv_clf.predict_proba(adv_X.iloc[val_adv])[:, 1]\n",
        "\n",
        "auc_adv = roc_auc_score(adv_y, oof_adv)\n",
        "print(f\"Adversarial AUC (train vs test): {auc_adv:.5f}\")\n",
        "\n",
        "p_test_train = oof_adv[: len(X)]\n",
        "eps = 1e-3\n",
        "w_train = p_test_train / (1.0 - p_test_train + eps)\n",
        "w_train = w_train / w_train.mean()\n",
        "print(\n",
        "    f\"Sample weights (train-like vs test-like) -> min={w_train.min():.3f}, max={w_train.max():.3f}, mean={w_train.mean():.3f}\"\n",
        ")\n",
        "\n",
        "\n",
        "def get_cat_feature_indices(X_):\n",
        "    return [i for i, c in enumerate(X_.columns) if c.startswith(\"CAT_\")]\n",
        "\n",
        "\n",
        "def fe_foldwise(X_tr, X_val, y_tr):\n",
        "    X_tr = X_tr.copy()\n",
        "    X_val = X_val.copy()\n",
        "\n",
        "    temp = pd.concat([X_tr, y_tr], axis=1)\n",
        "\n",
        "    # casting\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"age>55\"] = (df[\"age\"] > 55).astype(int)\n",
        "        for col in df.columns:\n",
        "            if col == \"teacher_pred\":\n",
        "                continue\n",
        "            colname = f\"CAT_{col}\"\n",
        "            df[colname] = df[col].astype(str).astype(\"category\")\n",
        "\n",
        "    # numeric interactions and derived + bin features (from 0.954 notebook)\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"chest_pain_type_bin\"] = (df[\"chest_pain_type\"] >= 3).astype(int)\n",
        "        df[\"st_depression_bin\"] = (df[\"st_depression\"] >= 2).astype(int)\n",
        "        df[\"number_of_vessels_fluro_bin\"] = (df[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "        df[\"hr_age\"] = df[\"max_hr\"] * df[\"age\"]\n",
        "        df[\"bp_age\"] = df[\"bp\"] * df[\"age\"]\n",
        "        df[\"st_slope\"] = df[\"st_depression\"] * df[\"slope_of_st\"]\n",
        "        df[\"chol_exercise\"] = df[\"cholesterol\"] * df[\"exercise_angina\"]\n",
        "        pred_max = (220 - df[\"age\"]).clip(lower=10)\n",
        "        df[\"max_hr_pct_pred\"] = df[\"max_hr\"] / pred_max\n",
        "        df[\"risk_sum\"] = df[\"number_of_vessels_fluro\"] + df[\"thallium\"] + df[\"exercise_angina\"]\n",
        "\n",
        "    # target statistics + smoothed target encoding\n",
        "    global_mean = float(y_tr.mean())\n",
        "    m_smooth = 20\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            cname = f\"target_{bf}_{s}\"\n",
        "            X_tr[cname] = X_tr[bf].map(stats[s])\n",
        "            X_val[cname] = X_val[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_tr[f\"target_{bf}_smooth\"] = X_tr[bf].map(smoothed).fillna(global_mean)\n",
        "        X_val[f\"target_{bf}_smooth\"] = X_val[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    # categorical combinations\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_tr[c2].max(), X_val[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_tr[cname] = (\n",
        "                (X_tr[c1] + 1 + (X_tr[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "            X_val[cname] = (\n",
        "                (X_val[c1] + 1 + (X_val[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    if DROP_BP_MAX_HR:\n",
        "        X_tr = X_tr.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "        X_val = X_val.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "    return X_tr, X_val\n",
        "\n",
        "\n",
        "def fe_test(X_test_, X_train_, y_train_):\n",
        "    X_test_ = X_test_.copy()\n",
        "    temp = pd.concat([X_train_, y_train_], axis=1)\n",
        "\n",
        "    X_test_[\"age>55\"] = (X_test_[\"age\"] > 55).astype(int)\n",
        "    for col in X_test_.columns:\n",
        "        if col == \"teacher_pred\":\n",
        "            continue\n",
        "        colname = f\"CAT_{col}\"\n",
        "        X_test_[colname] = X_test_[col].astype(str).astype(\"category\")\n",
        "\n",
        "    X_test_[\"chest_pain_type_bin\"] = (X_test_[\"chest_pain_type\"] >= 3).astype(int)\n",
        "    X_test_[\"st_depression_bin\"] = (X_test_[\"st_depression\"] >= 2).astype(int)\n",
        "    X_test_[\"number_of_vessels_fluro_bin\"] = (X_test_[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "    X_test_[\"hr_age\"] = X_test_[\"max_hr\"] * X_test_[\"age\"]\n",
        "    X_test_[\"bp_age\"] = X_test_[\"bp\"] * X_test_[\"age\"]\n",
        "    X_test_[\"st_slope\"] = X_test_[\"st_depression\"] * X_test_[\"slope_of_st\"]\n",
        "    X_test_[\"chol_exercise\"] = X_test_[\"cholesterol\"] * X_test_[\"exercise_angina\"]\n",
        "    pred_max = (220 - X_test_[\"age\"]).clip(lower=10)\n",
        "    X_test_[\"max_hr_pct_pred\"] = X_test_[\"max_hr\"] / pred_max\n",
        "    X_test_[\"risk_sum\"] = X_test_[\"number_of_vessels_fluro\"] + X_test_[\"thallium\"] + X_test_[\"exercise_angina\"]\n",
        "\n",
        "    global_mean = float(y_train_.mean())\n",
        "    m_smooth = 20\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            X_test_[f\"target_{bf}_{s}\"] = X_test_[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_test_[f\"target_{bf}_smooth\"] = X_test_[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_train_[c2].max(), X_test_[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_test_[cname] = (\n",
        "                (X_test_[c1] + 1 + (X_test_[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    if DROP_BP_MAX_HR:\n",
        "        X_test_ = X_test_.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "    return X_test_\n",
        "\n",
        "\n",
        "xgboost_params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"auc\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"max_depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"colsample_bytree\": 0.9,\n",
        "    \"n_estimators\": 2000,\n",
        "    \"min_child_weight\": 10,\n",
        "    \"gamma\": 1,\n",
        "    \"reg_lambda\": 0.01,\n",
        "    \"reg_alpha\": 1.5,\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"n_jobs\": -1,\n",
        "    \"random_state\": SEED,\n",
        "    \"early_stopping_rounds\": 100,\n",
        "    \"enable_categorical\": True,\n",
        "}\n",
        "\n",
        "catboost_params = {\n",
        "    \"loss_function\": \"Logloss\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"iterations\": 2000,\n",
        "    \"min_data_in_leaf\": 1,\n",
        "    \"l2_leaf_reg\": 1.002,\n",
        "    \"thread_count\": -1,\n",
        "    \"random_seed\": SEED,\n",
        "    \"early_stopping_rounds\": 100,\n",
        "    \"bootstrap_type\": \"Bernoulli\",\n",
        "}\n",
        "\n",
        "lgbm_params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"metric\": \"auc\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"n_estimators\": 1000,\n",
        "    \"num_leaves\": 31,\n",
        "    \"feature_fraction\": 0.9,\n",
        "    \"bagging_fraction\": 0.9,\n",
        "    \"bagging_freq\": 1,\n",
        "    \"min_data_in_leaf\": 30,\n",
        "    \"random_state\": SEED,\n",
        "    \"n_jobs\": -1,\n",
        "    \"verbose\": -1,\n",
        "}\n",
        "models = {\n",
        "    XGBClassifier: xgboost_params,\n",
        "    CatBoostClassifier: catboost_params,\n",
        "    LGBMClassifier: lgbm_params,\n",
        "}\n",
        "\n",
        "kf = KFold(n_splits=NSPLITS, shuffle=True, random_state=SEED)\n",
        "\n",
        "oof_train_model = {}\n",
        "oof_test_model = {}\n",
        "cv_auc_model = defaultdict(list)\n",
        "\n",
        "for modelClass, param in models.items():\n",
        "    model_name = modelClass.__name__\n",
        "    oof_train = np.zeros(len(X))\n",
        "    oof_test = np.zeros(len(X_test))\n",
        "\n",
        "    for fold, (tr, val) in enumerate(kf.split(X)):\n",
        "        print(f\"FOLD {fold + 1}/{NSPLITS} - {model_name}\")\n",
        "\n",
        "        X_tr_raw, X_val_raw = X.iloc[tr], X.iloc[val]\n",
        "        y_tr, y_val = y.iloc[tr], y.iloc[val]\n",
        "\n",
        "        X_tr, X_val = fe_foldwise(X_tr_raw, X_val_raw, y_tr)\n",
        "\n",
        "        model = modelClass(**param)\n",
        "        fit_kwargs = {\n",
        "            \"X\": X_tr,\n",
        "            \"y\": y_tr,\n",
        "            \"eval_set\": [(X_val, y_val)],\n",
        "            \"sample_weight\": w_train[tr],\n",
        "        }\n",
        "        if model_name != \"LGBMClassifier\":\n",
        "            fit_kwargs[\"verbose\"] = 2000\n",
        "        if \"cat_features\" in inspect.signature(model.fit).parameters:\n",
        "            cat_features = get_cat_feature_indices(X_tr)\n",
        "            fit_kwargs[\"cat_features\"] = cat_features\n",
        "        model.fit(**fit_kwargs)\n",
        "        oof_train[val] = model.predict_proba(X_val)[:, 1]\n",
        "        X_test_fe = fe_test(X_test, X_tr_raw, y_tr)\n",
        "        oof_test += model.predict_proba(X_test_fe)[:, 1] / NSPLITS\n",
        "        cv_auc_model[model_name].append(roc_auc_score(y[val], oof_train[val]))\n",
        "\n",
        "    oof_train_model[model_name] = oof_train\n",
        "    oof_test_model[model_name] = oof_test\n",
        "\n",
        "# Evaluation per model\n",
        "for modelClass in models.keys():\n",
        "    model_name = modelClass.__name__\n",
        "    print(f\"\\n{model_name} OOF AUC: {roc_auc_score(y, oof_train_model[model_name]):.6f}\")\n",
        "    print(\n",
        "        f\"{model_name} CV AUC mean: {np.mean(cv_auc_model[model_name]):.6f}, std: +-{np.std(cv_auc_model[model_name]):.5f}\"\n",
        "    )\n",
        "\n",
        "# Stack: LR meta for 3+ models or when USE_LR_STACK; else tuned 2-model weight blend\n",
        "X_oof_tr = pd.DataFrame.from_dict(oof_train_model)\n",
        "X_oof_test = pd.DataFrame.from_dict(oof_test_model)\n",
        "cols = list(X_oof_tr.columns)\n",
        "use_meta = USE_LR_STACK or len(cols) >= 3\n",
        "if use_meta:\n",
        "    meta = LogisticRegression(max_iter=500, random_state=SEED)\n",
        "    meta.fit(X_oof_tr, y, sample_weight=w_train)\n",
        "    oof_tr_final = pd.Series(meta.predict_proba(X_oof_tr)[:, 1], index=X_oof_tr.index)\n",
        "    oof_test_final = pd.Series(meta.predict_proba(X_oof_test)[:, 1], index=X_oof_test.index)\n",
        "    stack_auc = roc_auc_score(y, oof_tr_final)\n",
        "    print(f\"\\nStack (LR meta, {len(cols)} models) OOF AUC: {stack_auc:.6f}\")\n",
        "else:\n",
        "    a, b = X_oof_tr[cols[0]], X_oof_tr[cols[1]]\n",
        "    best_w, best_auc = 0.5, 0.0\n",
        "    for w in np.linspace(0, 1, 21):\n",
        "        blend = w * a + (1 - w) * b\n",
        "        auc = roc_auc_score(y, blend)\n",
        "        if auc > best_auc:\n",
        "            best_auc, best_w = auc, w\n",
        "    oof_tr_final = best_w * X_oof_tr[cols[0]] + (1 - best_w) * X_oof_tr[cols[1]]\n",
        "    oof_test_final = best_w * X_oof_test[cols[0]] + (1 - best_w) * X_oof_test[cols[1]]\n",
        "    print(f\"\\nBlend weight {cols[0]}={best_w:.2f}, {cols[1]}={1-best_w:.2f} -> OOF AUC: {best_auc:.6f}\")\n",
        "\n",
        "# Set variables used by later cells\n",
        "oof = oof_tr_final.values\n",
        "test_proba = oof_test_final.values\n",
        "N_STACK_MODELS = len(oof_train_model)\n",
        "print(f\"Submission: {N_STACK_MODELS}-model blend. test_proba shape: {test_proba.shape}\")\n",
        "\n",
        "# Ensure id column exists for submission\n",
        "test[\"id\"] = test.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix (OOF, threshold=0.5)\n",
            "Rows: true, Cols: predicted |  Absence   Presence\n",
            "[[314904  32642]\n",
            " [ 37254 245200]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred = (oof >= 0.5).astype(int)\n",
        "cm = confusion_matrix(y, y_pred)\n",
        "print(\"Confusion matrix (OOF, threshold=0.5)\")\n",
        "print(\"Rows: true, Cols: predicted |  Absence   Presence\")\n",
        "print(cm)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "plt.colorbar()\n",
        "plt.xticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.yticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
        "plt.title(\"Confusion matrix (OOF)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission saved (3-model blend): submission.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>630000</th>\n",
              "      <td>630000</td>\n",
              "      <td>0.948362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630001</th>\n",
              "      <td>630001</td>\n",
              "      <td>0.039821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630002</th>\n",
              "      <td>630002</td>\n",
              "      <td>0.959373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630003</th>\n",
              "      <td>630003</td>\n",
              "      <td>0.038669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630004</th>\n",
              "      <td>630004</td>\n",
              "      <td>0.136764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630005</th>\n",
              "      <td>630005</td>\n",
              "      <td>0.958787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630006</th>\n",
              "      <td>630006</td>\n",
              "      <td>0.038059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630007</th>\n",
              "      <td>630007</td>\n",
              "      <td>0.574125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630008</th>\n",
              "      <td>630008</td>\n",
              "      <td>0.960392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630009</th>\n",
              "      <td>630009</td>\n",
              "      <td>0.040659</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  Heart Disease\n",
              "id                           \n",
              "630000  630000       0.948362\n",
              "630001  630001       0.039821\n",
              "630002  630002       0.959373\n",
              "630003  630003       0.038669\n",
              "630004  630004       0.136764\n",
              "630005  630005       0.958787\n",
              "630006  630006       0.038059\n",
              "630007  630007       0.574125\n",
              "630008  630008       0.960392\n",
              "630009  630009       0.040659"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub = pd.DataFrame({\"id\": test[\"id\"], \"Heart Disease\": test_proba})\n",
        "sub.to_csv(OUTPUT_DIR / \"submission.csv\", index=False)\n",
        "print(f\"Submission saved ({N_STACK_MODELS}-model blend): {OUTPUT_DIR / 'submission.csv'}\")\n",
        "sub.head(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
