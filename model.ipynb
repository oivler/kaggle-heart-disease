{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicting Heart Disease\n",
        "\n",
        "## Score: .95369"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict, KFold\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import catboost as cb\n",
        "from catboost import CatBoostClassifier\n",
        "#%pip install torch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "DATA_DIR = Path(\"playground-series-s6e2\")\n",
        "OUTPUT_DIR = Path(\".\")\n",
        "n_splits = 5\n",
        "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (630000, 15)\n",
            "Test: (270000, 14)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Chest pain type</th>\n",
              "      <th>BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FBS over 120</th>\n",
              "      <th>EKG results</th>\n",
              "      <th>Max HR</th>\n",
              "      <th>Exercise angina</th>\n",
              "      <th>ST depression</th>\n",
              "      <th>Slope of ST</th>\n",
              "      <th>Number of vessels fluro</th>\n",
              "      <th>Thallium</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>152</td>\n",
              "      <td>239</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>325</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>160</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>134</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>140</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  Age  Sex  Chest pain type   BP  Cholesterol  FBS over 120  EKG results  \\\n",
              "0   0   58    1                4  152          239             0            0   \n",
              "1   1   52    1                1  125          325             0            2   \n",
              "2   2   56    0                2  160          188             0            2   \n",
              "3   3   44    0                3  134          229             0            2   \n",
              "4   4   58    1                4  140          234             0            2   \n",
              "\n",
              "   Max HR  Exercise angina  ST depression  Slope of ST  \\\n",
              "0     158                1            3.6            2   \n",
              "1     171                0            0.0            1   \n",
              "2     151                0            0.0            1   \n",
              "3     150                0            1.0            2   \n",
              "4     125                1            3.8            2   \n",
              "\n",
              "   Number of vessels fluro  Thallium Heart Disease  \n",
              "0                        2         7      Presence  \n",
              "1                        0         3       Absence  \n",
              "2                        0         3       Absence  \n",
              "3                        0         3       Absence  \n",
              "4                        3         3      Presence  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR / \"test.csv\")\n",
        "print(f\"Train: {train.shape}\")\n",
        "print(f\"Test: {test.shape}\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features: 32 columns\n",
            "Target distribution: {0: 347546, 1: 282454}\n"
          ]
        }
      ],
      "source": [
        "target_col = \"Heart Disease\"\n",
        "id_col = \"id\"\n",
        "feature_cols = [c for c in train.columns if c not in (id_col, target_col)]\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(train[target_col])\n",
        "\n",
        "X_train = train[feature_cols].copy()\n",
        "X_test = test[feature_cols].copy()\n",
        "\n",
        "for col in feature_cols:\n",
        "    if X_train[col].isna().any() or X_test[col].isna().any():\n",
        "        med = X_train[col].median()\n",
        "        X_train[col] = X_train[col].fillna(med)\n",
        "        X_test[col] = X_test[col].fillna(med)\n",
        "\n",
        "X_train[\"chol_exercise\"] = X_train[\"Cholesterol\"] * X_train[\"Exercise angina\"]\n",
        "X_test[\"chol_exercise\"] = X_test[\"Cholesterol\"] * X_test[\"Exercise angina\"]\n",
        "X_train[\"st_slope\"] = X_train[\"ST depression\"] * X_train[\"Slope of ST\"]\n",
        "X_test[\"st_slope\"] = X_test[\"ST depression\"] * X_test[\"Slope of ST\"]\n",
        "X_train[\"hr_age\"] = X_train[\"Max HR\"] * X_train[\"Age\"]\n",
        "X_test[\"hr_age\"] = X_test[\"Max HR\"] * X_test[\"Age\"]\n",
        "X_train[\"bp_age\"] = X_train[\"BP\"] * X_train[\"Age\"]\n",
        "X_test[\"bp_age\"] = X_test[\"BP\"] * X_test[\"Age\"]\n",
        "\n",
        "te_cols = [\"Chest pain type\", \"Slope of ST\", \"Thallium\"]\n",
        "global_mean = float(y.mean())\n",
        "m = 20\n",
        "for col in te_cols:\n",
        "    agg = pd.DataFrame({\"_y\": y}).groupby(X_train[col])[\"_y\"].agg([\"mean\", \"count\"])\n",
        "    smoothed = (agg[\"count\"] * agg[\"mean\"] + m * global_mean) / (agg[\"count\"] + m)\n",
        "    X_train[col + \"_te\"] = X_train[col].map(smoothed).fillna(global_mean)\n",
        "    X_test[col + \"_te\"] = X_test[col].map(smoothed).fillna(global_mean)\n",
        "\n",
        "scaler_feat = StandardScaler()\n",
        "X_tr_s = scaler_feat.fit_transform(X_train)\n",
        "X_te_s = scaler_feat.transform(X_test)\n",
        "kmeans = KMeans(n_clusters=12, random_state=42, n_init=10)\n",
        "kmeans.fit(X_tr_s)\n",
        "for i in range(kmeans.n_clusters):\n",
        "    d_tr = np.linalg.norm(X_tr_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    d_te = np.linalg.norm(X_te_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    X_train[f\"dist_c{i}\"] = d_tr\n",
        "    X_test[f\"dist_c{i}\"] = d_te\n",
        "\n",
        "print(f\"Features: {len(X_train.columns)} columns\")\n",
        "print(f\"Target distribution: {pd.Series(y).value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best OOF AUC: 0.95507, params: {'depth': 6, 'lr': 0.05, 'min_data_in_leaf': 15}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\"depth\": [4, 5, 6], \"lr\": [0.03, 0.04, 0.05], \"min_data_in_leaf\": [15, 25, 35]}\n",
        "n_est = 800\n",
        "best_auc, best_params = 0, None\n",
        "for depth in param_grid[\"depth\"]:\n",
        "    for lr in param_grid[\"lr\"]:\n",
        "        for min_leaf in param_grid[\"min_data_in_leaf\"]:\n",
        "            m = cb.CatBoostClassifier(iterations=n_est, depth=depth, learning_rate=lr, min_data_in_leaf=min_leaf, subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "            oof = cross_val_predict(m, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "            auc = roc_auc_score(y, oof)\n",
        "            if auc > best_auc:\n",
        "                best_auc, best_params = auc, {\"depth\": depth, \"lr\": lr, \"min_data_in_leaf\": min_leaf}\n",
        "print(f\"Best OOF AUC: {best_auc:.5f}, params: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV AUC: 0.95517 (blend w_xgb=0.4)\n"
          ]
        }
      ],
      "source": [
        "model = cb.CatBoostClassifier(iterations=n_est, depth=best_params[\"depth\"], learning_rate=best_params[\"lr\"], min_data_in_leaf=best_params[\"min_data_in_leaf\"], subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "oof_cb = cross_val_predict(model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=n_est, max_depth=5, learning_rate=0.05, min_child_weight=20, subsample=0.75, colsample_bytree=0.75, random_state=42, eval_metric=\"auc\")\n",
        "oof_xgb = cross_val_predict(xgb_model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "best_w, best_auc = 0.0, roc_auc_score(y, oof_cb)\n",
        "for w in [0, 0.1, 0.2, 0.3, 0.4]:\n",
        "    oof_blend = (1 - w) * oof_cb + w * oof_xgb\n",
        "    auc = roc_auc_score(y, oof_blend)\n",
        "    if auc > best_auc:\n",
        "        best_auc, best_w = auc, w\n",
        "oof = (1 - best_w) * oof_cb + best_w * oof_xgb\n",
        "print(f\"CV AUC: {best_auc:.5f} (blend w_xgb={best_w})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train, y)\n",
        "xgb_model.fit(X_train, y)\n",
        "test_cb = model.predict_proba(X_test)[:, 1]\n",
        "test_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
        "test_proba = (1 - best_w) * test_cb + best_w * test_xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher model using 13 shared columns from original dataset\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 180000, number of negative: 420000\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011382 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 668\n",
            "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300000 -> initscore=-0.847298\n",
            "[LightGBM] [Info] Start training from score -0.847298\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 180000, number of negative: 420000\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009887 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 672\n",
            "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300000 -> initscore=-0.847298\n",
            "[LightGBM] [Info] Start training from score -0.847298\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 180000, number of negative: 420000\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010957 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 671\n",
            "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300000 -> initscore=-0.847298\n",
            "[LightGBM] [Info] Start training from score -0.847298\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Adversarial AUC (train vs test): 0.50147\n",
            "Sample weights (train-like vs test-like) -> min=0.350, max=2.793, mean=1.000\n",
            "FOLD 1/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90499\n",
            "[1499]\tvalidation_0-auc:0.95524\n",
            "FOLD 2/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90580\n",
            "[1499]\tvalidation_0-auc:0.95552\n",
            "FOLD 3/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90708\n",
            "[1499]\tvalidation_0-auc:0.95610\n",
            "FOLD 4/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90562\n",
            "[1499]\tvalidation_0-auc:0.95499\n",
            "FOLD 5/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90558\n",
            "[1499]\tvalidation_0-auc:0.95523\n",
            "FOLD 1/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713352\ttest: 0.6713531\tbest: 0.6713531 (0)\ttotal: 130ms\tremaining: 3m 14s\n",
            "1499:\tlearn: 0.2676097\ttest: 0.2682199\tbest: 0.2682199 (1499)\ttotal: 3m 23s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2682199412\n",
            "bestIteration = 1499\n",
            "\n",
            "FOLD 2/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713394\ttest: 0.6713447\tbest: 0.6713447 (0)\ttotal: 159ms\tremaining: 3m 58s\n",
            "1499:\tlearn: 0.2678219\ttest: 0.2673233\tbest: 0.2673233 (1498)\ttotal: 3m 4s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.267323266\n",
            "bestIteration = 1498\n",
            "\n",
            "Shrink model to first 1499 iterations.\n",
            "FOLD 3/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6714011\ttest: 0.6712825\tbest: 0.6712825 (0)\ttotal: 140ms\tremaining: 3m 30s\n",
            "1499:\tlearn: 0.2683232\ttest: 0.2655683\tbest: 0.2655683 (1499)\ttotal: 3m\tremaining: 0us\n",
            "\n",
            "bestTest = 0.265568329\n",
            "bestIteration = 1499\n",
            "\n",
            "FOLD 4/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713478\ttest: 0.6713436\tbest: 0.6713436 (0)\ttotal: 131ms\tremaining: 3m 16s\n",
            "1499:\tlearn: 0.2675293\ttest: 0.2689226\tbest: 0.2689226 (1499)\ttotal: 3m\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2689226004\n",
            "bestIteration = 1499\n",
            "\n",
            "FOLD 5/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6714200\ttest: 0.6712798\tbest: 0.6712798 (0)\ttotal: 129ms\tremaining: 3m 13s\n",
            "1499:\tlearn: 0.2676917\ttest: 0.2679777\tbest: 0.2679777 (1499)\ttotal: 3m 1s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2679777122\n",
            "bestIteration = 1499\n",
            "\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955415\n",
            "XGBClassifier CV AUC mean: 0.955416, std: +-0.00038\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955493\n",
            "CatBoostClassifier CV AUC mean: 0.955494, std: +-0.00037\n",
            "\n",
            "Blend weight XGBClassifier=0.40, CatBoostClassifier=0.60 -> OOF AUC: 0.955552\n",
            "Submission: 2-model blend. test_proba shape: (270000,)\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import inspect\n",
        "\n",
        "SEED = 42\n",
        "NSPLITS = 5\n",
        "\n",
        "# Reload data Kaggle-style (lowercase columns, id as index)\n",
        "path = DATA_DIR\n",
        "dfs = []\n",
        "for fl in (\"train.csv\", \"test.csv\"):\n",
        "    df = pd.read_csv(path / fl, index_col=0)\n",
        "    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns.tolist()]\n",
        "    dfs.append(df)\n",
        "train, test = dfs\n",
        "\n",
        "ystr = train.columns[-1]\n",
        "base_features = [c for c in train.columns if c != ystr]\n",
        "\n",
        "cols2comb = [\n",
        "    \"exercise_angina\", \"thallium\", \"chest_pain_type\",\n",
        "    \"slope_of_st\", \"sex\", \"st_depression\", \"number_of_vessels_fluro\",\n",
        "    \"ekg_results\", \"fbs_over_120\",\n",
        "]\n",
        "\n",
        "statmetrics = [\"mean\", \"count\"]\n",
        "\n",
        "X = train.drop(columns=ystr)\n",
        "y = (train[ystr] == \"Presence\").astype(int)\n",
        "\n",
        "X_test = test.copy()\n",
        "\n",
        "# Teacher model from original clinical dataset -> prior feature\n",
        "orig_path = DATA_DIR.parent / \"original-data\" / \"Heart_Disease_Prediction.csv\"\n",
        "orig_df = pd.read_csv(orig_path)\n",
        "orig_df.columns = [c.strip().lower().replace(\" \", \"_\") for c in orig_df.columns]\n",
        "orig_ystr = orig_df.columns[-1]\n",
        "orig_X = orig_df.drop(columns=orig_ystr)\n",
        "orig_y = (orig_df[orig_ystr] == \"Presence\").astype(int)\n",
        "\n",
        "common_cols = sorted(set(orig_X.columns) & set(X.columns))\n",
        "print(f\"Teacher model using {len(common_cols)} shared columns from original dataset\")\n",
        "\n",
        "teacher = cb.CatBoostClassifier(\n",
        "    iterations=400,\n",
        "    depth=4,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.9,\n",
        "    colsample_bylevel=0.9,\n",
        "    random_seed=SEED,\n",
        "    verbose=0,\n",
        ")\n",
        "teacher.fit(orig_X[common_cols], orig_y)\n",
        "\n",
        "X[\"teacher_pred\"] = teacher.predict_proba(X[common_cols])[:, 1]\n",
        "X_test[\"teacher_pred\"] = teacher.predict_proba(X_test[common_cols])[:, 1]\n",
        "\n",
        "# Adversarial validation: train vs test\n",
        "adv_X = pd.concat([X, X_test], axis=0).reset_index(drop=True)\n",
        "adv_y = np.concatenate([\n",
        "    np.zeros(len(X), dtype=int),\n",
        "    np.ones(len(X_test), dtype=int),\n",
        "])\n",
        "adv_skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "oof_adv = np.zeros(len(adv_y), dtype=float)\n",
        "for tr_adv, val_adv in adv_skf.split(adv_X, adv_y):\n",
        "    adv_clf = lgb.LGBMClassifier(\n",
        "        objective=\"binary\",\n",
        "        metric=\"auc\",\n",
        "        learning_rate=0.05,\n",
        "        n_estimators=400,\n",
        "        num_leaves=31,\n",
        "        feature_fraction=0.9,\n",
        "        bagging_fraction=0.9,\n",
        "        bagging_freq=1,\n",
        "        min_data_in_leaf=30,\n",
        "        random_state=SEED,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    adv_clf.fit(adv_X.iloc[tr_adv], adv_y[tr_adv])\n",
        "    oof_adv[val_adv] = adv_clf.predict_proba(adv_X.iloc[val_adv])[:, 1]\n",
        "\n",
        "auc_adv = roc_auc_score(adv_y, oof_adv)\n",
        "print(f\"Adversarial AUC (train vs test): {auc_adv:.5f}\")\n",
        "\n",
        "p_test_train = oof_adv[: len(X)]\n",
        "eps = 1e-3\n",
        "w_train = p_test_train / (1.0 - p_test_train + eps)\n",
        "w_train = w_train / w_train.mean()\n",
        "print(\n",
        "    f\"Sample weights (train-like vs test-like) -> min={w_train.min():.3f}, max={w_train.max():.3f}, mean={w_train.mean():.3f}\"\n",
        ")\n",
        "\n",
        "\n",
        "def get_cat_feature_indices(X_):\n",
        "    return [i for i, c in enumerate(X_.columns) if c.startswith(\"CAT_\")]\n",
        "\n",
        "\n",
        "def fe_foldwise(X_tr, X_val, y_tr):\n",
        "    X_tr = X_tr.copy()\n",
        "    X_val = X_val.copy()\n",
        "\n",
        "    temp = pd.concat([X_tr, y_tr], axis=1)\n",
        "\n",
        "    # casting\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"age>55\"] = (df[\"age\"] > 55).astype(int)\n",
        "        for col in df.columns:\n",
        "            if col == \"teacher_pred\":\n",
        "                continue\n",
        "            colname = f\"CAT_{col}\"\n",
        "            df[colname] = df[col].astype(str).astype(\"category\")\n",
        "\n",
        "    # numeric interactions and derived + bin features (from 0.954 notebook)\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"chest_pain_type_bin\"] = (df[\"chest_pain_type\"] >= 3).astype(int)\n",
        "        df[\"st_depression_bin\"] = (df[\"st_depression\"] >= 2).astype(int)\n",
        "        df[\"number_of_vessels_fluro_bin\"] = (df[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "        df[\"hr_age\"] = df[\"max_hr\"] * df[\"age\"]\n",
        "        df[\"bp_age\"] = df[\"bp\"] * df[\"age\"]\n",
        "        df[\"st_slope\"] = df[\"st_depression\"] * df[\"slope_of_st\"]\n",
        "        df[\"chol_exercise\"] = df[\"cholesterol\"] * df[\"exercise_angina\"]\n",
        "        pred_max = (220 - df[\"age\"]).clip(lower=10)\n",
        "        df[\"max_hr_pct_pred\"] = df[\"max_hr\"] / pred_max\n",
        "        df[\"risk_sum\"] = df[\"number_of_vessels_fluro\"] + df[\"thallium\"] + df[\"exercise_angina\"]\n",
        "\n",
        "    # target statistics + smoothed target encoding\n",
        "    global_mean = float(y_tr.mean())\n",
        "    m_smooth = 20\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            cname = f\"target_{bf}_{s}\"\n",
        "            X_tr[cname] = X_tr[bf].map(stats[s])\n",
        "            X_val[cname] = X_val[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_tr[f\"target_{bf}_smooth\"] = X_tr[bf].map(smoothed).fillna(global_mean)\n",
        "        X_val[f\"target_{bf}_smooth\"] = X_val[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    # categorical combinations\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_tr[c2].max(), X_val[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_tr[cname] = (\n",
        "                (X_tr[c1] + 1 + (X_tr[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "            X_val[cname] = (\n",
        "                (X_val[c1] + 1 + (X_val[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    return X_tr, X_val\n",
        "\n",
        "\n",
        "def fe_test(X_test_, X_train_, y_train_):\n",
        "    X_test_ = X_test_.copy()\n",
        "    temp = pd.concat([X_train_, y_train_], axis=1)\n",
        "\n",
        "    X_test_[\"age>55\"] = (X_test_[\"age\"] > 55).astype(int)\n",
        "    for col in X_test_.columns:\n",
        "        if col == \"teacher_pred\":\n",
        "            continue\n",
        "        colname = f\"CAT_{col}\"\n",
        "        X_test_[colname] = X_test_[col].astype(str).astype(\"category\")\n",
        "\n",
        "    X_test_[\"chest_pain_type_bin\"] = (X_test_[\"chest_pain_type\"] >= 3).astype(int)\n",
        "    X_test_[\"st_depression_bin\"] = (X_test_[\"st_depression\"] >= 2).astype(int)\n",
        "    X_test_[\"number_of_vessels_fluro_bin\"] = (X_test_[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "    X_test_[\"hr_age\"] = X_test_[\"max_hr\"] * X_test_[\"age\"]\n",
        "    X_test_[\"bp_age\"] = X_test_[\"bp\"] * X_test_[\"age\"]\n",
        "    X_test_[\"st_slope\"] = X_test_[\"st_depression\"] * X_test_[\"slope_of_st\"]\n",
        "    X_test_[\"chol_exercise\"] = X_test_[\"cholesterol\"] * X_test_[\"exercise_angina\"]\n",
        "    pred_max = (220 - X_test_[\"age\"]).clip(lower=10)\n",
        "    X_test_[\"max_hr_pct_pred\"] = X_test_[\"max_hr\"] / pred_max\n",
        "    X_test_[\"risk_sum\"] = X_test_[\"number_of_vessels_fluro\"] + X_test_[\"thallium\"] + X_test_[\"exercise_angina\"]\n",
        "\n",
        "    global_mean = float(y_train_.mean())\n",
        "    m_smooth = 20\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            X_test_[f\"target_{bf}_{s}\"] = X_test_[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_test_[f\"target_{bf}_smooth\"] = X_test_[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_train_[c2].max(), X_test_[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_test_[cname] = (\n",
        "                (X_test_[c1] + 1 + (X_test_[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    return X_test_\n",
        "\n",
        "\n",
        "xgboost_params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"auc\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"max_depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"colsample_bytree\": 0.9,\n",
        "    \"n_estimators\": 1500,\n",
        "    \"min_child_weight\": 10,\n",
        "    \"gamma\": 1,\n",
        "    \"reg_lambda\": 0.01,\n",
        "    \"reg_alpha\": 1.5,\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"n_jobs\": -1,\n",
        "    \"random_state\": SEED,\n",
        "    \"early_stopping_rounds\": 80,\n",
        "    \"enable_categorical\": True,\n",
        "}\n",
        "\n",
        "catboost_params = {\n",
        "    \"loss_function\": \"Logloss\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"iterations\": 1500,\n",
        "    \"min_data_in_leaf\": 1,\n",
        "    \"l2_leaf_reg\": 1.002,\n",
        "    \"thread_count\": -1,\n",
        "    \"random_seed\": SEED,\n",
        "    \"early_stopping_rounds\": 80,\n",
        "    \"bootstrap_type\": \"Bernoulli\",\n",
        "}\n",
        "\n",
        "models = {\n",
        "    XGBClassifier: xgboost_params,\n",
        "    CatBoostClassifier: catboost_params,\n",
        "}\n",
        "\n",
        "kf = KFold(n_splits=NSPLITS, shuffle=True, random_state=SEED)\n",
        "\n",
        "oof_train_model = {}\n",
        "oof_test_model = {}\n",
        "cv_auc_model = defaultdict(list)\n",
        "\n",
        "for modelClass, param in models.items():\n",
        "    model_name = modelClass.__name__\n",
        "    oof_train = np.zeros(len(X))\n",
        "    oof_test = np.zeros(len(X_test))\n",
        "\n",
        "    for fold, (tr, val) in enumerate(kf.split(X)):\n",
        "        print(f\"FOLD {fold + 1}/{NSPLITS} - {model_name}\")\n",
        "\n",
        "        X_tr_raw, X_val_raw = X.iloc[tr], X.iloc[val]\n",
        "        y_tr, y_val = y.iloc[tr], y.iloc[val]\n",
        "\n",
        "        X_tr, X_val = fe_foldwise(X_tr_raw, X_val_raw, y_tr)\n",
        "\n",
        "        model = modelClass(**param)\n",
        "        fit_kwargs = {\n",
        "            \"X\": X_tr,\n",
        "            \"y\": y_tr,\n",
        "            \"eval_set\": [(X_val, y_val)],\n",
        "            \"sample_weight\": w_train[tr],\n",
        "        }\n",
        "        if model_name != \"LGBMClassifier\":\n",
        "            fit_kwargs[\"verbose\"] = 2000\n",
        "        if \"cat_features\" in inspect.signature(model.fit).parameters:\n",
        "            cat_features = get_cat_feature_indices(X_tr)\n",
        "            fit_kwargs[\"cat_features\"] = cat_features\n",
        "        model.fit(**fit_kwargs)\n",
        "        oof_train[val] = model.predict_proba(X_val)[:, 1]\n",
        "        X_test_fe = fe_test(X_test, X_tr_raw, y_tr)\n",
        "        oof_test += model.predict_proba(X_test_fe)[:, 1] / NSPLITS\n",
        "        cv_auc_model[model_name].append(roc_auc_score(y[val], oof_train[val]))\n",
        "\n",
        "    oof_train_model[model_name] = oof_train\n",
        "    oof_test_model[model_name] = oof_test\n",
        "\n",
        "# Evaluation per model\n",
        "for modelClass in models.keys():\n",
        "    model_name = modelClass.__name__\n",
        "    print(f\"\\n{model_name} OOF AUC: {roc_auc_score(y, oof_train_model[model_name]):.6f}\")\n",
        "    print(\n",
        "        f\"{model_name} CV AUC mean: {np.mean(cv_auc_model[model_name]):.6f}, std: +-{np.std(cv_auc_model[model_name]):.5f}\"\n",
        "    )\n",
        "\n",
        "# Blend: tune weight on OOF (one scalar, no extra training)\n",
        "X_oof_tr = pd.DataFrame.from_dict(oof_train_model)\n",
        "X_oof_test = pd.DataFrame.from_dict(oof_test_model)\n",
        "cols = list(X_oof_tr.columns)\n",
        "a, b = X_oof_tr[cols[0]], X_oof_tr[cols[1]]\n",
        "best_w, best_auc = 0.5, 0.0\n",
        "for w in np.linspace(0, 1, 21):\n",
        "    blend = w * a + (1 - w) * b\n",
        "    auc = roc_auc_score(y, blend)\n",
        "    if auc > best_auc:\n",
        "        best_auc, best_w = auc, w\n",
        "oof_tr_final = best_w * X_oof_tr[cols[0]] + (1 - best_w) * X_oof_tr[cols[1]]\n",
        "oof_test_final = best_w * X_oof_test[cols[0]] + (1 - best_w) * X_oof_test[cols[1]]\n",
        "print(f\"\\nBlend weight {cols[0]}={best_w:.2f}, {cols[1]}={1-best_w:.2f} -> OOF AUC: {best_auc:.6f}\")\n",
        "\n",
        "# Set variables used by later cells\n",
        "oof = oof_tr_final.values\n",
        "test_proba = oof_test_final.values\n",
        "N_STACK_MODELS = len(oof_train_model)\n",
        "print(f\"Submission: {N_STACK_MODELS}-model blend. test_proba shape: {test_proba.shape}\")\n",
        "\n",
        "# Ensure id column exists for submission\n",
        "test[\"id\"] = test.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix (OOF, threshold=0.5)\n",
            "Rows: true, Cols: predicted |  Absence   Presence\n",
            "[[314887  32659]\n",
            " [ 37243 245211]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred = (oof >= 0.5).astype(int)\n",
        "cm = confusion_matrix(y, y_pred)\n",
        "print(\"Confusion matrix (OOF, threshold=0.5)\")\n",
        "print(\"Rows: true, Cols: predicted |  Absence   Presence\")\n",
        "print(cm)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "plt.colorbar()\n",
        "plt.xticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.yticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
        "plt.title(\"Confusion matrix (OOF)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission saved (2-model blend): submission.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>630000</th>\n",
              "      <td>630000</td>\n",
              "      <td>0.944246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630001</th>\n",
              "      <td>630001</td>\n",
              "      <td>0.009723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630002</th>\n",
              "      <td>630002</td>\n",
              "      <td>0.985173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630003</th>\n",
              "      <td>630003</td>\n",
              "      <td>0.005530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630004</th>\n",
              "      <td>630004</td>\n",
              "      <td>0.208577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630005</th>\n",
              "      <td>630005</td>\n",
              "      <td>0.983279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630006</th>\n",
              "      <td>630006</td>\n",
              "      <td>0.004116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630007</th>\n",
              "      <td>630007</td>\n",
              "      <td>0.548770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630008</th>\n",
              "      <td>630008</td>\n",
              "      <td>0.990847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630009</th>\n",
              "      <td>630009</td>\n",
              "      <td>0.013223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  Heart Disease\n",
              "id                           \n",
              "630000  630000       0.944246\n",
              "630001  630001       0.009723\n",
              "630002  630002       0.985173\n",
              "630003  630003       0.005530\n",
              "630004  630004       0.208577\n",
              "630005  630005       0.983279\n",
              "630006  630006       0.004116\n",
              "630007  630007       0.548770\n",
              "630008  630008       0.990847\n",
              "630009  630009       0.013223"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub = pd.DataFrame({\"id\": test[\"id\"], \"Heart Disease\": test_proba})\n",
        "sub.to_csv(OUTPUT_DIR / \"submission.csv\", index=False)\n",
        "print(f\"Submission saved ({N_STACK_MODELS}-model blend): {OUTPUT_DIR / 'submission.csv'}\")\n",
        "sub.head(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
