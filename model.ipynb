{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicting Heart Disease\n",
        "\n",
        "## Score: .95370"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict, KFold\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import catboost as cb\n",
        "from catboost import CatBoostClassifier\n",
        "#%pip install torch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "DATA_DIR = Path(\"playground-series-s6e2\")\n",
        "OUTPUT_DIR = Path(\".\")\n",
        "n_splits = 5\n",
        "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (630000, 15)\n",
            "Test: (270000, 14)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Chest pain type</th>\n",
              "      <th>BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FBS over 120</th>\n",
              "      <th>EKG results</th>\n",
              "      <th>Max HR</th>\n",
              "      <th>Exercise angina</th>\n",
              "      <th>ST depression</th>\n",
              "      <th>Slope of ST</th>\n",
              "      <th>Number of vessels fluro</th>\n",
              "      <th>Thallium</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>152</td>\n",
              "      <td>239</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>325</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>160</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>134</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>140</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  Age  Sex  Chest pain type   BP  Cholesterol  FBS over 120  EKG results  \\\n",
              "0   0   58    1                4  152          239             0            0   \n",
              "1   1   52    1                1  125          325             0            2   \n",
              "2   2   56    0                2  160          188             0            2   \n",
              "3   3   44    0                3  134          229             0            2   \n",
              "4   4   58    1                4  140          234             0            2   \n",
              "\n",
              "   Max HR  Exercise angina  ST depression  Slope of ST  \\\n",
              "0     158                1            3.6            2   \n",
              "1     171                0            0.0            1   \n",
              "2     151                0            0.0            1   \n",
              "3     150                0            1.0            2   \n",
              "4     125                1            3.8            2   \n",
              "\n",
              "   Number of vessels fluro  Thallium Heart Disease  \n",
              "0                        2         7      Presence  \n",
              "1                        0         3       Absence  \n",
              "2                        0         3       Absence  \n",
              "3                        0         3       Absence  \n",
              "4                        3         3      Presence  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR / \"test.csv\")\n",
        "print(f\"Train: {train.shape}\")\n",
        "print(f\"Test: {test.shape}\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features: 32 columns\n",
            "Target distribution: {0: 347546, 1: 282454}\n"
          ]
        }
      ],
      "source": [
        "target_col = \"Heart Disease\"\n",
        "id_col = \"id\"\n",
        "feature_cols = [c for c in train.columns if c not in (id_col, target_col)]\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(train[target_col])\n",
        "\n",
        "X_train = train[feature_cols].copy()\n",
        "X_test = test[feature_cols].copy()\n",
        "\n",
        "for col in feature_cols:\n",
        "    if X_train[col].isna().any() or X_test[col].isna().any():\n",
        "        med = X_train[col].median()\n",
        "        X_train[col] = X_train[col].fillna(med)\n",
        "        X_test[col] = X_test[col].fillna(med)\n",
        "\n",
        "X_train[\"chol_exercise\"] = X_train[\"Cholesterol\"] * X_train[\"Exercise angina\"]\n",
        "X_test[\"chol_exercise\"] = X_test[\"Cholesterol\"] * X_test[\"Exercise angina\"]\n",
        "X_train[\"st_slope\"] = X_train[\"ST depression\"] * X_train[\"Slope of ST\"]\n",
        "X_test[\"st_slope\"] = X_test[\"ST depression\"] * X_test[\"Slope of ST\"]\n",
        "X_train[\"hr_age\"] = X_train[\"Max HR\"] * X_train[\"Age\"]\n",
        "X_test[\"hr_age\"] = X_test[\"Max HR\"] * X_test[\"Age\"]\n",
        "X_train[\"bp_age\"] = X_train[\"BP\"] * X_train[\"Age\"]\n",
        "X_test[\"bp_age\"] = X_test[\"BP\"] * X_test[\"Age\"]\n",
        "\n",
        "te_cols = [\"Chest pain type\", \"Slope of ST\", \"Thallium\"]\n",
        "global_mean = float(y.mean())\n",
        "m = 20\n",
        "for col in te_cols:\n",
        "    agg = pd.DataFrame({\"_y\": y}).groupby(X_train[col])[\"_y\"].agg([\"mean\", \"count\"])\n",
        "    smoothed = (agg[\"count\"] * agg[\"mean\"] + m * global_mean) / (agg[\"count\"] + m)\n",
        "    X_train[col + \"_te\"] = X_train[col].map(smoothed).fillna(global_mean)\n",
        "    X_test[col + \"_te\"] = X_test[col].map(smoothed).fillna(global_mean)\n",
        "\n",
        "scaler_feat = StandardScaler()\n",
        "X_tr_s = scaler_feat.fit_transform(X_train)\n",
        "X_te_s = scaler_feat.transform(X_test)\n",
        "kmeans = KMeans(n_clusters=12, random_state=42, n_init=10)\n",
        "kmeans.fit(X_tr_s)\n",
        "for i in range(kmeans.n_clusters):\n",
        "    d_tr = np.linalg.norm(X_tr_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    d_te = np.linalg.norm(X_te_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    X_train[f\"dist_c{i}\"] = d_tr\n",
        "    X_test[f\"dist_c{i}\"] = d_te\n",
        "\n",
        "print(f\"Features: {len(X_train.columns)} columns\")\n",
        "print(f\"Target distribution: {pd.Series(y).value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best OOF AUC: 0.95507, params: {'depth': 6, 'lr': 0.05, 'min_data_in_leaf': 15}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\"depth\": [4, 5, 6], \"lr\": [0.03, 0.04, 0.05], \"min_data_in_leaf\": [15, 25, 35]}\n",
        "n_est = 800\n",
        "best_auc, best_params = 0, None\n",
        "for depth in param_grid[\"depth\"]:\n",
        "    for lr in param_grid[\"lr\"]:\n",
        "        for min_leaf in param_grid[\"min_data_in_leaf\"]:\n",
        "            m = cb.CatBoostClassifier(iterations=n_est, depth=depth, learning_rate=lr, min_data_in_leaf=min_leaf, subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "            oof = cross_val_predict(m, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "            auc = roc_auc_score(y, oof)\n",
        "            if auc > best_auc:\n",
        "                best_auc, best_params = auc, {\"depth\": depth, \"lr\": lr, \"min_data_in_leaf\": min_leaf}\n",
        "print(f\"Best OOF AUC: {best_auc:.5f}, params: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV AUC: 0.95517 (blend w_xgb=0.4)\n"
          ]
        }
      ],
      "source": [
        "model = cb.CatBoostClassifier(iterations=n_est, depth=best_params[\"depth\"], learning_rate=best_params[\"lr\"], min_data_in_leaf=best_params[\"min_data_in_leaf\"], subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "oof_cb = cross_val_predict(model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=n_est, max_depth=5, learning_rate=0.05, min_child_weight=20, subsample=0.75, colsample_bytree=0.75, random_state=42, eval_metric=\"auc\")\n",
        "oof_xgb = cross_val_predict(xgb_model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "best_w, best_auc = 0.0, roc_auc_score(y, oof_cb)\n",
        "for w in [0, 0.1, 0.2, 0.3, 0.4]:\n",
        "    oof_blend = (1 - w) * oof_cb + w * oof_xgb\n",
        "    auc = roc_auc_score(y, oof_blend)\n",
        "    if auc > best_auc:\n",
        "        best_auc, best_w = auc, w\n",
        "oof = (1 - best_w) * oof_cb + best_w * oof_xgb\n",
        "print(f\"CV AUC: {best_auc:.5f} (blend w_xgb={best_w})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train, y)\n",
        "xgb_model.fit(X_train, y)\n",
        "test_cb = model.predict_proba(X_test)[:, 1]\n",
        "test_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
        "test_proba = (1 - best_w) * test_cb + best_w * test_xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher model using 13 shared columns from original dataset\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 180000, number of negative: 420000\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010319 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 668\n",
            "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300000 -> initscore=-0.847298\n",
            "[LightGBM] [Info] Start training from score -0.847298\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 180000, number of negative: 420000\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 672\n",
            "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300000 -> initscore=-0.847298\n",
            "[LightGBM] [Info] Start training from score -0.847298\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 180000, number of negative: 420000\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010289 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 671\n",
            "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300000 -> initscore=-0.847298\n",
            "[LightGBM] [Info] Start training from score -0.847298\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Adversarial AUC (train vs test): 0.50147\n",
            "Sample weights (train-like vs test-like) -> min=0.350, max=2.793, mean=1.000\n",
            "FOLD 1/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90499\n",
            "[1499]\tvalidation_0-auc:0.95524\n",
            "FOLD 2/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90580\n",
            "[1499]\tvalidation_0-auc:0.95552\n",
            "FOLD 3/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90708\n",
            "[1499]\tvalidation_0-auc:0.95610\n",
            "FOLD 4/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90562\n",
            "[1499]\tvalidation_0-auc:0.95499\n",
            "FOLD 5/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90558\n",
            "[1499]\tvalidation_0-auc:0.95523\n",
            "FOLD 1/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713352\ttest: 0.6713531\tbest: 0.6713531 (0)\ttotal: 121ms\tremaining: 3m\n",
            "1499:\tlearn: 0.2676097\ttest: 0.2682199\tbest: 0.2682199 (1499)\ttotal: 2m 47s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2682199412\n",
            "bestIteration = 1499\n",
            "\n",
            "FOLD 2/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713394\ttest: 0.6713447\tbest: 0.6713447 (0)\ttotal: 122ms\tremaining: 3m 3s\n",
            "1499:\tlearn: 0.2678219\ttest: 0.2673233\tbest: 0.2673233 (1498)\ttotal: 2m 51s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.267323266\n",
            "bestIteration = 1498\n",
            "\n",
            "Shrink model to first 1499 iterations.\n",
            "FOLD 3/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6714011\ttest: 0.6712825\tbest: 0.6712825 (0)\ttotal: 110ms\tremaining: 2m 44s\n",
            "1499:\tlearn: 0.2683232\ttest: 0.2655683\tbest: 0.2655683 (1499)\ttotal: 2m 47s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.265568329\n",
            "bestIteration = 1499\n",
            "\n",
            "FOLD 4/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713478\ttest: 0.6713436\tbest: 0.6713436 (0)\ttotal: 132ms\tremaining: 3m 18s\n",
            "1499:\tlearn: 0.2675293\ttest: 0.2689226\tbest: 0.2689226 (1499)\ttotal: 2m 46s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2689226004\n",
            "bestIteration = 1499\n",
            "\n",
            "FOLD 5/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6714200\ttest: 0.6712798\tbest: 0.6712798 (0)\ttotal: 111ms\tremaining: 2m 45s\n",
            "1499:\tlearn: 0.2676917\ttest: 0.2679777\tbest: 0.2679777 (1499)\ttotal: 2m 46s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2679777122\n",
            "bestIteration = 1499\n",
            "\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955415\n",
            "XGBClassifier CV AUC mean: 0.955416, std: +-0.00038\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955493\n",
            "CatBoostClassifier CV AUC mean: 0.955494, std: +-0.00037\n",
            "\n",
            "Blended (2-model mean) OOF AUC: 0.955548\n",
            "Submission: 2-model blend. test_proba shape: (270000,)\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import inspect\n",
        "\n",
        "SEED = 42\n",
        "NSPLITS = 5\n",
        "\n",
        "# Reload data Kaggle-style (lowercase columns, id as index)\n",
        "path = DATA_DIR\n",
        "dfs = []\n",
        "for fl in (\"train.csv\", \"test.csv\"):\n",
        "    df = pd.read_csv(path / fl, index_col=0)\n",
        "    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns.tolist()]\n",
        "    dfs.append(df)\n",
        "train, test = dfs\n",
        "\n",
        "ystr = train.columns[-1]\n",
        "base_features = [c for c in train.columns if c != ystr]\n",
        "\n",
        "cols2comb = [\n",
        "    \"exercise_angina\", \"thallium\", \"chest_pain_type\",\n",
        "    \"slope_of_st\", \"sex\", \"st_depression\", \"number_of_vessels_fluro\",\n",
        "    \"ekg_results\", \"fbs_over_120\",\n",
        "]\n",
        "\n",
        "statmetrics = [\"mean\", \"count\"]\n",
        "\n",
        "X = train.drop(columns=ystr)\n",
        "y = (train[ystr] == \"Presence\").astype(int)\n",
        "\n",
        "X_test = test.copy()\n",
        "\n",
        "# Teacher model from original clinical dataset -> prior feature\n",
        "orig_path = DATA_DIR.parent / \"original-data\" / \"Heart_Disease_Prediction.csv\"\n",
        "orig_df = pd.read_csv(orig_path)\n",
        "orig_df.columns = [c.strip().lower().replace(\" \", \"_\") for c in orig_df.columns]\n",
        "orig_ystr = orig_df.columns[-1]\n",
        "orig_X = orig_df.drop(columns=orig_ystr)\n",
        "orig_y = (orig_df[orig_ystr] == \"Presence\").astype(int)\n",
        "\n",
        "common_cols = sorted(set(orig_X.columns) & set(X.columns))\n",
        "print(f\"Teacher model using {len(common_cols)} shared columns from original dataset\")\n",
        "\n",
        "teacher = cb.CatBoostClassifier(\n",
        "    iterations=400,\n",
        "    depth=4,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.9,\n",
        "    colsample_bylevel=0.9,\n",
        "    random_seed=SEED,\n",
        "    verbose=0,\n",
        ")\n",
        "teacher.fit(orig_X[common_cols], orig_y)\n",
        "\n",
        "X[\"teacher_pred\"] = teacher.predict_proba(X[common_cols])[:, 1]\n",
        "X_test[\"teacher_pred\"] = teacher.predict_proba(X_test[common_cols])[:, 1]\n",
        "\n",
        "# Adversarial validation: train vs test\n",
        "adv_X = pd.concat([X, X_test], axis=0).reset_index(drop=True)\n",
        "adv_y = np.concatenate([\n",
        "    np.zeros(len(X), dtype=int),\n",
        "    np.ones(len(X_test), dtype=int),\n",
        "])\n",
        "adv_skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "oof_adv = np.zeros(len(adv_y), dtype=float)\n",
        "for tr_adv, val_adv in adv_skf.split(adv_X, adv_y):\n",
        "    adv_clf = lgb.LGBMClassifier(\n",
        "        objective=\"binary\",\n",
        "        metric=\"auc\",\n",
        "        learning_rate=0.05,\n",
        "        n_estimators=400,\n",
        "        num_leaves=31,\n",
        "        feature_fraction=0.9,\n",
        "        bagging_fraction=0.9,\n",
        "        bagging_freq=1,\n",
        "        min_data_in_leaf=30,\n",
        "        random_state=SEED,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    adv_clf.fit(adv_X.iloc[tr_adv], adv_y[tr_adv])\n",
        "    oof_adv[val_adv] = adv_clf.predict_proba(adv_X.iloc[val_adv])[:, 1]\n",
        "\n",
        "auc_adv = roc_auc_score(adv_y, oof_adv)\n",
        "print(f\"Adversarial AUC (train vs test): {auc_adv:.5f}\")\n",
        "\n",
        "p_test_train = oof_adv[: len(X)]\n",
        "eps = 1e-3\n",
        "w_train = p_test_train / (1.0 - p_test_train + eps)\n",
        "w_train = w_train / w_train.mean()\n",
        "print(\n",
        "    f\"Sample weights (train-like vs test-like) -> min={w_train.min():.3f}, max={w_train.max():.3f}, mean={w_train.mean():.3f}\"\n",
        ")\n",
        "\n",
        "\n",
        "def get_cat_feature_indices(X_):\n",
        "    return [i for i, c in enumerate(X_.columns) if c.startswith(\"CAT_\")]\n",
        "\n",
        "\n",
        "def fe_foldwise(X_tr, X_val, y_tr):\n",
        "    X_tr = X_tr.copy()\n",
        "    X_val = X_val.copy()\n",
        "\n",
        "    temp = pd.concat([X_tr, y_tr], axis=1)\n",
        "\n",
        "    # casting\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"age>55\"] = (df[\"age\"] > 55).astype(int)\n",
        "        for col in df.columns:\n",
        "            if col == \"teacher_pred\":\n",
        "                continue\n",
        "            colname = f\"CAT_{col}\"\n",
        "            df[colname] = df[col].astype(str).astype(\"category\")\n",
        "\n",
        "    # numeric interactions and derived + bin features (from 0.954 notebook)\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"chest_pain_type_bin\"] = (df[\"chest_pain_type\"] >= 3).astype(int)\n",
        "        df[\"st_depression_bin\"] = (df[\"st_depression\"] >= 2).astype(int)\n",
        "        df[\"number_of_vessels_fluro_bin\"] = (df[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "        df[\"hr_age\"] = df[\"max_hr\"] * df[\"age\"]\n",
        "        df[\"bp_age\"] = df[\"bp\"] * df[\"age\"]\n",
        "        df[\"st_slope\"] = df[\"st_depression\"] * df[\"slope_of_st\"]\n",
        "        df[\"chol_exercise\"] = df[\"cholesterol\"] * df[\"exercise_angina\"]\n",
        "        pred_max = (220 - df[\"age\"]).clip(lower=10)\n",
        "        df[\"max_hr_pct_pred\"] = df[\"max_hr\"] / pred_max\n",
        "        df[\"risk_sum\"] = df[\"number_of_vessels_fluro\"] + df[\"thallium\"] + df[\"exercise_angina\"]\n",
        "\n",
        "    # target statistics + smoothed target encoding\n",
        "    global_mean = float(y_tr.mean())\n",
        "    m_smooth = 20\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            cname = f\"target_{bf}_{s}\"\n",
        "            X_tr[cname] = X_tr[bf].map(stats[s])\n",
        "            X_val[cname] = X_val[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_tr[f\"target_{bf}_smooth\"] = X_tr[bf].map(smoothed).fillna(global_mean)\n",
        "        X_val[f\"target_{bf}_smooth\"] = X_val[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    # categorical combinations\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_tr[c2].max(), X_val[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_tr[cname] = (\n",
        "                (X_tr[c1] + 1 + (X_tr[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "            X_val[cname] = (\n",
        "                (X_val[c1] + 1 + (X_val[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    return X_tr, X_val\n",
        "\n",
        "\n",
        "def fe_test(X_test_, X_train_, y_train_):\n",
        "    X_test_ = X_test_.copy()\n",
        "    temp = pd.concat([X_train_, y_train_], axis=1)\n",
        "\n",
        "    X_test_[\"age>55\"] = (X_test_[\"age\"] > 55).astype(int)\n",
        "    for col in X_test_.columns:\n",
        "        if col == \"teacher_pred\":\n",
        "            continue\n",
        "        colname = f\"CAT_{col}\"\n",
        "        X_test_[colname] = X_test_[col].astype(str).astype(\"category\")\n",
        "\n",
        "    X_test_[\"chest_pain_type_bin\"] = (X_test_[\"chest_pain_type\"] >= 3).astype(int)\n",
        "    X_test_[\"st_depression_bin\"] = (X_test_[\"st_depression\"] >= 2).astype(int)\n",
        "    X_test_[\"number_of_vessels_fluro_bin\"] = (X_test_[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "    X_test_[\"hr_age\"] = X_test_[\"max_hr\"] * X_test_[\"age\"]\n",
        "    X_test_[\"bp_age\"] = X_test_[\"bp\"] * X_test_[\"age\"]\n",
        "    X_test_[\"st_slope\"] = X_test_[\"st_depression\"] * X_test_[\"slope_of_st\"]\n",
        "    X_test_[\"chol_exercise\"] = X_test_[\"cholesterol\"] * X_test_[\"exercise_angina\"]\n",
        "    pred_max = (220 - X_test_[\"age\"]).clip(lower=10)\n",
        "    X_test_[\"max_hr_pct_pred\"] = X_test_[\"max_hr\"] / pred_max\n",
        "    X_test_[\"risk_sum\"] = X_test_[\"number_of_vessels_fluro\"] + X_test_[\"thallium\"] + X_test_[\"exercise_angina\"]\n",
        "\n",
        "    global_mean = float(y_train_.mean())\n",
        "    m_smooth = 20\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            X_test_[f\"target_{bf}_{s}\"] = X_test_[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_test_[f\"target_{bf}_smooth\"] = X_test_[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_train_[c2].max(), X_test_[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_test_[cname] = (\n",
        "                (X_test_[c1] + 1 + (X_test_[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    return X_test_\n",
        "\n",
        "\n",
        "xgboost_params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"auc\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"max_depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"colsample_bytree\": 0.9,\n",
        "    \"n_estimators\": 1500,\n",
        "    \"min_child_weight\": 10,\n",
        "    \"gamma\": 1,\n",
        "    \"reg_lambda\": 0.01,\n",
        "    \"reg_alpha\": 1.5,\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"n_jobs\": -1,\n",
        "    \"random_state\": SEED,\n",
        "    \"early_stopping_rounds\": 80,\n",
        "    \"enable_categorical\": True,\n",
        "}\n",
        "\n",
        "catboost_params = {\n",
        "    \"loss_function\": \"Logloss\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"iterations\": 1500,\n",
        "    \"min_data_in_leaf\": 1,\n",
        "    \"l2_leaf_reg\": 1.002,\n",
        "    \"thread_count\": -1,\n",
        "    \"random_seed\": SEED,\n",
        "    \"early_stopping_rounds\": 80,\n",
        "    \"bootstrap_type\": \"Bernoulli\",\n",
        "}\n",
        "\n",
        "models = {\n",
        "    XGBClassifier: xgboost_params,\n",
        "    CatBoostClassifier: catboost_params,\n",
        "}\n",
        "\n",
        "kf = KFold(n_splits=NSPLITS, shuffle=True, random_state=SEED)\n",
        "\n",
        "oof_train_model = {}\n",
        "oof_test_model = {}\n",
        "cv_auc_model = defaultdict(list)\n",
        "\n",
        "for modelClass, param in models.items():\n",
        "    model_name = modelClass.__name__\n",
        "    oof_train = np.zeros(len(X))\n",
        "    oof_test = np.zeros(len(X_test))\n",
        "\n",
        "    for fold, (tr, val) in enumerate(kf.split(X)):\n",
        "        print(f\"FOLD {fold + 1}/{NSPLITS} - {model_name}\")\n",
        "\n",
        "        X_tr_raw, X_val_raw = X.iloc[tr], X.iloc[val]\n",
        "        y_tr, y_val = y.iloc[tr], y.iloc[val]\n",
        "\n",
        "        X_tr, X_val = fe_foldwise(X_tr_raw, X_val_raw, y_tr)\n",
        "\n",
        "        model = modelClass(**param)\n",
        "        fit_kwargs = {\n",
        "            \"X\": X_tr,\n",
        "            \"y\": y_tr,\n",
        "            \"eval_set\": [(X_val, y_val)],\n",
        "            \"sample_weight\": w_train[tr],\n",
        "        }\n",
        "        if model_name != \"LGBMClassifier\":\n",
        "            fit_kwargs[\"verbose\"] = 2000\n",
        "        if \"cat_features\" in inspect.signature(model.fit).parameters:\n",
        "            cat_features = get_cat_feature_indices(X_tr)\n",
        "            fit_kwargs[\"cat_features\"] = cat_features\n",
        "        model.fit(**fit_kwargs)\n",
        "        oof_train[val] = model.predict_proba(X_val)[:, 1]\n",
        "        X_test_fe = fe_test(X_test, X_tr_raw, y_tr)\n",
        "        oof_test += model.predict_proba(X_test_fe)[:, 1] / NSPLITS\n",
        "        cv_auc_model[model_name].append(roc_auc_score(y[val], oof_train[val]))\n",
        "\n",
        "    oof_train_model[model_name] = oof_train\n",
        "    oof_test_model[model_name] = oof_test\n",
        "\n",
        "# Evaluation per model\n",
        "for modelClass in models.keys():\n",
        "    model_name = modelClass.__name__\n",
        "    print(f\"\\n{model_name} OOF AUC: {roc_auc_score(y, oof_train_model[model_name]):.6f}\")\n",
        "    print(\n",
        "        f\"{model_name} CV AUC mean: {np.mean(cv_auc_model[model_name]):.6f}, std: +-{np.std(cv_auc_model[model_name]):.5f}\"\n",
        "    )\n",
        "\n",
        "# Simple blend: mean of 2 models (no meta-learner)\n",
        "X_oof_tr = pd.DataFrame.from_dict(oof_train_model)\n",
        "X_oof_test = pd.DataFrame.from_dict(oof_test_model)\n",
        "oof_tr_final = X_oof_tr.mean(axis=1)\n",
        "oof_test_final = X_oof_test.mean(axis=1)\n",
        "meta = None\n",
        "\n",
        "stack_auc = roc_auc_score(y, oof_tr_final)\n",
        "print(f\"\\nBlended (2-model mean) OOF AUC: {stack_auc:.6f}\")\n",
        "\n",
        "# Set variables used by later cells\n",
        "oof = oof_tr_final.values\n",
        "test_proba = oof_test_final.values\n",
        "N_STACK_MODELS = len(oof_train_model)\n",
        "print(f\"Submission: {N_STACK_MODELS}-model blend. test_proba shape: {test_proba.shape}\")\n",
        "\n",
        "# Ensure id column exists for submission\n",
        "test[\"id\"] = test.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix (OOF, threshold=0.5)\n",
            "Rows: true, Cols: predicted |  Absence   Presence\n",
            "[[314836  32710]\n",
            " [ 37233 245221]]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAF1CAYAAADBdGLoAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUyBJREFUeJzt3Qd4FFUXBuCTTkLvRXoLHQQREKRIFxApUqWDglSRqkhTQeFXQGkKShOkqCCggEjvVXqR3iFITyB9/+c7OOtu6mbJSDZ8L88+ye7emZ1swp459557x81isViEiIiIXIb70z4AIiIiShgGbyIiIhfD4E1ERORiGLyJiIhcDIM3ERGRi2HwJiIicjEM3kRERC6GwZuIiMjFMHgTERG5GAZvSpZOnTolderUkbRp04qbm5ssW7YsUfd//vx53e/s2bMTdb/JQd68eaVjx46Jus/du3eLt7e3XLhwQZKi1atXS6pUqeTmzZtP+1DoGcHgTaY5c+aMvP3225I/f35JkSKFpEmTRipXriyTJk2SR48emfraHTp0kMOHD8snn3wi8+bNkxdeeMHU10uOjh07JiNHjtQTlaftgw8+kNatW0uePHnsHsfqzvj9Vq1aVdKlSyd+fn5SsmRJGT16tAQFBcW4r4RuU716dT1Ri+l24sQJbVOvXj0pWLCgjB071qR3gMieG9c2JzP8+uuv8sYbb4iPj4+0b99eSpQoIaGhobJ161b56aefNDP75ptvTHltnBjgAxkf+B9//LEpr4H/NiEhIeLl5SUeHh6SHP3444/6O9ywYYMGMEfhfXF3d9f3JjEcOHBAnn/+edm+fbtUqlTJ+nhERIS0adNGFi9eLC+//LI0bdpUf+9btmyRBQsWSLFixeSPP/6QrFmzPtE2+NlxIhpTYH7ttdf0pBSmTZsmAwYMkOvXr0vq1KkT5WcnihWCN1FiOnv2rCVVqlSWIkWKWK5evRrt+VOnTlkmTpxo2utfuHABJ6SW8ePHm/Yaz4IlS5bo+7hhw4Z420ZGRloePnxoynH06dPHkjt3bn0NW2PGjNHjGzBgQLRtli9fbnF3d7fUq1fvibepVq2apXjx4vEe540bNyweHh6Wb7/9NgE/HZFzGLwp0XXv3l0/ILdt2+ZQ+7CwMMvo0aMt+fPnt3h7e1vy5MljGTp0qCU4ONiuHR5v0KCBZcuWLZby5ctbfHx8LPny5bPMmTPH2mbEiBH62rY3bAcdOnSwfm/L2MbW77//bqlcubIlbdq0lpQpU1oKFy6sx2Q4d+6cbjNr1iy77datW2epUqWKxc/PT7d97bXXLMeOHYvx9XASg2NCuzRp0lg6duxoCQoKivf9MoLJwYMHLVWrVrX4+vpaChQooMEWNm7caHnxxRctKVKk0ONeu3at3fbnz5+39OjRQ59DmwwZMliaN2+uP5MBP1fU99E2kBu/i9WrV1vKlSunv4sJEyZYn8PPBQi41atXt2TKlEmDmyEkJMRSokQJ/Z0HBgbG+fMicOO9sYUThfTp0+vPgL+fmHTq1EmPeceOHU5vY/t+O+L555/X3zmR2TjmTYluxYoVOs790ksvOdS+a9euMnz4cClbtqxMmDBBqlWrpl2UrVq1itb29OnT0rx5c6ldu7Z8/vnnkj59eu2CP3r0qD6PblDsAzBGirHNiRMnJuj4sa+GDRtq9y/GQfE66B7dtm1bnNuhu7Vu3boSEBCgY8X9+/fXrl6M88c0btyiRQt58OCB/qz4HsVvo0aNcugY79y5o8dYoUIFGTdunA5P4P1atGiRfn311Vfl008/1TFcvF94HcOePXv0uNDuyy+/lO7du8u6deu0e/jhw4faBuPBffr00e/ff/99fR9xK1q0qHU/J0+e1PcYvwvUMZQpUybacWJc+LvvvpPg4GB9HcOIESP0fZ41a5akTJky1p/zypUrcvHiRf3bsIXhF7wH6AL39PSMcVsM18DKlSud3sa2u/3vv/+2uwUGBkbbvly5cvreEpnO9NMDeqbcu3dPM5fGjRs71P7AgQPavmvXrnaPo1sTj69fv976GDI6PLZ582brYwEBAZr1vffee9Gy4qjd5o5m3sggcf/mzZuxHndMmXeZMmUsWbJksdy6dcv6GLJjdMW2b98+2ut17tzZbp9NmjSxZMyY0RIfZILYfsGCBdbHTpw4oY/htXbu3Gl9fM2aNdGOM6bubWSaaDd37lyHus2N3wUy75ieMzJvw9dff63tv//+ez0+dC/369cv3p/1jz/+0O1WrFhh9ziGXfD40qVLY9329u3b2qZp06ZOb2P7fke9Rf0ZbbvlbXsZiMzAzJsS1f379/WrowU7v/32m35Flmrrvffesxa+2UJBEQqNDJkzZxZ/f385e/asJBZUIMMvv/wikZGRDm1z7do1LaxCL0CGDBmsj5cqVUozU+PntGWbiQJ+rlu3blnfw7hgWpJtzwTeAxw3MmNk4wbje9v3x9fX1/p9WFiYviYqpbH9/v37xVH58uXTngZHvPXWW9q2d+/e0q5dOylQoICMGTMm3u1wbIAeFltGT0Jcf2fGc8b76cw2ttPf1q5da3cbNGhQtO2N40RmTmQmBm9KVEblrW03bVwwbxeVyQgetrJly6bBJOq83ty5c8f4gYnu0MTSsmVL7epGdz6qjhEkUZ0cVyA3jhNBNCoEVHyYR52GFPVnMT74HflZcubMqV3StjCnPVeuXNEei7pPVONjmAJt0d2eKVMmPQm6e/eu3Lt3TxISvBPi22+/1W55zMHHEIHtSUR8ok6KMYJsXH9nUYO1M9sY0LVfq1YtuxtOJGM7zqi/G6LExuBNiR68c+TIIUeOHEnQdo5+2MU2LcuRGY+xvQbGM20hqGzevFnHsJElHjp0SAM6MuiobZ/Ek/wssW3ryD6R/WL+O8bZcVLy+++/ayaZMWNGh3saICHBFzZu3Kh1BIA5+I7AMcV0QmOMveN3ExvjOSPIOrNNQhnHiRMiIjMxeFOiQyEV5sXu2LEj3rZYdAMBA9mYrRs3bmgmGHVRjieBzBb7jCqmVbvQG1CzZk354osvdLESBLv169frnOfYfg6jiCsqLOSBD/O4CrP+6/nbWMQGhXhG8V+VKlWivTeJmT1iWAEnDVj1Dn8fmA/tyGppRYoU0a/nzp2zexzHi54ZzM2O7YRq7ty5+hWv5+w2CYXjNHoyiMzE4E2JDmOBCFTodkYQjgqBHdXJgKpoiFoRjqAJDRo0SLTjwjgruoVtMy8ElaVLl9q1u337drRtjUpqI3OMKnv27Npmzpw5dkEQPRDIbI2fMylAdh41u//qq6+iBTTjZCOmE56E6tatm56koesci/Og2rtLly7x9jI899xz2r2/d+9eu8exsApOAHCyhMV4okKtBLrmMc5esWJFp7dJqH379tktJENklpjnSxA9YZBEdoOuZnRV2q6whmk0S5Yssa59Xbp0ac0C8YGOIIFpYljHGkHw9ddflxo1aiTacWHsevDgwdKkSROdBoXxV6yKVbhwYbtCLUwPQ7c5ThyQUWPq19SpU3WcGdlbbMaPHy/169fXD28EJowtIyhi3BlTx5IKZJWY9oXjQvcwekgwRGB0URtwMoJA/9lnn+lJD8bHX3nlFcmSJUuCXg/TwYzAiPcQ8L68+eab+v6/8847cW7fuHFjPcFCoLftDRgyZIj8+eefenz4GZo1a6Zd+ZgS9v333+vfHv6ObDmzjaPwd4ITw549ezq1fXKEKYL4f+8srGePpZUpBqbUsBNZLJa//vrL0q1bN0vevHl18ZXUqVPrwidfffWV3QIsWDBj1KhRuuCKl5eXJVeuXHEu0hIVpvLgFt9UMWPxFSwOguPx9/fXqUtRp4phoRVMdcuRI4e2w9fWrVvrzxPfIi2Y2oSfEQunYOGVRo0axbpIS9SpaMbCKLaLpcQktkVDYnt/sM+ePXta79+5c0cXI8HCKVgJr27dujrVLKYpXjNmzNCFVDC1K6ZFWmJiu59Lly7pIjR4H6LC1DgsgIMV+eKyf/9+fW0szhNVRESEvm94z/F+Y9EZvDf4e4pt8ZeEbuPoIi3Tpk3TxXnu378fb9tnwaNHjyzi6RfjNDtHb9myZdP9UHRc25yIkjzUH6AQEj0GSRXWX8dCN8YiQc86TLdD745PsQ4iHt4J30FEqIQcm6O9PsYsFvoXu82JKMnDnHDMg8eFZhKziDExLwmKoss1a9Y87UNJejxTiJsTwdvixpKsuDB4E1GSh8VmnmTs1Gy4JGhMy6USpi3o1AXntqNYMXgTEZF5kEE7k0Uz844TgzcREZkHWbdTmTdT77gweBMRkXmYeZuCwTsJwmIWV69e1fWVuUYyEf2XMAEJa7yjuh8rDT4xZt6mYPBOghC4o15ggojov3Tp0iXrojqU9DB4J0HGFY28i3VwaooF0cWN/3vah0Au6sH9+1IwXy6HL+sbPye7zbl6d5wYvJMgo6scgZvBm5zBRS3oSSXakB27zU3B4E1EROZhwZopGLyJiMg8zLxNwVMbIiIyP/N25uagadOmSalSpXS4CDdc2W/VqlV2VzfD1d5w5bxUqVLp1eSiXq744sWLeiVBXDoWV84bOHCghIeH27XZuHGjlC1bVq+wV7BgQb1SXlRTpkyRvHnz6tXQsDIgrpJoy5FjcQSDNxERubScOXPKp59+qtdTx7XfcelaXEr26NGj+vy7774rK1as0MsRb9q0SWf0NG3a1Lo9rmWPwG1cthiXhUVgHj58uLXNuXPntA0uU3zgwAHp16+fdO3a1W49+0WLFkn//v1lxIgReplhXPIY14fH5WIN8R2Lo3hVsaR8NZ6S3ViwRk65s2fy0z4EcuHPn6wZ0z7x1bysn2MVB4mbp0+Ct7eEh0jIznE6Zc32OJD1+vjEv78MGTLI+PHjpXnz5pI5c2ZZsGCBfg8nTpzQa7fjmu4VK1bULB3XuUcgzZo1q7aZPn26DB48WG7evKnXFcf3uC79kSNHrK/RqlUruXv3rl6YBpBply9fXiZPnmxdswPTfnv37q3Xksd7Gt+xOIqZNxERJdlucwQ/nAQYt7Fjx8b5csiiFy5cKEFBQdp9jmw8LCxMatWqZW1TpEgRyZ07twZMwNeSJUtaAzcgY8YJiJG9o43tPow2xj6QteO1bNtgkRvcN9o4ciyOYsEaERGZXLDm7nTBWkyZd0wOHz6swRpjyhhLXrp0qRQrVky7uJE5p0uXzq49AvX169f1e3y1DdzG88ZzcbVBgH/06JHcuXNHTxxiaoPs2thHfMfiKAZvIiIyj7vb45sz2/2zZoEj3ff+/v4aqNE1/eOPP0qHDh10TDm5YvAmIiKXn+ft7e2tFeBQrlw52bNnj0yaNElatmypXdoYm7bNeFHhnS1bNv0eX6NWhRsV4LZtolaF4z5OLHx9fcXDw0NvMbWx3Ud8x+IojnkTEVGyExkZKSEhIRrIvby8ZN26ddbnTp48qVPD0M0O+Ipud9uq8LVr12pgRte70cZ2H0YbYx84ecBr2bbBMeC+0caRY3EUM28iInLpRVqGDh0q9evX18IvXBEN1dyYk41pXChy69Kli07hQgU6AjKqvxEsjeruOnXqaJBu166djBs3Tsefhw0bpvOxjTH27t27axX5oEGDpHPnzrJ+/XpZvHixVqAb8Brorn/hhRfkxRdflIkTJ2rhXKdOnfR5R47FUQzeRETk0t3mAQEB0r59e7l27ZoGSCzYgsBdu3ZtfX7ChAla+Y0FUZCNo0p86tSp1u3R3b1y5Urp0aOHBtKUKVNqEB49erS1Tb58+TRQY542uuMxt3zmzJm6LwO66DG1DPPDcQJQpkwZnUZmW8QW37E4/PZwnnfSw3ne9KQ4z5uSzDzv6iPFzTNFgre3hAdLyMaRT3wcyRUzbyIiMg8vTGIKBm8iIjIPL0xiCgZvIiIyDzNvU/DdISIicjHMvImIyDzsNjcFgzcREZnIyW5zdgzHicGbiIjMw8zbFAzeRESUZK8qRjFj8CYiIvOw2twUfHeIiIhcDDNvIiIyD8e8TcHgTURE5mG3uSkYvImIyDzMvE3B4E1EROZh5m0KBm8iIjIPM29T8NSGiIjIxTDzJiIi07i5uenNiQ3NOJxkg8GbiIhMw+BtDgZvIiIyD2KwM3GYsTtODN5ERGQaZt7mYPAmIiLTMHibg9XmRERELoaZNxERmYaZtzkYvImIyDQM3uZg8CYiIvOw2twUDN5ERGQaZt7mYPAmIiKTlzZ3JnibcTTJB4M3ERGZxg3/nMqiGb3jwqliRERELoaZNxERmYZj3uZg8CYiIvOw2twUDN5ERGQeJzNvCzPvODF4ExFRkus2d67I7dnB4E1ERKZh8DYHq82JiIhcDDNvIiIyDwvWTMHgTUREpmG3uTkYvImIyDQM3uZg8CYiItMweJuDwZuIiEzD4G0OVpsTERG5GGbeRERkHlabm4LBm4iITMNuc3Ow25yIiEwP3s7cHDV27FgpX768pE6dWrJkySKvv/66nDx50q5N9erVo+2/e/fudm0uXrwoDRo0ED8/P93PwIEDJTw83K7Nxo0bpWzZsuLj4yMFCxaU2bNnRzueKVOmSN68eSVFihRSoUIF2b17t93zwcHB0rNnT8mYMaOkSpVKmjVrJjdu3JCEYPAmIiKXDt6bNm3SYLhz505Zu3athIWFSZ06dSQoKMiuXbdu3eTatWvW27hx46zPRUREaOAODQ2V7du3y5w5czQwDx8+3Nrm3Llz2qZGjRpy4MAB6devn3Tt2lXWrFljbbNo0SLp37+/jBgxQvbv3y+lS5eWunXrSkBAgLXNu+++KytWrJAlS5bosV+9elWaNm2asPfVYrFYErQFme7+/fuSNm1a8SnZTdw8vJ/24ZALurNn8tM+BHLhz5+sGdPKvXv3JE2aNE/8OZaj2wJx9/ZL8PaRoQ/l6ow2cunSJbvjQMbr4+MT57Y3b97UzBmBsWrVqtbMu0yZMjJx4sQYt1m1apU0bNhQA2nWrFn1senTp8vgwYN1f97e3vr9r7/+KkeOHLFu16pVK7l7966sXr1a7yPTRi/A5MmP/w9GRkZKrly5pHfv3jJkyBB9XzNnziwLFiyQ5s2ba5sTJ05I0aJFZceOHVKxYkWH3h9m3kRElGQzbwQ+nAQYN3SRxwcBEjJkyGD3+Pz58yVTpkxSokQJGTp0qDx8+ND6HAJnyZIlrYEbkDHjJOTo0aPWNrVq1bLbJ9rgcUDWvm/fPrs27u7uet9og+fRM2DbpkiRIpI7d25rG0ewYI2IiJKsmDLvuCDTRXd25cqVNUgb2rRpI3ny5JEcOXLIoUOHNIvGuPjPP/+sz1+/ft0ucINxH8/F1QYB/tGjR3Lnzh3tfo+pDbJrYx/I4tOlSxetjfE6jmDwJiKiJFttjsCdkO77nj17arf21q1b7R5/6623rN8jw86ePbvUrFlTzpw5IwUKFBBXw25zIiIyjZs42W3uxETvXr16ycqVK2XDhg2SM2fOONtibBpOnz6tX7Nlyxat4tu4j+fiaoOTC19fX+2S9/DwiLGN7T7QvY5x8tjaOILBm4iIXLra3GKxaOBeunSprF+/XvLlyxfvNqgWB2TgUKlSJTl8+LBdVTgq1xGYixUrZm2zbt06u/2gDR4HdIeXK1fOrg268XHfaIPnvby87Nqg+x7T1Iw2jmDwpkQX/vcRCTmxUIIPfaO3kL9+lIj7F2yePyohp5Y+fv7AFLGEh8S6L0tkxON9HZgikQ9v2j0Xcf+i7lv3c/hbCT23SiJD7lufjwy8KiGnfpLgwzMl+OB0CTk+X8IDDkR/jdBACb2w9t92J36QyIf//gemp+ub6dOk/POlJEuGNHqrVqWSrFm9Sp+7ffu2vNu3t5Qq7i/pU/tKofy5pX+/PtaCJZg3Z7b4ernFeDM+qDFtqEO7NlKyWGHx83aXAf37xXgsP/24REqXKCLpUqWQF8qUlNWrfvuP3oVksMKaM7cEdJV///33WsGNud4YO8YN49CArvGPPvpIi8XOnz8vy5cvl/bt22sleqlSpbQNppYhSLdr104OHjyo07+GDRum+zbG2TEv/OzZszJo0CAdw546daosXrxYp34ZME1sxowZOtXs+PHj0qNHD52y1qlTJ30eRXddunTRdughwDHhOQRuRyvNXWrMGxPjMbcOBQFRB/opaXHzSimeOSqKm086EYtIxJ0TEnbuN3Er3ELcfTOKRIaLR5rcImlyS/i1nXHuK/zqdt2fJfiW3eMI0tinR+bS4pGntkhEqIRd2Sph51eJj3/Lx43cvcQzU0lxS5FRv7cEXZOwyxv/eby4NrGEB0vIqZ/FI/Vz4p2/kYinr1hC7op4xF0UQ/+d53LmlI/GfCoFCxbSDOv7eXPkjaaNZeeeP/X+tWtXZexn/5OiRYvJxYsXpHfP7vrYD4t+1O2bt2gptevWs9vnW1066kIZmE4EoSEhkilTZhkydJh8NWlCjMexY/t26fBmaxn9yVh59dWGsmjhAmnR7HXZsXu/FLcpjKL/foW1adOmWaeD2Zo1a5Z07NhRM+I//vhDp4khkKKCHQujIDgb0N2NLncEWwTSlClTSocOHWT06NHWNsjoMVUMwXrSpEnaNT9z5kytODe0bNlSp5ZhfjhOIDA9DdPIbIvYJkyYoFXoOIaQkBDdHicCLj3PG6XyVapUkXr16umb9CwG7+Q4zxtZrWeOl8Qz4+PuJ4h4cEXCziwTnxJdxc0zerBEth5+ZZt45asnoSd+EG8Ef7/Mj5+7e1rCzq8Vn9Ldrf/JI+6d04D++DGPGI8D2bm4e4o3Ar6IhF3dIZFB18SnUMIWSEjqkvs87xxZMsiYT8dLx85dYsyOO3d4U27dCxJPz+j5CT5YC+R5TqZ/8620ebNdtOfr1KwupUqXkf99YT8f+M02LeVhUJD8/MtK62NVK1eU0qXLyFdTp0tykdjzvPO8s0TcfZyY5x3yUC5MfeOJjyO5SnLd5t9++61OZt+8ebNOlifXZrFESsSdUyKRYeKe0vFiDEvYQwm7tEG88tQScYv+Aezmm0W71SJuH9fXsESESMSdk+KeOlesgRvd7gjU7qme+/exe+fE3S+LhJ5bLcFHvpOQk4sk/NbjOZ2U9GAazuJFCzV7qlAx5vHB+/982McUuGH+93N1+csmzR4vkOGoXTt3SI1X7Of41q5TVx+npzvm/SxKUsE7MDBQl5ZDtwWWoItpzdht27bpGAXWjMX4gO1KNxcuXJBGjRpJ+vTptcujePHi8ttv/45JoW39+vV1LVl0YWBs4++//7Y+jy6XPn366HgGJvej8m/kyJF2r48Kwbffflu3xzFgHiG6WgyYnvDyyy9r5SG6ZrC/qEv0RYVuE5yl2t5cXeSjWxJ86GsJOThdwi5tFK989cU9hf2CCbFBZ1DYxXXimbGEBtaYuPukEe8Cr2m3O14j5PBMsYQGiVeef7uvDMFHZ0vwwWkS+tcS7Ua3zf4tofcl4u8j4uaTVrvNPTKWkPDLWyTi9uM5mZQ0HDl8WDKlSyVpU/pIn57dZdGPS6XoP0VEtvD/eeyYj6Rz13+nBUU1Z9a30rJVG/0/mhA3rl+XLFHm72bJklVu3HB8bu6zCDHY2Ru5SPDGwD9WmvH395c333xTvvvuO/0gt4WF4j///HPZs2ePLjGHYI3VagCFBQiEyNpRNfjZZ59poDaC7iuvvCLPP/+87N27V8cgUJrfokULu/2jyACBf9euXbruLcY7UE1oVA0i+OMEAsURx44dk08//VTHSoyiCHT3YxwDiwDgRATBHFWQccGKQbYrCCHouzqMd3v7txTvws3FI1MJCbuwTiKDbzu0bcTfh8QSGSYeWcvG2sYSFqSZuUeGIuJd+A3xLthExM1dws6vjvY3412wqXa5e+aqJuE3D0rEnb9s9yRuvpnFK0cl7ZLHWLhHxmJadEdJR2F/f9m194Bs3rZLur3dQ7p17iDHjx2za4OT3iavNdCx72HD7U+6DTt37JATx49Lh07Ru9vJHI8DsTOZ99M+8qTNM6l1mSNoA4IgxjqwNq1tEQIWe69du7Y10KJgANMDEIRRao/AiQn4kD9/fut2WGcWgXvMmDHWx3BygED5119/SeHChfUxZPV4DShUqJBuh5J+vCYKHnB1GFQQGu1tXwNBuG3btrq6j7H9l19+KdWqVdOCCmTqMcEyfag8tP0QcvUA7ubu8bhgDWeIflnE8jBAIm4eFPdcNeLdNvLBFbEEXdeM2hYyZ/f0hcU7T63HwdXdR7xyvGR9HuPYIcfmiOXhDXGz6aJHlq5fUSwX9kjCr+8Rj/SPf3/i6SfuKdLbH3uKDGK5d/bJ3gBKVCg4KlCwoH5ftlw52bd3j0z5apJMnva1PvbgwQN5rUE9rTRGVo6pODGZ/d1MHaPGPhIqa7ZsEhBl/m5AwA3JmtXx4aBnkrNZNIO3awRvzHNDYEQgBoxXoWoPAd02eNvOg0PXNrJ0BFNAFzW63H///XddNxaB3JgGgNJ/lOUbmbgtZMy2wdsW5gAa00kwLxAnC0bbqPAayLixfq4BWSAydlyNBgvPx8SRhfZdn0UskZEOtfTK+bJYIirYZ9lnV4hX3rri7vdPt2VkWPT/3NZPCEs8xxFhveeeMrtEorrctkXIXXHzSu3QsdLTgf9T6GUzTnYbvVpX/w/9uHR5rCfJGJb76cfFMvrj+NfGjgnG2DduWCe9+/47jWzdH2tjHXunx3g972QevBGkcd1UrDtrG/jwH9K4Okt8cGk2lNyjSh0BHJkwuthRAIf/uOhiR1d6VMYkfYh6xo4/IHxQQHxjZHgNjIfjJCIqLDr/rEAFt0eaPCJeqTTIops6MvCKeBV4zRqMUZBmCX08FxfTwCzuXuLmnVrcPFM8/mqzv0j3x78TN+804ub9+OTLPU1ezeSRRbunLyQSEfZ42plXau0Gh/Cbh7W92z+ZNeZ9hwf8KR6Z/z1B88xSWkL/+lnCb+wV93QFH/cQ3DoqXjntp5zQ0/PhB0Olbr36kitXbs2wMUVr86aNsuK3NRq4G9avI48ePpRZc763qxnBsJoxpAU/Ll6knzGt2z7u3Yvq4D+LdgQFBsrfN2/qfWT8xth6z159pU7NajJxwudSv34DWbJ4oezft1emTPvmP3kfiJJc8MZ/qLlz52qgxUR5W7io+g8//KBj4YDrtRqBENPG0OVtm9GiuxkT6XFDdzQmyyN44+LpP/30k14gPbYq1PggK798+bJdN7stvAbGwXGB9mda+CMJvfCHSHiQzpd2T5FRA7dH6lzWRVoibuyxNg89/U9vS65XxDNjzL0TUXmkzimSp46EB+zXG+ZuIyv3LtBI3NyN369FAzqK0lDe4eaTRqereWR8PMcbsA2K6cKv7ZDw63v1BMHzuSrikcE/Ud8Sct7NgADp0qm9XL92TWtCSpQspYG7Zq3aGsT37N6l7YoXsf9/d+LUOcmTN6/1/uxZ30rj15vGOtW0Yvnnrd/v379PTxJy58kjJ0+f18cqvfSSzJ63QEaNGCYjhr0vBQsVksU/LeMc73g4W3zGxNsF5nkvW7ZMu8jRPY3/nLZw5Rcsdzd+/Hid540KckyOR7X3Bx98oF3Zp06d0jNkjDWjoAyBFYH9nXfe0avIoHAM084wWR7jz0Y1Oda0XbhwoU6yxxl6TNd7xckD/rMble84BlS0fvHFFxqkscoOsnOM0aPLHBXwnTt31l4AFL4hmKPgzdHeg+Q6z5v+W8l9nje5zjzvwv1/Fg+flAnePiIkSP76oinneSflanN0mWOMOmrgBoxbozocgRFQ3d23b19dHxar16xYsUIDtzEHFBXnyMQRTBHEjVVr0B2PKnG0QXaPojYEewRmrHTjKGTvuNB669atdSk9nAhgn0ZmjgI7ZOaYLoYCOayyYzsUQET0LOFUsWSceZM9Zt70pJh5U1LJvIsMWOp05n3if02YeSflMW8iIkqeOOadjLvNiYiIyHHMvImIyDSc520OBm8iIjINg7c5GLyJiMg0HPM2B4M3ERGZxk2czLy5uHmcGLyJiMg0zLzNweBNRESm4Zi3OThVjIiIyMUw8yYiItOw29wcDN5ERGQadpubg8GbiIhMw8zbHAzeRERkGmbe5mDwJiIi8zh7eU/G7jix2pyIiMjFMPMmIiLTsNvcHAzeRERkGhasmYPBm4iITMPM2xwM3kREZBpm3uZg8CYiItMw8zYHq82JiIhcDDNvIiIyDTNvczB4ExGRaTjmbQ4GbyIiMg0zb3MweBMRkWmYeZuDwZuIiEzDzNscDN5ERGQahGCnMm8zDiYZ4VQxIiIiF8PMm4iITOPu5qY3Z7aj2DF4ExGRaViwZg4GbyIiMg0L1szB4E1ERKZxd3t8c2Y7ih2DNxERmUe7zVlunthYbU5ERC5t7NixUr58eUmdOrVkyZJFXn/9dTl58qRdm+DgYOnZs6dkzJhRUqVKJc2aNZMbN27Ytbl48aI0aNBA/Pz8dD8DBw6U8PBwuzYbN26UsmXLio+PjxQsWFBmz54d7XimTJkiefPmlRQpUkiFChVk9+7dCT6W+DB4ExGR6QVrztwctWnTJg2GO3fulLVr10pYWJjUqVNHgoKCrG3effddWbFihSxZskTbX716VZo2bWp9PiIiQgN3aGiobN++XebMmaOBefjw4dY2586d0zY1atSQAwcOSL9+/aRr166yZs0aa5tFixZJ//79ZcSIEbJ//34pXbq01K1bVwICAhw+FofeV4vFYknQFmS6+/fvS9q0acWnZDdx8/B+2odDLujOnslP+xDIhT9/smZMK/fu3ZM0adI88edYnQnrxcs3VYK3D3sUKL+/+4pcunTJ7jiQ8fr4+MS57c2bNzVzRmCsWrWq/iyZM2eWBQsWSPPmzbXNiRMnpGjRorJjxw6pWLGirFq1Sho2bKiBNGvWrNpm+vTpMnjwYN2ft7e3fv/rr7/KkSNHrK/VqlUruXv3rqxevVrvI9NGL8DkyY//D0ZGRkquXLmkd+/eMmTIEIeOxRHMvImIyPSCNWdugMCHkwDjhi7y+CBAQoYMGfTrvn37NBuvVauWtU2RIkUkd+7cGjABX0uWLGkN3ICMGSchR48etbax3YfRxtgHsna8lm0bd3d3vW+0ceRYHMGCNSIiSrJTxWLKvOOCTBfd2ZUrV5YSJUroY9evX9fMOV26dHZtEajxnNHGNnAbzxvPxdUGAf7Ro0dy584d7X6PqQ2ya0ePxREM3kRElGQXaUHgTkj3fc+ePbVbe+vWrZKcsduciIiShV69esnKlStlw4YNkjNnTuvj2bJl0y5tjE3bQoU3njPaRK34Nu7H1wYnF76+vpIpUybx8PCIsY3tPuI7FkcweBMRkelrmztzc5TFYtHAvXTpUlm/fr3ky5fP7vly5cqJl5eXrFu3zvoYppJhalilSpX0Pr4ePnzYrioclesIzMWKFbO2sd2H0cbYB7rD8Vq2bdCNj/tGG0eOxRHsNiciIpde27xnz55avf3LL7/oXG9j7BgFbsiI8bVLly46hQtFbAjIqP5GsDSquzG1DEG6Xbt2Mm7cON3HsGHDdN/GOHv37t21inzQoEHSuXNnPVFYvHixVqAb8BodOnSQF154QV588UWZOHGiTlnr1KmT9ZjiOxZHMHgTEZFLr20+bdo0/Vq9enW7x2fNmiUdO3bU7ydMmKCV31gQJSQkRKvEp06dam2L7m50uffo0UMDacqUKTUIjx492toGGT0CNeZpT5o0SbvmZ86cqfsytGzZUqeWYX44TgDKlCmj08hsi9jiOxaH3h/O8056OM+bnhTneVNSmefdeOomp+d5//JOtSc+juSKmTcREZmG1/M2BwvWiIiIXAwzbyIiMg3yZ2dyaObdcWPwJiIily5YexYxeBMRkWls1ylP6HYUOwZvIiIyDTNvczB4ExGRqRiHEx+DNxERmYaZdxKaKrZlyxZ58803dRWaK1eu6GPz5s1L9ldxISIicsng/dNPP+lSblgv9s8//9Sl3QCr4IwZM8aMYyQiIhcvWHPmRokYvD/++GOZPn26zJgxQ6+MYsCFz/fv35/Q3RER0TPQbe7MjRJxzBuXLqtatWq0x7GGbdTrkxIR0bONi7QkkcwbFws/ffp0tMcx3p0/f/7EOi4iIkoG/ovreT+LEhy8u3XrJn379pVdu3Zpt8bVq1dl/vz5MmDAAL2UGhERUdTreTtzo0TsNh8yZIhERkZKzZo15eHDh9qFjguVI3jjguJERESUxII3su0PPvhABg4cqN3ngYGBUqxYMUmVKuHXayUiouSN87yT2CIt3t7eGrSJiIhi42wXOGN3IgfvGjVqxHlGtH79+oTukoiIkilni89YsJbIwbtMmTJ298PCwuTAgQNy5MgR6dChQ0J3R0REyRgz7yQSvCdMmBDj4yNHjtTxbyIiIgPHvJP4hUmw1vmLL74o//vf/xJrl8+8s+vGSZo0aZ72YZALKjrw16d9COSiIkMePu1DoP8yeO/YsUNSpEiRWLsjIqJkspiI+3911axnSIKDd9OmTe3uWywWuXbtmuzdu1c+/PDDxDw2IiJycew2TyLBG2uY23J3dxd/f38ZPXq01KlTJzGPjYiIXJybk1cIY+xOxOAdEREhnTp1kpIlS0r69OkTsikRET2DnL28Jy8JmojDCh4eHppd8+phRETkCF4S1BwJrgkoUaKEnD171pyjISKiZMXIvJ25USIG748//lgvQrJy5UotVLt//77djYiIiJLImDcK0t577z159dVX9f5rr71m162BqnPcx7g4ERERcIW1pxy8R40aJd27d5cNGzaYdChERJTccG3zpxy8kVlDtWrVTDoUIiJKbrhISxKYKsbqPyIiSgh2myeB4F24cOF4A/jt27ef9JiIiCiZcBcnu82F0TvRgjfGvaOusEZERERJOHi3atVKsmTJYt7REBFRssJu86ccvDneTURECcXlUZNItTkREVHCLkzizFXFTDmcZy94R0ZGmnskRESU7LDbPIlcEpSIiMhR7DY3B+fBExERuRhm3kREZBq3f/45sx3FjsGbiIhMw25zczB4ExGRaRi8zcExbyIiMg3WCHH2lhCbN2+WRo0aSY4cOXTbZcuW2T3fsWPHaPuvV69etOW927ZtK2nSpJF06dJJly5dJDAw0K7NoUOH5OWXX5YUKVJIrly5ZNy4cdGOZcmSJVKkSBFtU7JkSfntt9+iTb0ePny4ZM+eXXx9faVWrVpy6tSpBP28DN5ERGR65u3MLSGCgoKkdOnSMmXKlFjbIFhfu3bNevvhhx/snkfgPnr0qKxdu1ZWrlypJwRvvfWW9fn79+9LnTp1JE+ePLJv3z4ZP368jBw5Ur755htrm+3bt0vr1q018P/555/y+uuv6+3IkSPWNgj4X375pUyfPl127dolKVOmlLp160pwcLDDPy+7zYmIKMlCwLTl4+Ojt6jq16+vt7hgu2zZssX43PHjx2X16tWyZ88eeeGFF/Sxr776Sl599VX53//+pxn9/PnzJTQ0VL777jvx9vaW4sWLy4EDB+SLL76wBvlJkybpScLAgQP1/kcffaQnA5MnT9Zgjax74sSJMmzYMGncuLG2mTt3rmTNmlV7C7AMuSOYeRMRkemLtDhzA3RN44JYxm3s2LFOH8vGjRv1+hz+/v7So0cPuXXrlvW5HTt2aFe5EbgB3dnu7u6aHRttqlatqoHbgIz55MmTcufOHWsbbGcLbfA4nDt3Tq5fv27XBj9XhQoVrG0cwcybiIhMg6VRnbok6D/bXLp0ScegDTFl3Y5ANty0aVPJly+fnDlzRt5//33N1BEwPTw8NKBGvfCWp6enZMiQQZ8DfMX2tpAxG8+lT59evxqP2bax3YftdjG1cQSDNxERJdlqcwRu2+DtrFY23dEoIitVqpQUKFBAs/GaNWuKq2G3ORERmcfZLnOTp4rlz59fMmXKJKdPn9b7GAsPCAiwaxMeHq4V6MY4Ob7euHHDro1xP742ts/bbhdTG0cweBMRkWncxc3pm5kuX76sY96YrgWVKlWSu3fvahW5Yf369XpRLoxHG21QgR4WFmZtg2I0jKGjy9xos27dOrvXQhs8Duh2R5C2bYOiPIyrG20cweBNRERJtmDNUYGBgVr5jZtRGIbvL168qM+h+nvnzp1y/vx5DZyo9C5YsKAWk0HRokV1XLxbt26ye/du2bZtm/Tq1Uu721FpDm3atNFiNUwDw5SyRYsWaXV5//79rcfRt29frVr//PPP5cSJEzqVbO/evbqvx++Hm/Tr108+/vhjWb58uRw+fFjat2+vr4EpZY7imDcREbm8vXv3So0aNaz3jYDaoUMHmTZtmi6uMmfOHM2uESgxXxvTuGwL4DAVDEEWY+CoMm/WrJnOx7atCv/999+lZ8+eUq5cOe12x2IrtnPBX3rpJVmwYIFOBUNRXKFChXQKWIkSJaxtBg0apPPSsR2Op0qVKhrwsaiLo9wsmHRGSQq6UPBHciXgTqIUatCzp+SQVU/7EMhFRYY8lIvTWsi9e/ee6PPH+Bz7Yu0h8U2ZOsHbPwp6IP1rl3ri40iumHkTEVGSnSpGMWPwJiIi0zgzfm1sR7Fj8CYiItNo5bgzmTev5x0nBm8iIjINM29zcKoYERGRi2HmTUREpmaIzmSJzCzjxuBNRESmwaIkuDmzHcWOwZuIiEzj7DLlDN1xY/AmIiLTcJ63ORi8iYjIVAzDiY81AURERC6GmTcREZmG87zNweBNRESmYbW5ORi8iYjINJznbQ4GbyIiMg0zb3MweBMRkWk4z9scDN5ERGQaZt7m4LACERGRi2HmTUREpmHBmjkYvImIyDTsNjcHgzcREZmGBWvmYPAmIiLTcIU1czB4ExGRadzFTW/ObEexY00AERGRi2HmTUREpmG3uTkYvImIyDRu//xzZjuKHYM3ERGZhpm3ORi8iYjINMignSk+Y+YdNwZvIiIyDTNvc7DanIiIyMUw8yYiItMw8zYHgzcREZmG1ebmYPAmIiLTuLs9vjmzHcWOwZuIiEzDzNscDN5kupnfTJOZ33wtFy+c1/tFihWXIe8Pkzp168uF8+elRJECMW43d/5CadLsDTl86KB8Mf4z2bF9m9y69bfkzpNXunR7W97p1cfadvu2rTL8g6Hy118n5NHDh5Irdx7p3PUt6dWnn0PHQUnH3d2L5eGZHRJ2+7K4eXqLT/aikqFKR/HKkDNaW4vFIgHLRsqjC/skc8MPJGXBStbnzk9sGK19pvoDJZV/Nf0+6PR2eXDoNwm9eVYsEWHinSG3pKvYRnzzlkvQsTw4vFoCT2yU0JtnxBL6SHJ1XygeKVKZ8M64Jo55J8Pg3bFjR5kzZ45+7+XlJblz55b27dvL+++/L56ePK9ILnI8l1NGfTxGChQspB+2C+bNlVbNm8i2XfuksH8ROX3+il37Wd/OkEkT/ie1/wmqf+7fJ5mzZJGZs+bKczlzya6d26VPz+7i4eEhb/foqW1Spkwpb/d4R0qULCV+fillx/at0rdXD/Hz89MgHt9xFC1W/Cm8MxST4CtHJHWpBuKTrZBIZITc2TZXri/9UJ5rP03cvVLYtb3/5y9xXjsyY+1+dsHY3Sflv69z+Yj45i4j6V9qr48HHvtDbiz/SLK3+lx8shRw+Fgiw0L0NXC7u+3x5xlFvSSoM5k3xeWpR8h69erJrFmzJCQkRH777Tfp2bOnBvKhQ4fatQsNDRVvb++ndpzkvFcbNLK7P2L0x/LtjOmye9dODZpZs2Wze37F8mWacadK9Th7ad+xs93z+fLn122XL1tqDd6lyzyvN0OevHll+S9LZce2rdbgHd9xUNKQrclou/uZ6rwrl75pK6E3TkuKnCWsj4cEnJX7+5dK9tYT5fKMdjHuC0HZM2X6GJ/LWP3x34UhfeUO8vDMLnl0drc1eDtyLGnLNtavjy4dcurnJXLJed4+Pj6SLVs2yZMnj/To0UNq1aoly5cv16z89ddfl08++URy5Mgh/v7+2v7SpUvSokULSZcunWTIkEEaN24s588/7gaFjRs3yosvvqiZGNpUrlxZLly4YH3+l19+kbJly0qKFCkkf/78MmrUKAkPD7c+7+bmJjNnzpQmTZpo1laoUCE9HltHjx6Vhg0bSpo0aSR16tTy8ssvy5kzZ6zPY/uiRYvqaxQpUkSmTp1q8rvoOiIiIuTHxQslKChIKlT8t4vTgCz70MED0QJ2VPfv3ZP0GWL+UIaDB/6UXTt3SOWXqzp1HJR0RIYG6Vd3m67oyLBg+Xv1eMlYo0eswRlub5gmF6e3kas/vCsPjv6uPS6xsVgiJTLskd3rOHIs5FjBmjM3SsKZd1S+vr5y69Yt/X7dunUaINeuXav3w8LCpG7dulKpUiXZsmWLdq1//PHHmr0fOnRI3N3dNeB369ZNfvjhB83Wd+/erQEZsA265b/88ktrwH3rrcdn3yNGjLAeAwL6uHHjZPz48fLVV19J27Zt9QQAJwtXrlyRqlWrSvXq1WX9+vV6fNu2bbOeAMyfP1+GDx8ukydPlueff17+/PNPPR6cTHTo0CHGnxm9DrgZ7t+/L8nN0SOHpWa1yhIcHKwZ9YLFP0mRosWitZs7+zvxL1JUKlZ6KdZ97dyxXX76cbH8uHRFtOf8C+SWv2/e1N/H+8NGSMfOXZ06DkoaEFBvb5ohPjmKiXemvNbHb2+aqePPfgUqxrptukptJUWu0uLm6SPBF/6UW+uniSU0WNI8/1qM7e/v+1nHrFMWfjlBx0JxY8GaOZJM8MYZMYL1mjVrpHfv3nLz5k0NeMhije7y77//XiIjI/UxIyCjyx0ZNjLuF154Qe7du6dZcYECj7u9kAHbBuUhQ4ZYgygy748++kgGDRpkF7yR9bdu3Vq/HzNmjAZ7nATgJGHKlCmSNm1aWbhwoXbvQ+HCha3bYj+ff/65NG3aVO/ny5dPjh07Jl9//XWswXvs2LF6bMlZocL+sm33fs2Yl/38k7zdtZOsXrvBLnA+evRIliz6QQYNHRbrfo4dPSKt3mgiQz8YLjVr14n2/Jo/NklQUKB2hY/48H3JX6CAvNGydYKOg5KO2+unSejfFyR7i3HWx9C1HXz5oORo82Wc26ar8O/vHd3gkeHBcm/fzzEGbxSc3d35g2R57UPx8Evn8LFQ/FiwlkyD98qVKzUDQlaNwNymTRsZOXKkjn2XLFnSbpz74MGDcvr0ae2qtoUsCll0nTp1NPAiO69du7Z2waOLPXv27NbtkSWjK962+xTbP3z4ULvJoVSpUtbncQKB7DogIEDvHzhwQLN2I3DbQhcsjqNLly6abRuQBSLgxwbj+/3797fLvHPlyiXJCX6PBQoU1O+fL1tO9u/bK1MnfylfTplubbPs5x/199C6bczjlyeOH5OG9WtLp87dZNDQD2JskzdfPv1avERJuRkQIGM+Hm0XvB05Dkoabm2YJg/P7ZFsb3wqnqkzWR9/dOmghN+9LhentbRrf/PXsXI/RzHJ/sanMe7PJ5u/3Nu1UCzhYeLm+e//38CTm+TWH19J5gZDtIAtIcdCjhasObcdJeHgXaNGDZk2bZp+qGJs27bKHIHTVmBgoJQrV067pqPKnDmzNRPv06ePrF69WhYtWiTDhg3TbveKFSvq9shwjazYFsanDVEDM7J8nFgY3fqxwf5hxowZUqFCBbvnUBkd17g/bs8SvJ+2QwUwd/YsebVhI+vv0tbxY0elQb1a0ubN9lpo5uhrhEZ5DUeOg55+L9ztjdPl4ekdkq35WPFKa1/QmLb8G5K6hH2vy9Xve0mGql3FN/+Lse4XU8LcfVLZB+4Tm+TW2kmS+dVB4pevfIKPheKHK4q5O5FGO3MlsmfJUw/eCNAFCz7OhOKDQjME5CxZsmg2HBuMNeOGjBbj4wsWLNDgje1Pnjzp8OvFBFk5prehpyBqkM+aNauegJw9e1bHyemxEcPel9p160muXLklMPCBLF74g2zZvFGWrVhlbXPmzGnZtnWz/PTLyhi7yhG4a9WqI737vCs3rl/Xx909PKyB/pvpUyVnrlw69Qy2bdksX078XLq/0ztBx0FPH4rMEFSzvjZM3Lz9JDzojj7u7uMn7p4+jwvUYihS80id2RpcH57dJREP72q2jfnZjy4ckHu7F0uack3tusr//n2CZKj2lnhn8//3dTy9rVPK4jsWwGMRQXck/N41vR9267yEe/mJZ5rM4pHCvpeQKNlUmycEAmKmTJm0whzFZ+fOndOxbmTaly9f1vsI2Dt27NACs99//11OnTplHfdGIdncuXM1+0bF+PHjx3XsGtm5o3r16qXd2q1atZK9e/fq/ufNm6cnBYB9Ywwb4+R//fWXHD58WHsDvvjiC3lW3bwZIG936ShlSxXVbm90VSNgvlKrtrXNvNmz5LnnckrNWtHHsTE2jSK0hT/Ml4J5n7PeqleuYJdBj/zwA6n8Ylmp9tKLMuPraTL6k7EybMSoBB0HPX1YOMUSGiTXfxyqU8CMW9DJLY7vxN1THhz8Va4tGihX5/eRB4dXaWaermJru8VVMHcbAdr2dW5t/CZBx4I21xb00a53uL5kiN7H2Dz9223uzC0hNm/eLI0aNdIECr2ly5Yti9aLghiAYVT0oGJYFZ/ftm7fvq1xBskhaqkwBGr0qBpQHI2hU/TWYngTxc1RLVmyRGcaoQ2GfzENOqHHkuQz74TAmDR+QYMHD9au7wcPHshzzz0nNWvW1DcbBU8nTpzQzBgV63hjMHb+9ttv6/YYC8cY++jRo+Wzzz7TzBlvcNeu9hXJccmYMaNWmQ8cOFCqVaum3eFlypTRKWmAfeE4UamONuhZwC+vX79/V/p61kz9ema8bUZ+9IneYvL+hyP0Fpfu7/TS25MeBz19efutfOJt/PKW01tcYhsbT+ixpK/UVm/0dAe9g4KCpHTp0tK5c+cYh0YRZJFUIT6gkPjDDz/UmICCYmPYFIH72rVrOtSK3tVOnTrpjCT03gISN9RWIdhOnz5dkzO8HgK9MXNp+/btWvCMJA7F09gWs6D2798vJUqUcPhY4n17LHFNfKSnAn8gKHC7EnAnzuEBotiUHMKhAHJOZMhDuTithc7ceZLPH+NzbN2fFyVl6oTvJ+jBfan5fG5d28P2OBypEXJzc5OlS5dq0ASEOWTk7733ngwYMEAfw8+Hoc7Zs2drTyp6YosVKyZ79uzRmUuA2qlXX31Ve3axPeqzPvjgA7l+/bq1mBozmJDlI3GEli1b6okEEkUDhm2R5CHgO3Isya7bnIiIXMw/U8USejMyb3RN4yTAuCGjTSgMqSLgImM2YF8oLMYwK+ArMmgjcAPaY/2QXbt2WdtgnQ/bWVDImDFseufOHWsb29cx2hiv48ixJLtucyIierZ6zWPKvBMKwRKQ3drCfeM5fEUxtC3MfsLiXLZt0M0ddR/Gc+nTp9ev8b1OfMfiCAZvIiJKshC4OXwYHbvNiYjI9cvN44DrZ8CNGzfsHsd94zl8NRbjsl1gCxXotm1i2ofta8TWxvb5+I7FEQzeRERk+trmzvxLLPny5dPAiCW4bQvqMJaNtUAAX+/evSv79u2ztsHMIkxDNRbdQhvMeEIlugGV6bhwFrrMjTa2r2O0MV7HkWNxBIM3ERGZxpliNWfWQw8MDNTlq3EzCsPw/cWLF7X6HNN1cSErXCUSU7xwkSpUfRsV6VgPBNevwNLWuJYFltLGuh6o/kY7wPLdKFbD/G+sFYJFwyZNmmS3vHXfvn21Sh3XuEAFOpb7xpog2Nfj9yP+Y3EEx7yJiMjl1zbfu3evLrdtMAIqLgiFKVi4ABWmcGE+NjLsKlWqaJC1nVeNpbcRZLF2CKrMmzVrpvOxbavCsfgX1g/BUt1YNAyLrRhzvOGll17Sud1Y/Ov999/Xy0pjKpkxxxscOZZ43x/O8056OM+bnhTneVNSmee96fAlSeXEPO/AB/elWslcT3wcyRW7zYmIiFwMu82JiMg0zhafJWbBWnLE4E1ERKZxpvjM2I5ix+BNREQuX7D2rGHwJiIi8zB6m4LBm4iITMMxb3MweBMRkWk45m0OThUjIiJyMcy8iYjINBzyNgeDNxERmYfR2xQM3kREZBoWrJmDwZuIiEzDgjVzMHgTEZFp2GtuDlabExERuRhm3kREZB6m3qZg8CYiItOwYM0cDN5ERGQaFqyZg8GbiIhMw15zczB4ExGReRi9TcFqcyIiIhfDzJuIiEzDgjVzMHgTEZF5nCxYY+yOG4M3ERGZhkPe5mDwJiIi8zB6m4LBm4iITMMxb3MweBMRkWm4SIs5OFWMiIjIxTDzJiIi03DI2xwM3kREZB5Gb1MweBMRkWlYsGYOBm8iIjI38XamYM2Mg0lGGLyJiMg07DU3B6vNiYiIXAwzbyIiMg3neZuDwZuIiEzEjnMzMHgTEZFpmHmbg8GbiIhMw7zbHAzeRERkGmbe5mC1ORERkYth5k1ERKbhCmvmYPAmIiLzcNDbFAzeRERkGsZuczB4ExGRaViwZg4WrBERkelj3s78c9TIkSPFzc3N7lakSBHr88HBwdKzZ0/JmDGjpEqVSpo1ayY3btyw28fFixelQYMG4ufnJ1myZJGBAwdKeHi4XZuNGzdK2bJlxcfHRwoWLCizZ8+OdixTpkyRvHnzSooUKaRChQqye/duMQODNxERubzixYvLtWvXrLetW7dan3v33XdlxYoVsmTJEtm0aZNcvXpVmjZtan0+IiJCA3doaKhs375d5syZo4F5+PDh1jbnzp3TNjVq1JADBw5Iv379pGvXrrJmzRprm0WLFkn//v1lxIgRsn//fildurTUrVtXAgICEv3ndbNYLJZE3ys9kfv370vatGnlSsAdSZMmzdM+HHJBJYesetqHQC4qMuShXJzWQu7du/dEnz/G59iZK7cktRP7eXD/vhR4LqNcunTJ7jiQ9fr4+ETLvJctW6ZBNSr8HJkzZ5YFCxZI8+bN9bETJ05I0aJFZceOHVKxYkVZtWqVNGzYUIN61qxZtc306dNl8ODBcvPmTfH29tbvf/31Vzly5Ih1361atZK7d+/K6tWr9T4y7fLly8vkyZP1fmRkpOTKlUt69+4tQ4YMkcTEzJuIiEwvWHPmBgh+OAkwbmPHjo3xdU6dOiU5cuSQ/PnzS9u2bbUbHPbt2ydhYWFSq1Yta1t0qefOnVuDN+BryZIlrYEbkDHjBOTo0aPWNrb7MNoY+0DWjteybePu7q73jTaJiQVrRESUZAvWYsq8o0LGi25uf39/7TIfNWqUvPzyy5olX79+XTPndOnS2W2DQI3nAF9tA7fxvPFcXG0Q4B89eiR37tzR7veY2iDTT2wM3kREZCLnFmkxcm8E7vi67+vXr2/9vlSpUhrM8+TJI4sXLxZfX19JjthtTkREpmfeztyclS5dOilcuLCcPn1asmXLpl3aGJu2hWpzPAf4GrX63LgfXxucWOAEIVOmTOLh4RFjG2MfiYnBm4iIkpXAwEA5c+aMZM+eXcqVKydeXl6ybt066/MnT57UMfFKlSrpfXw9fPiwXVX42rVrNTAXK1bM2sZ2H0YbYx/omsdr2bZBwRruG20SE4M3ERG5tAEDBugUsPPnz+tUryZNmmgW3Lp1ay1y69Kli07h2rBhgxaVderUSQMqKs2hTp06GqTbtWsnBw8e1Olfw4YN07nhxhh79+7d5ezZszJo0CAdw546dap2y2MamgGvMWPGDJ1qdvz4cenRo4cEBQXp6yU2jnkTEZFLr7B2+fJlDdS3bt3SaWFVqlSRnTt36vcwYcIErfzG4iwhISFaJY7ga0CgX7lypQZbBPWUKVNKhw4dZPTo0dY2+fLl06liCNaTJk2SnDlzysyZM3VfhpYtW+rUMswPR4FbmTJldBpZ1CK2xMB53kkQ53nTk+I8b0oq87wvXnfucwzb586W/omPI7li5k1ERKbh2ubmYPAmIiLT8Kpi5mDwToKMkYwHD+4/7UMhF+76JHJGZOjjv51EG1Fl9DYFg3cS9ODBA/1apECep30oRPQMfw5hzJqSJgbvJAjr82JJwNSpU+ul7Sh6IQvWO466bCKRI/j3Ezdk3Ajc+BxKDAm9vKftdhQ7Bu8kCFMaMA2B4ubIsolEseHfT+wSM+NmwZo5GLyJiMg0HPI2B4M3ERGZh9HbFAze5HKwXOGIESNivDQgUXz49/Pf4pi3ObjCGhERJTpjhbXrfzu3Qhq2z5YpLVdYiwUzbyIiMg3Wq3Cm+IzrXMSNwZuIiBIdLpGJ61gXypfL6X1ge+yHomO3ORERmSI4OFhCQ0Od3h6BO0WKFIl6TMkFgzf9JzZu3Cg1atSQO3fuSLp06Z724RARuTT3p30AlLzs2LFDr43boEGDp30o5AI6duyoqwjihiyrYMGCeg3l8PDwp31oREkagzclqm+//VZ69+4tmzdvlqtXrz7twyEXUK9ePbl27ZqcOnVK3nvvPRk5cqSMHz8+Wrsn6X4lSm4YvCnRBAYGyqJFi6RHjx6aec+ePTtam23btkmpUqV0HKtixYpy5MgR63MXLlyQRo0aSfr06SVlypRSvHhx+e2336zPo239+vUlVapUkjVrVmnXrp38/fff1uerV68uffr0kUGDBkmGDBm02AWBwNbdu3fl7bff1u1xDCVKlJCVK1dan9+6dau8/PLL4uvrq+tfY39BQUEmvFtkwHxr/K7y5Mmjfzu1atWS5cuXa1b++uuvyyeffKLrbPv7+2t7rEneokULHX7B77lx48Zy/vx5uyGaF198Uf+G0KZy5cr6t2X45ZdfpGzZsvr7z58/v4waNcou00cvwMyZM6VJkybi5+cnhQoV0uOxdfToUWnYsKFOYcI1CPA3c+bMGevz2L5o0aL6GkWKFJGpU6ea/C7Ss4bBmxLN4sWL9YMKH7JvvvmmfPfdd9EuKzhw4ED5/PPPZc+ePZI5c2YN1mFhYfpcz549JSQkRLP2w4cPy2effaaB2gi6r7zyijz//POyd+9eWb16tdy4cUM/xG3NmTNHP7R37dol48aN0y7YtWvX6nORkZEa/HEC8f3338uxY8fk008/1W5+wIcvssBmzZrJoUOH9EQEwbxXr17/0TtIgBMnI8tet26dnDx5Un+HOMnC30rdunU1YG7ZskV/l/gbwe8N2yAII+BXq1ZNf4cYxnnrrbesF/jBNu3bt5e+ffvq7//rr7/Wk0ycINhCQMffFvbx6quvStu2beX27dv63JUrV6Rq1ap60rF+/XrZt2+fdO7c2XoCMH/+fBk+fLju8/jx4zJmzBj58MMP9W+TKNGgYI0oMbz00kuWiRMn6vdhYWGWTJkyWTZs2KD38RV/bgsXLrS2v3XrlsXX19eyaNEivV+yZEnLyJEjY9z3Rx99ZKlTp47dY5cuXdJ9njx5Uu9Xq1bNUqVKFbs25cuXtwwePFi/X7NmjcXd3d3aPqouXbpY3nrrLbvHtmzZots8evQowe8Hxa9Dhw6Wxo0b6/eRkZGWtWvXWnx8fCwDBgzQ57JmzWoJCQmxtp83b57F399f2xrwPP6O8PvF3xT+JjZu3Bjj69WsWdMyZswYu8ewz+zZs1vvY/thw4ZZ7wcGBupjq1at0vtDhw615MuXzxIaGhrjaxQoUMCyYMGCaH+/lSpVSuC7QxQ7zvOmRIHsaPfu3bJ06VK97+npKS1bttQxcHRnGypVqmT9Hl2eyNKRnQC6qNFt+vvvv2vXKTJgdLHDwYMHZcOGDdZM3BYy5sKFC+v3RntD9uzZJSAgQL8/cOCAXq3NaBsVXgOZFjInAz7LkbGfO3dOu0Ep8SGjxu8VWTXe6zZt2uhwB3piSpYsaTfPF7+j06dPa+YddUoS/g7q1Kmj3e3IzmvXrq1/R8ig8XdgbI9s3TbTjoiI0O0fPnyo3eRR/47Qk4Pucdu/I3STe3l5RftZMMSC4+jSpYt069bN+jiycl4bmxITgzclCgRpfEDZXgMYgQ9di5MnT3ZoH127dtUP3V9//VUD+NixY7WLHQVwGE9HFzu60qMyPpgh6gcquksREIzu2LjgNTAejpOIqHLnzu3Qz0AJhymE06ZN0yCNvx+c+NkGzqi/o3LlytmdYBkwDAOzZs3S3yGGVjD0MWzYMO12R40FtkeXeNOmTaNtbzuf2Nm/I+wfZsyYIRUqVLB7zhieIUoMDN70xBC0586dq4EWmY8tjD/+8MMPOhYOO3futAZCzPn+66+/7DJaFIl1795db0OHDtUPQQRvFBj99NNPkjdvXrsP94RANnX58mV9zZiyb7wGxkExXYn+OwjQjr7n+B0hIGfJkiXO9a5RG4Eb/obQ27NgwQIN3tgevURP8jvG3xHGr9FTEDXIoxASJyBnz57VcXIis7BgjRKl2xOBGF2FqN62vaHrG1m5AQVkKEJC5Ti6NzNlyqQBHvr16ydr1qzRLur9+/drN7kR2NGFioKh1q1ba7EbuibRtlOnTtrt6QgUMaHQCMeETAyvs2rVKs3QYPDgwbJ9+3YtUEPXKKYuoTKZBWtJBwIi/mZQYY7iM/wOUV2OTBsnZriPgI1CNVSYowcHv0fj7wiFZDjRRPaNinEM2SxcuFCzc0fh7wEXzWjVqpUWT2L/8+bN05MCwL7Ra/Tll1/qiSKKL9Eb8MUXX5j2vtCzh8GbnhiCM8YWYxrTQ6DEBxzGkgHV3aj0Rdfn9evXZcWKFdYxTQRhBGl80KJ6GNmxMcUG2QzGKtEG2T3GQhHsMRXI3d3xP2Nk7+XLl9eTgGLFium0MiP4I6PatGmTfuBiTBOZGz7sbYcC6OnCmDRmI6D3Bl3f+FvBSSPGrJGJ4/kTJ07o3x3+flBpjr8pDIcAhmVwsomgjr8DZOMTJkzQaWqOypgxo1aZo4scJ4T4W0YPkZGFY/gHU8UQsPF3ijaoaM+XL59p7ws9e7g8KhERkYth5k1ERORiGLyJiIhcDIM3ERGRi2HwJiIicjEM3kRERC6GwZuIiMjFMHgTERG5GAZvIiIiF8PgTeTisMysscQs4CpuWH3uv4ZlSnEBD1x7nYjMxeBNZGJQRTDDDUvA4mIYWNsdF3Ix088//ywfffSRQ20ZcIlcE68qRmQirNGONa5DQkLkt99+03W2sQY2Lp5hKzQ01O661U8C10knouSNmTeRiXA982zZsumFL3r06KEXcFm+fLm1q/uTTz7RC5/4+/tr+0uXLkmLFi30gisIwrh61vnz5637w0VU+vfvr8/jAhm4sErUyxNE7TbHiQOumIbLreJ40AOAi8lgv7iWNqRPn14zcBwX4NrVuDIWLqaB61eXLl1afvzxR7vXwckILv6B57Ef2+MkInMxeBP9hxDokGUDLo2Ky0ji8qS40hWuD42rXqVOnVovd4mrqKVKlUqzd2MbXDMdV6j67rvvZOvWrXqZ1KVLl8b5mu3bt9drquMSlbgE5tdff637RTDHVdYAx3Ht2jWZNGmS3kfgxqUzp0+frpfOfPfdd+XNN9/Uq64ZJxm4qlejRo308qm4ktaQIUNMfveIyApXFSOixNehQwdL48aN9fvIyEjL2rVrLT4+PpYBAwboc1mzZrWEhIRY28+bN8/i7++vbQ143tfX17JmzRq9nz17dsu4ceOsz4eFhVly5sxpfR2oVq2apW/fvvr9yZMnkZbra8dkw4YN+vydO3esjwUHB1v8/Pws27dvt2vbpUsXS+vWrfX7oUOHWooVK2b3/ODBg6Pti4jMwTFvIhMho0aWi6waXdFt2rSRkSNH6tg3rvVsO8598OBBOX36tGbetnCt6jNnzsi9e/c0O65QoYL1OU9PT3nhhReidZ0bkBV7eHjoNaUdhWN4+PCh1K5d2+5xZP+4xjkgg7c9DqhUqZLDr0FET4bBm8hEGAueNm2aBmmMbSPYGlKmTGnXNjAwUMqVKyfz58+Ptp/MmTM73U2fUDgO+PXXX+W5556zew5j5kT09DF4E5kIARoFYo4oW7asLFq0SLJkySJp0qSJsU327Nll165dUrVqVb2PaWf79u3TbWOC7B4ZP8aqUSwXlZH5oxDOUKxYMQ3SFy9ejDVjL1q0qBbe2dq5c6dDPycRPTkWrBElEW3btpVMmTJphTkK1s6dO6fzsPv06SOXL1/WNn379pVPP/1Uli1bJidOnJB33nknzjnaefPmlQ4dOkjnzp11G2Ofixcv1udRBY8qc3Tv37x5U7NudNsPGDBAi9TmzJmjXfb79++Xr776Su9D9+7d5dSpUzJw4EAtdluwYIEW0hHRf4PBmyiJ8PPzk82bN0vu3Lm1khvZbZcuXXTM28jE33vvPWnXrp0GZIwxI9A2adIkzv2i27558+Ya6IsUKSLdunWToKAgfQ7d4qNGjdJK8axZs0qvXr30cSzy8uGHH2rVOY4DFe/oRsfUMcAxolIdJwSYRoaq9DFjxpj+HhHRY26oWvvneyIiInIBzLyJiIhcDIM3ERGRi2HwJiIicjEM3kRERC6GwZuIiMjFMHgTERG5GAZvIiIiF8PgTURE5GIYvImIiFwMgzcREZGLYfAmIiIS1/J/DZf6U4nggbIAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred = (oof >= 0.5).astype(int)\n",
        "cm = confusion_matrix(y, y_pred)\n",
        "print(\"Confusion matrix (OOF, threshold=0.5)\")\n",
        "print(\"Rows: true, Cols: predicted |  Absence   Presence\")\n",
        "print(cm)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "plt.colorbar()\n",
        "plt.xticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.yticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
        "plt.title(\"Confusion matrix (OOF)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission saved (2-model blend): submission.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>630000</th>\n",
              "      <td>630000</td>\n",
              "      <td>0.945509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630001</th>\n",
              "      <td>630001</td>\n",
              "      <td>0.010015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630002</th>\n",
              "      <td>630002</td>\n",
              "      <td>0.985070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630003</th>\n",
              "      <td>630003</td>\n",
              "      <td>0.005499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630004</th>\n",
              "      <td>630004</td>\n",
              "      <td>0.209162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630005</th>\n",
              "      <td>630005</td>\n",
              "      <td>0.983138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630006</th>\n",
              "      <td>630006</td>\n",
              "      <td>0.004404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630007</th>\n",
              "      <td>630007</td>\n",
              "      <td>0.549733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630008</th>\n",
              "      <td>630008</td>\n",
              "      <td>0.990905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630009</th>\n",
              "      <td>630009</td>\n",
              "      <td>0.012845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  Heart Disease\n",
              "id                           \n",
              "630000  630000       0.945509\n",
              "630001  630001       0.010015\n",
              "630002  630002       0.985070\n",
              "630003  630003       0.005499\n",
              "630004  630004       0.209162\n",
              "630005  630005       0.983138\n",
              "630006  630006       0.004404\n",
              "630007  630007       0.549733\n",
              "630008  630008       0.990905\n",
              "630009  630009       0.012845"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub = pd.DataFrame({\"id\": test[\"id\"], \"Heart Disease\": test_proba})\n",
        "sub.to_csv(OUTPUT_DIR / \"submission.csv\", index=False)\n",
        "print(f\"Submission saved ({N_STACK_MODELS}-model blend): {OUTPUT_DIR / 'submission.csv'}\")\n",
        "sub.head(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
