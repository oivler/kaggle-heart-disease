{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicting Heart Disease\n",
        "\n",
        "## Score: .95377"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict, KFold\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import catboost as cb\n",
        "from catboost import CatBoostClassifier\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "DATA_DIR = Path(\"playground-series-s6e2\")\n",
        "OUTPUT_DIR = Path(\".\")\n",
        "n_splits = 5\n",
        "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (630000, 15)\n",
            "Test: (270000, 14)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Chest pain type</th>\n",
              "      <th>BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FBS over 120</th>\n",
              "      <th>EKG results</th>\n",
              "      <th>Max HR</th>\n",
              "      <th>Exercise angina</th>\n",
              "      <th>ST depression</th>\n",
              "      <th>Slope of ST</th>\n",
              "      <th>Number of vessels fluro</th>\n",
              "      <th>Thallium</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>152</td>\n",
              "      <td>239</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>325</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>160</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>134</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>140</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  Age  Sex  Chest pain type   BP  Cholesterol  FBS over 120  EKG results  \\\n",
              "0   0   58    1                4  152          239             0            0   \n",
              "1   1   52    1                1  125          325             0            2   \n",
              "2   2   56    0                2  160          188             0            2   \n",
              "3   3   44    0                3  134          229             0            2   \n",
              "4   4   58    1                4  140          234             0            2   \n",
              "\n",
              "   Max HR  Exercise angina  ST depression  Slope of ST  \\\n",
              "0     158                1            3.6            2   \n",
              "1     171                0            0.0            1   \n",
              "2     151                0            0.0            1   \n",
              "3     150                0            1.0            2   \n",
              "4     125                1            3.8            2   \n",
              "\n",
              "   Number of vessels fluro  Thallium Heart Disease  \n",
              "0                        2         7      Presence  \n",
              "1                        0         3       Absence  \n",
              "2                        0         3       Absence  \n",
              "3                        0         3       Absence  \n",
              "4                        3         3      Presence  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR / \"test.csv\")\n",
        "print(f\"Train: {train.shape}\")\n",
        "print(f\"Test: {test.shape}\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features: 32 columns\n",
            "Target distribution: {0: 347546, 1: 282454}\n"
          ]
        }
      ],
      "source": [
        "target_col = \"Heart Disease\"\n",
        "id_col = \"id\"\n",
        "feature_cols = [c for c in train.columns if c not in (id_col, target_col)]\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(train[target_col])\n",
        "\n",
        "X_train = train[feature_cols].copy()\n",
        "X_test = test[feature_cols].copy()\n",
        "\n",
        "for col in feature_cols:\n",
        "    if X_train[col].isna().any() or X_test[col].isna().any():\n",
        "        med = X_train[col].median()\n",
        "        X_train[col] = X_train[col].fillna(med)\n",
        "        X_test[col] = X_test[col].fillna(med)\n",
        "\n",
        "X_train[\"chol_exercise\"] = X_train[\"Cholesterol\"] * X_train[\"Exercise angina\"]\n",
        "X_test[\"chol_exercise\"] = X_test[\"Cholesterol\"] * X_test[\"Exercise angina\"]\n",
        "X_train[\"st_slope\"] = X_train[\"ST depression\"] * X_train[\"Slope of ST\"]\n",
        "X_test[\"st_slope\"] = X_test[\"ST depression\"] * X_test[\"Slope of ST\"]\n",
        "X_train[\"hr_age\"] = X_train[\"Max HR\"] * X_train[\"Age\"]\n",
        "X_test[\"hr_age\"] = X_test[\"Max HR\"] * X_test[\"Age\"]\n",
        "X_train[\"bp_age\"] = X_train[\"BP\"] * X_train[\"Age\"]\n",
        "X_test[\"bp_age\"] = X_test[\"BP\"] * X_test[\"Age\"]\n",
        "\n",
        "te_cols = [\"Chest pain type\", \"Slope of ST\", \"Thallium\"]\n",
        "global_mean = float(y.mean())\n",
        "m = 20\n",
        "for col in te_cols:\n",
        "    agg = pd.DataFrame({\"_y\": y}).groupby(X_train[col])[\"_y\"].agg([\"mean\", \"count\"])\n",
        "    smoothed = (agg[\"count\"] * agg[\"mean\"] + m * global_mean) / (agg[\"count\"] + m)\n",
        "    X_train[col + \"_te\"] = X_train[col].map(smoothed).fillna(global_mean)\n",
        "    X_test[col + \"_te\"] = X_test[col].map(smoothed).fillna(global_mean)\n",
        "\n",
        "scaler_feat = StandardScaler()\n",
        "X_tr_s = scaler_feat.fit_transform(X_train)\n",
        "X_te_s = scaler_feat.transform(X_test)\n",
        "kmeans = KMeans(n_clusters=12, random_state=42, n_init=10)\n",
        "kmeans.fit(X_tr_s)\n",
        "for i in range(kmeans.n_clusters):\n",
        "    d_tr = np.linalg.norm(X_tr_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    d_te = np.linalg.norm(X_te_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    X_train[f\"dist_c{i}\"] = d_tr\n",
        "    X_test[f\"dist_c{i}\"] = d_te\n",
        "\n",
        "print(f\"Features: {len(X_train.columns)} columns\")\n",
        "print(f\"Target distribution: {pd.Series(y).value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best OOF AUC: 0.95507, params: {'depth': 6, 'lr': 0.05, 'min_data_in_leaf': 15}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\"depth\": [4, 5, 6], \"lr\": [0.03, 0.04, 0.05], \"min_data_in_leaf\": [15, 25, 35]}\n",
        "n_est = 800\n",
        "best_auc, best_params = 0, None\n",
        "for depth in param_grid[\"depth\"]:\n",
        "    for lr in param_grid[\"lr\"]:\n",
        "        for min_leaf in param_grid[\"min_data_in_leaf\"]:\n",
        "            m = cb.CatBoostClassifier(iterations=n_est, depth=depth, learning_rate=lr, min_data_in_leaf=min_leaf, subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "            oof = cross_val_predict(m, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "            auc = roc_auc_score(y, oof)\n",
        "            if auc > best_auc:\n",
        "                best_auc, best_params = auc, {\"depth\": depth, \"lr\": lr, \"min_data_in_leaf\": min_leaf}\n",
        "print(f\"Best OOF AUC: {best_auc:.5f}, params: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV AUC: 0.95517 (blend w_xgb=0.4)\n"
          ]
        }
      ],
      "source": [
        "model = cb.CatBoostClassifier(iterations=n_est, depth=best_params[\"depth\"], learning_rate=best_params[\"lr\"], min_data_in_leaf=best_params[\"min_data_in_leaf\"], subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "oof_cb = cross_val_predict(model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=n_est, max_depth=5, learning_rate=0.05, min_child_weight=20, subsample=0.75, colsample_bytree=0.75, random_state=42, eval_metric=\"auc\")\n",
        "oof_xgb = cross_val_predict(xgb_model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "best_w, best_auc = 0.0, roc_auc_score(y, oof_cb)\n",
        "for w in [0, 0.1, 0.2, 0.3, 0.4]:\n",
        "    oof_blend = (1 - w) * oof_cb + w * oof_xgb\n",
        "    auc = roc_auc_score(y, oof_blend)\n",
        "    if auc > best_auc:\n",
        "        best_auc, best_w = auc, w\n",
        "oof = (1 - best_w) * oof_cb + best_w * oof_xgb\n",
        "print(f\"CV AUC: {best_auc:.5f} (blend w_xgb={best_w})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train, y)\n",
        "xgb_model.fit(X_train, y)\n",
        "test_cb = model.predict_proba(X_test)[:, 1]\n",
        "test_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
        "test_proba = (1 - best_w) * test_cb + best_w * test_xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher model using 13 shared columns from original dataset\n",
            "Adversarial AUC (train vs test): 0.50147\n",
            "Sample weights (train-like vs test-like) -> min=0.350, max=2.793, mean=1.000\n",
            "FOLD 1/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90611\n",
            "[1999]\tvalidation_0-auc:0.95537\n",
            "FOLD 2/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90775\n",
            "[1999]\tvalidation_0-auc:0.95634\n",
            "FOLD 3/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90505\n",
            "[1999]\tvalidation_0-auc:0.95435\n",
            "FOLD 4/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90495\n",
            "[1710]\tvalidation_0-auc:0.95515\n",
            "FOLD 5/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90584\n",
            "[1989]\tvalidation_0-auc:0.95557\n",
            "FOLD 6/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90614\n",
            "[1679]\tvalidation_0-auc:0.95502\n",
            "FOLD 7/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90503\n",
            "[1999]\tvalidation_0-auc:0.95516\n",
            "FOLD 8/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90703\n",
            "[1837]\tvalidation_0-auc:0.95640\n",
            "FOLD 9/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90578\n",
            "[1950]\tvalidation_0-auc:0.95563\n",
            "FOLD 1/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713666\ttest: 0.6713086\tbest: 0.6713086 (0)\ttotal: 168ms\tremaining: 5m 36s\n",
            "1999:\tlearn: 0.2674484\ttest: 0.2676826\tbest: 0.2676815 (1997)\ttotal: 4m 54s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2676814555\n",
            "bestIteration = 1997\n",
            "\n",
            "Shrink model to first 1998 iterations.\n",
            "FOLD 2/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713883\ttest: 0.6712144\tbest: 0.6712144 (0)\ttotal: 166ms\tremaining: 5m 31s\n",
            "1999:\tlearn: 0.2677796\ttest: 0.2648704\tbest: 0.2648704 (1999)\ttotal: 4m 52s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2648703886\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 3/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713258\ttest: 0.6712982\tbest: 0.6712982 (0)\ttotal: 166ms\tremaining: 5m 32s\n",
            "1999:\tlearn: 0.2670877\ttest: 0.2706006\tbest: 0.2706006 (1999)\ttotal: 4m 57s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2706005694\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 4/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713295\ttest: 0.6713382\tbest: 0.6713382 (0)\ttotal: 159ms\tremaining: 5m 16s\n",
            "1999:\tlearn: 0.2673713\ttest: 0.2680502\tbest: 0.2680497 (1993)\ttotal: 5m 11s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2680496505\n",
            "bestIteration = 1993\n",
            "\n",
            "Shrink model to first 1994 iterations.\n",
            "FOLD 5/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713388\ttest: 0.6713107\tbest: 0.6713107 (0)\ttotal: 155ms\tremaining: 5m 8s\n",
            "1999:\tlearn: 0.2675582\ttest: 0.2670842\tbest: 0.2670831 (1995)\ttotal: 4m 39s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2670831305\n",
            "bestIteration = 1995\n",
            "\n",
            "Shrink model to first 1996 iterations.\n",
            "FOLD 6/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713685\ttest: 0.6712715\tbest: 0.6712715 (0)\ttotal: 152ms\tremaining: 5m 4s\n",
            "1999:\tlearn: 0.2673082\ttest: 0.2692093\tbest: 0.2692093 (1999)\ttotal: 4m 35s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2692092593\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 7/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713193\ttest: 0.6713922\tbest: 0.6713922 (0)\ttotal: 144ms\tremaining: 4m 46s\n",
            "1999:\tlearn: 0.2673858\ttest: 0.2682511\tbest: 0.2682511 (1999)\ttotal: 4m 54s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2682510653\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 8/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713535\ttest: 0.6712392\tbest: 0.6712392 (0)\ttotal: 152ms\tremaining: 5m 3s\n",
            "1999:\tlearn: 0.2679147\ttest: 0.2646936\tbest: 0.2646934 (1995)\ttotal: 4m 49s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2646933706\n",
            "bestIteration = 1995\n",
            "\n",
            "Shrink model to first 1996 iterations.\n",
            "FOLD 9/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713537\ttest: 0.6713478\tbest: 0.6713478 (0)\ttotal: 164ms\tremaining: 5m 28s\n",
            "1999:\tlearn: 0.2676617\ttest: 0.2666558\tbest: 0.2666556 (1998)\ttotal: 4m 53s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2666555614\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 1/9 - LGBMClassifier\n",
            "FOLD 2/9 - LGBMClassifier\n",
            "FOLD 3/9 - LGBMClassifier\n",
            "FOLD 4/9 - LGBMClassifier\n",
            "FOLD 5/9 - LGBMClassifier\n",
            "FOLD 6/9 - LGBMClassifier\n",
            "FOLD 7/9 - LGBMClassifier\n",
            "FOLD 8/9 - LGBMClassifier\n",
            "FOLD 9/9 - LGBMClassifier\n",
            "FOLD 1/9 - HistGradientBoostingClassifier\n",
            "FOLD 2/9 - HistGradientBoostingClassifier\n",
            "FOLD 3/9 - HistGradientBoostingClassifier\n",
            "FOLD 4/9 - HistGradientBoostingClassifier\n",
            "FOLD 5/9 - HistGradientBoostingClassifier\n",
            "FOLD 6/9 - HistGradientBoostingClassifier\n",
            "FOLD 7/9 - HistGradientBoostingClassifier\n",
            "FOLD 8/9 - HistGradientBoostingClassifier\n",
            "FOLD 9/9 - HistGradientBoostingClassifier\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955442\n",
            "XGBClassifier CV AUC mean: 0.955447, std: +-0.00061\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955533\n",
            "CatBoostClassifier CV AUC mean: 0.955537, std: +-0.00062\n",
            "\n",
            "LGBMClassifier OOF AUC: 0.954939\n",
            "LGBMClassifier CV AUC mean: 0.954944, std: +-0.00063\n",
            "\n",
            "HistGradientBoostingClassifier OOF AUC: 0.955290\n",
            "HistGradientBoostingClassifier CV AUC mean: 0.955296, std: +-0.00062\n",
            "\n",
            "4-model: blend (blend=0.955599, meta=0.955549) -> OOF AUC: 0.955599\n",
            "FOLD 1/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88882\n",
            "[1999]\tvalidation_0-auc:0.95484\n",
            "FOLD 2/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89742\n",
            "[1999]\tvalidation_0-auc:0.95402\n",
            "FOLD 3/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89904\n",
            "[1999]\tvalidation_0-auc:0.95552\n",
            "FOLD 4/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90178\n",
            "[1945]\tvalidation_0-auc:0.95652\n",
            "FOLD 5/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89847\n",
            "[1999]\tvalidation_0-auc:0.95473\n",
            "FOLD 6/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89143\n",
            "[1999]\tvalidation_0-auc:0.95655\n",
            "FOLD 7/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89045\n",
            "[1999]\tvalidation_0-auc:0.95546\n",
            "FOLD 8/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89158\n",
            "[1952]\tvalidation_0-auc:0.95576\n",
            "FOLD 9/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89178\n",
            "[1763]\tvalidation_0-auc:0.95553\n",
            "FOLD 1/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716858\ttest: 0.6717855\tbest: 0.6717855 (0)\ttotal: 158ms\tremaining: 5m 16s\n",
            "1999:\tlearn: 0.2672524\ttest: 0.2696470\tbest: 0.2696461 (1994)\ttotal: 4m 40s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.269646136\n",
            "bestIteration = 1994\n",
            "\n",
            "Shrink model to first 1995 iterations.\n",
            "FOLD 2/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716993\ttest: 0.6717887\tbest: 0.6717887 (0)\ttotal: 148ms\tremaining: 4m 55s\n",
            "1999:\tlearn: 0.2670135\ttest: 0.2717539\tbest: 0.2717539 (1999)\ttotal: 4m 37s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2717538864\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 3/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717290\ttest: 0.6716913\tbest: 0.6716913 (0)\ttotal: 149ms\tremaining: 4m 57s\n",
            "1999:\tlearn: 0.2674971\ttest: 0.2671666\tbest: 0.2671666 (1999)\ttotal: 4m 45s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2671666441\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 4/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717786\ttest: 0.6715727\tbest: 0.6715727 (0)\ttotal: 161ms\tremaining: 5m 22s\n",
            "1999:\tlearn: 0.2679665\ttest: 0.2639922\tbest: 0.2639919 (1998)\ttotal: 4m 37s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2639919385\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 5/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717115\ttest: 0.6717389\tbest: 0.6717389 (0)\ttotal: 152ms\tremaining: 5m 4s\n",
            "1999:\tlearn: 0.2673156\ttest: 0.2691689\tbest: 0.2691689 (1999)\ttotal: 4m 41s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2691688525\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 6/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717384\ttest: 0.6716479\tbest: 0.6716479 (0)\ttotal: 148ms\tremaining: 4m 55s\n",
            "1999:\tlearn: 0.2679200\ttest: 0.2645601\tbest: 0.2645601 (1999)\ttotal: 4m 39s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.264560092\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 7/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717280\ttest: 0.6716847\tbest: 0.6716847 (0)\ttotal: 156ms\tremaining: 5m 12s\n",
            "1999:\tlearn: 0.2676270\ttest: 0.2671396\tbest: 0.2671396 (1999)\ttotal: 4m 42s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2671395694\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 8/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717472\ttest: 0.6716157\tbest: 0.6716157 (0)\ttotal: 141ms\tremaining: 4m 41s\n",
            "1999:\tlearn: 0.2676658\ttest: 0.2670496\tbest: 0.2670494 (1997)\ttotal: 4m 39s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2670494237\n",
            "bestIteration = 1997\n",
            "\n",
            "Shrink model to first 1998 iterations.\n",
            "FOLD 9/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717503\ttest: 0.6716359\tbest: 0.6716359 (0)\ttotal: 158ms\tremaining: 5m 16s\n",
            "1999:\tlearn: 0.2675843\ttest: 0.2671011\tbest: 0.2671008 (1997)\ttotal: 4m 42s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2671008005\n",
            "bestIteration = 1997\n",
            "\n",
            "Shrink model to first 1998 iterations.\n",
            "FOLD 1/9 - LGBMClassifier\n",
            "FOLD 2/9 - LGBMClassifier\n",
            "FOLD 3/9 - LGBMClassifier\n",
            "FOLD 4/9 - LGBMClassifier\n",
            "FOLD 5/9 - LGBMClassifier\n",
            "FOLD 6/9 - LGBMClassifier\n",
            "FOLD 7/9 - LGBMClassifier\n",
            "FOLD 8/9 - LGBMClassifier\n",
            "FOLD 9/9 - LGBMClassifier\n",
            "FOLD 1/9 - HistGradientBoostingClassifier\n",
            "FOLD 2/9 - HistGradientBoostingClassifier\n",
            "FOLD 3/9 - HistGradientBoostingClassifier\n",
            "FOLD 4/9 - HistGradientBoostingClassifier\n",
            "FOLD 5/9 - HistGradientBoostingClassifier\n",
            "FOLD 6/9 - HistGradientBoostingClassifier\n",
            "FOLD 7/9 - HistGradientBoostingClassifier\n",
            "FOLD 8/9 - HistGradientBoostingClassifier\n",
            "FOLD 9/9 - HistGradientBoostingClassifier\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955438\n",
            "XGBClassifier CV AUC mean: 0.955439, std: +-0.00078\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955513\n",
            "CatBoostClassifier CV AUC mean: 0.955514, std: +-0.00078\n",
            "\n",
            "LGBMClassifier OOF AUC: 0.954949\n",
            "LGBMClassifier CV AUC mean: 0.954949, std: +-0.00076\n",
            "\n",
            "HistGradientBoostingClassifier OOF AUC: 0.955278\n",
            "HistGradientBoostingClassifier CV AUC mean: 0.955281, std: +-0.00078\n",
            "\n",
            "4-model: blend (blend=0.955584, meta=0.955534) -> OOF AUC: 0.955584\n",
            "FOLD 1/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90636\n",
            "[1987]\tvalidation_0-auc:0.95549\n",
            "FOLD 2/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90515\n",
            "[1999]\tvalidation_0-auc:0.95530\n",
            "FOLD 3/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90478\n",
            "[1999]\tvalidation_0-auc:0.95523\n",
            "FOLD 4/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90401\n",
            "[1999]\tvalidation_0-auc:0.95451\n",
            "FOLD 5/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90593\n",
            "[1999]\tvalidation_0-auc:0.95671\n",
            "FOLD 6/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90568\n",
            "[1999]\tvalidation_0-auc:0.95534\n",
            "FOLD 7/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90662\n",
            "[1946]\tvalidation_0-auc:0.95716\n",
            "FOLD 8/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90404\n",
            "[1999]\tvalidation_0-auc:0.95471\n",
            "FOLD 9/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90426\n",
            "[1831]\tvalidation_0-auc:0.95455\n",
            "FOLD 1/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717336\ttest: 0.6715631\tbest: 0.6715631 (0)\ttotal: 173ms\tremaining: 5m 45s\n",
            "1999:\tlearn: 0.2677724\ttest: 0.2674426\tbest: 0.2674426 (1999)\ttotal: 5m 18s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2674426295\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 2/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717116\ttest: 0.6716403\tbest: 0.6716403 (0)\ttotal: 169ms\tremaining: 5m 38s\n",
            "1999:\tlearn: 0.2675947\ttest: 0.2679352\tbest: 0.2679352 (1999)\ttotal: 5m 18s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2679351651\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 3/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717841\ttest: 0.6717293\tbest: 0.6717293 (0)\ttotal: 171ms\tremaining: 5m 41s\n",
            "1999:\tlearn: 0.2674997\ttest: 0.2681277\tbest: 0.2681277 (1998)\ttotal: 5m 20s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2681276502\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 4/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717315\ttest: 0.6718209\tbest: 0.6718209 (0)\ttotal: 188ms\tremaining: 6m 16s\n",
            "1999:\tlearn: 0.2672350\ttest: 0.2705142\tbest: 0.2705142 (1999)\ttotal: 5m 23s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2705142114\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 5/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717334\ttest: 0.6716509\tbest: 0.6716509 (0)\ttotal: 153ms\tremaining: 5m 5s\n",
            "1999:\tlearn: 0.2681154\ttest: 0.2638091\tbest: 0.2638091 (1999)\ttotal: 5m 21s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2638091298\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 6/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717007\ttest: 0.6716724\tbest: 0.6716724 (0)\ttotal: 170ms\tremaining: 5m 39s\n",
            "1999:\tlearn: 0.2676311\ttest: 0.2674009\tbest: 0.2674007 (1998)\ttotal: 5m 22s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2674006699\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 7/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717377\ttest: 0.6716342\tbest: 0.6716342 (0)\ttotal: 184ms\tremaining: 6m 8s\n",
            "1999:\tlearn: 0.2682998\ttest: 0.2621837\tbest: 0.2621830 (1994)\ttotal: 5m 17s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2621830059\n",
            "bestIteration = 1994\n",
            "\n",
            "Shrink model to first 1995 iterations.\n",
            "FOLD 8/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717018\ttest: 0.6717094\tbest: 0.6717094 (0)\ttotal: 173ms\tremaining: 5m 45s\n",
            "1999:\tlearn: 0.2672910\ttest: 0.2698167\tbest: 0.2698167 (1999)\ttotal: 5m 22s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2698167483\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 9/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717052\ttest: 0.6716735\tbest: 0.6716735 (0)\ttotal: 176ms\tremaining: 5m 50s\n",
            "1999:\tlearn: 0.2673232\ttest: 0.2699127\tbest: 0.2699127 (1999)\ttotal: 5m 18s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2699126784\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 1/9 - LGBMClassifier\n",
            "FOLD 2/9 - LGBMClassifier\n",
            "FOLD 3/9 - LGBMClassifier\n",
            "FOLD 4/9 - LGBMClassifier\n",
            "FOLD 5/9 - LGBMClassifier\n",
            "FOLD 6/9 - LGBMClassifier\n",
            "FOLD 7/9 - LGBMClassifier\n",
            "FOLD 8/9 - LGBMClassifier\n",
            "FOLD 9/9 - LGBMClassifier\n",
            "FOLD 1/9 - HistGradientBoostingClassifier\n",
            "FOLD 2/9 - HistGradientBoostingClassifier\n",
            "FOLD 3/9 - HistGradientBoostingClassifier\n",
            "FOLD 4/9 - HistGradientBoostingClassifier\n",
            "FOLD 5/9 - HistGradientBoostingClassifier\n",
            "FOLD 6/9 - HistGradientBoostingClassifier\n",
            "FOLD 7/9 - HistGradientBoostingClassifier\n",
            "FOLD 8/9 - HistGradientBoostingClassifier\n",
            "FOLD 9/9 - HistGradientBoostingClassifier\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955447\n",
            "XGBClassifier CV AUC mean: 0.955448, std: +-0.00087\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955529\n",
            "CatBoostClassifier CV AUC mean: 0.955531, std: +-0.00089\n",
            "\n",
            "LGBMClassifier OOF AUC: 0.954955\n",
            "LGBMClassifier CV AUC mean: 0.954957, std: +-0.00087\n",
            "\n",
            "HistGradientBoostingClassifier OOF AUC: 0.955280\n",
            "HistGradientBoostingClassifier CV AUC mean: 0.955282, std: +-0.00091\n",
            "\n",
            "4-model: blend (blend=0.955594, meta=0.955539) -> OOF AUC: 0.955594\n",
            "FOLD 1/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88758\n",
            "[1772]\tvalidation_0-auc:0.95547\n",
            "FOLD 2/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89008\n",
            "[1824]\tvalidation_0-auc:0.95560\n",
            "FOLD 3/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88761\n",
            "[1999]\tvalidation_0-auc:0.95482\n",
            "FOLD 4/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89090\n",
            "[1999]\tvalidation_0-auc:0.95597\n",
            "FOLD 5/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89064\n",
            "[1999]\tvalidation_0-auc:0.95510\n",
            "FOLD 6/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88982\n",
            "[1999]\tvalidation_0-auc:0.95518\n",
            "FOLD 7/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88655\n",
            "[1999]\tvalidation_0-auc:0.95476\n",
            "FOLD 8/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89031\n",
            "[1999]\tvalidation_0-auc:0.95607\n",
            "FOLD 9/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88875\n",
            "[1831]\tvalidation_0-auc:0.95596\n",
            "FOLD 1/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717913\ttest: 0.6717908\tbest: 0.6717908 (0)\ttotal: 153ms\tremaining: 5m 5s\n",
            "1999:\tlearn: 0.2675785\ttest: 0.2672266\tbest: 0.2672266 (1999)\ttotal: 5m 13s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2672266132\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 2/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6719421\ttest: 0.6718032\tbest: 0.6718032 (0)\ttotal: 169ms\tremaining: 5m 38s\n",
            "1999:\tlearn: 0.2675566\ttest: 0.2670300\tbest: 0.2670300 (1999)\ttotal: 5m 12s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.267030022\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 3/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6718752\ttest: 0.6719843\tbest: 0.6719843 (0)\ttotal: 143ms\tremaining: 4m 46s\n",
            "1999:\tlearn: 0.2673880\ttest: 0.2692846\tbest: 0.2692846 (1999)\ttotal: 5m 6s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2692846463\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 4/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6719685\ttest: 0.6717951\tbest: 0.6717951 (0)\ttotal: 154ms\tremaining: 5m 7s\n",
            "1999:\tlearn: 0.2677241\ttest: 0.2657692\tbest: 0.2657692 (1999)\ttotal: 5m 1s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2657692064\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 5/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6719302\ttest: 0.6718610\tbest: 0.6718610 (0)\ttotal: 133ms\tremaining: 4m 25s\n",
            "1999:\tlearn: 0.2674325\ttest: 0.2689300\tbest: 0.2689300 (1999)\ttotal: 4m 35s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2689300155\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 6/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6719259\ttest: 0.6718424\tbest: 0.6718424 (0)\ttotal: 140ms\tremaining: 4m 40s\n",
            "1999:\tlearn: 0.2674505\ttest: 0.2686181\tbest: 0.2686173 (1995)\ttotal: 4m 42s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2686173039\n",
            "bestIteration = 1995\n",
            "\n",
            "Shrink model to first 1996 iterations.\n",
            "FOLD 7/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6718631\ttest: 0.6719518\tbest: 0.6719518 (0)\ttotal: 132ms\tremaining: 4m 23s\n",
            "1999:\tlearn: 0.2673599\ttest: 0.2690147\tbest: 0.2690135 (1992)\ttotal: 4m 40s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2690134763\n",
            "bestIteration = 1992\n",
            "\n",
            "Shrink model to first 1993 iterations.\n",
            "FOLD 8/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6719232\ttest: 0.6718364\tbest: 0.6718364 (0)\ttotal: 158ms\tremaining: 5m 16s\n",
            "1999:\tlearn: 0.2677892\ttest: 0.2654359\tbest: 0.2654359 (1999)\ttotal: 4m 49s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2654358824\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 9/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6719169\ttest: 0.6718678\tbest: 0.6718678 (0)\ttotal: 177ms\tremaining: 5m 54s\n",
            "1999:\tlearn: 0.2677847\ttest: 0.2658551\tbest: 0.2658531 (1994)\ttotal: 4m 45s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2658530867\n",
            "bestIteration = 1994\n",
            "\n",
            "Shrink model to first 1995 iterations.\n",
            "FOLD 1/9 - LGBMClassifier\n",
            "FOLD 2/9 - LGBMClassifier\n",
            "FOLD 3/9 - LGBMClassifier\n",
            "FOLD 4/9 - LGBMClassifier\n",
            "FOLD 5/9 - LGBMClassifier\n",
            "FOLD 6/9 - LGBMClassifier\n",
            "FOLD 7/9 - LGBMClassifier\n",
            "FOLD 8/9 - LGBMClassifier\n",
            "FOLD 9/9 - LGBMClassifier\n",
            "FOLD 1/9 - HistGradientBoostingClassifier\n",
            "FOLD 2/9 - HistGradientBoostingClassifier\n",
            "FOLD 3/9 - HistGradientBoostingClassifier\n",
            "FOLD 4/9 - HistGradientBoostingClassifier\n",
            "FOLD 5/9 - HistGradientBoostingClassifier\n",
            "FOLD 6/9 - HistGradientBoostingClassifier\n",
            "FOLD 7/9 - HistGradientBoostingClassifier\n",
            "FOLD 8/9 - HistGradientBoostingClassifier\n",
            "FOLD 9/9 - HistGradientBoostingClassifier\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955435\n",
            "XGBClassifier CV AUC mean: 0.955438, std: +-0.00047\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955527\n",
            "CatBoostClassifier CV AUC mean: 0.955530, std: +-0.00046\n",
            "\n",
            "LGBMClassifier OOF AUC: 0.954950\n",
            "LGBMClassifier CV AUC mean: 0.954953, std: +-0.00050\n",
            "\n",
            "HistGradientBoostingClassifier OOF AUC: 0.955295\n",
            "HistGradientBoostingClassifier CV AUC mean: 0.955299, std: +-0.00045\n",
            "\n",
            "4-model: blend (blend=0.955595, meta=0.955539) -> OOF AUC: 0.955595\n",
            "Submission: 4-model stack, 4-seed avg. test_proba shape: (270000,)\n",
            "[0]\tvalidation_0-auc:0.92571\n",
            "[1631]\tvalidation_0-auc:0.96840\n",
            "[0]\tvalidation_0-auc:0.92628\n",
            "[1999]\tvalidation_0-auc:0.96905\n",
            "[0]\tvalidation_0-auc:0.92751\n",
            "[1968]\tvalidation_0-auc:0.96865\n",
            "[0]\tvalidation_0-auc:0.92681\n",
            "[1999]\tvalidation_0-auc:0.96967\n",
            "[0]\tvalidation_0-auc:0.92665\n",
            "[1999]\tvalidation_0-auc:0.96911\n",
            "[0]\tvalidation_0-auc:0.92697\n",
            "[1825]\tvalidation_0-auc:0.96939\n",
            "[0]\tvalidation_0-auc:0.92719\n",
            "[1999]\tvalidation_0-auc:0.96924\n",
            "[0]\tvalidation_0-auc:0.92631\n",
            "[1999]\tvalidation_0-auc:0.96884\n",
            "[0]\tvalidation_0-auc:0.92708\n",
            "[1780]\tvalidation_0-auc:0.96869\n",
            "0:\tlearn: 0.6705110\ttest: 0.6694190\tbest: 0.6694190 (0)\ttotal: 205ms\tremaining: 6m 50s\n",
            "1999:\tlearn: 0.2521659\ttest: 0.2247827\tbest: 0.2247827 (1999)\ttotal: 5m 56s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2247826672\n",
            "bestIteration = 1999\n",
            "\n",
            "0:\tlearn: 0.6705449\ttest: 0.6692939\tbest: 0.6692939 (0)\ttotal: 198ms\tremaining: 6m 35s\n",
            "1999:\tlearn: 0.2524120\ttest: 0.2228050\tbest: 0.2228046 (1998)\ttotal: 5m 54s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2228046368\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "0:\tlearn: 0.6707637\ttest: 0.6696095\tbest: 0.6696095 (0)\ttotal: 204ms\tremaining: 6m 47s\n",
            "1999:\tlearn: 0.2521772\ttest: 0.2247678\tbest: 0.2247678 (1999)\ttotal: 5m 46s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2247677707\n",
            "bestIteration = 1999\n",
            "\n",
            "0:\tlearn: 0.6705777\ttest: 0.6693169\tbest: 0.6693169 (0)\ttotal: 214ms\tremaining: 7m 8s\n",
            "1999:\tlearn: 0.2527258\ttest: 0.2210304\tbest: 0.2210304 (1999)\ttotal: 5m 13s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2210303556\n",
            "bestIteration = 1999\n",
            "\n",
            "0:\tlearn: 0.6705699\ttest: 0.6693427\tbest: 0.6693427 (0)\ttotal: 161ms\tremaining: 5m 22s\n",
            "1999:\tlearn: 0.2524013\ttest: 0.2230247\tbest: 0.2230247 (1999)\ttotal: 5m 51s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2230247157\n",
            "bestIteration = 1999\n",
            "\n",
            "0:\tlearn: 0.6706194\ttest: 0.6693865\tbest: 0.6693865 (0)\ttotal: 196ms\tremaining: 6m 32s\n",
            "1999:\tlearn: 0.2525813\ttest: 0.2216902\tbest: 0.2216902 (1999)\ttotal: 5m 22s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2216901983\n",
            "bestIteration = 1999\n",
            "\n",
            "0:\tlearn: 0.6707235\ttest: 0.6695113\tbest: 0.6695113 (0)\ttotal: 166ms\tremaining: 5m 31s\n",
            "1999:\tlearn: 0.2525621\ttest: 0.2222791\tbest: 0.2222791 (1999)\ttotal: 5m 19s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2222791486\n",
            "bestIteration = 1999\n",
            "\n",
            "0:\tlearn: 0.6706157\ttest: 0.6693650\tbest: 0.6693650 (0)\ttotal: 154ms\tremaining: 5m 8s\n",
            "1999:\tlearn: 0.2522026\ttest: 0.2240156\tbest: 0.2240154 (1998)\ttotal: 5m 17s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2240153565\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "0:\tlearn: 0.6707164\ttest: 0.6694500\tbest: 0.6694500 (0)\ttotal: 209ms\tremaining: 6m 58s\n",
            "1999:\tlearn: 0.2522802\ttest: 0.2239662\tbest: 0.2239662 (1999)\ttotal: 6m 5s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2239662122\n",
            "bestIteration = 1999\n",
            "\n",
            "Pseudo-label: added 135644 samples, blended 0.6*pass1 + 0.4*pass2\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import inspect\n",
        "\n",
        "SEED = 42\n",
        "NSPLITS = 9\n",
        "SEEDS = [42, 43, 44, 45] \n",
        "USE_LR_STACK = False\n",
        "DROP_BP_MAX_HR = False\n",
        "PSEUDO_LABEL = True\n",
        "PSEUDO_THRESH = 0.95\n",
        "PSEUDO_WEIGHT = 0.3\n",
        "\n",
        "\n",
        "path = DATA_DIR\n",
        "dfs = []\n",
        "for fl in (\"train.csv\", \"test.csv\"):\n",
        "    df = pd.read_csv(path / fl, index_col=0)\n",
        "    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns.tolist()]\n",
        "    dfs.append(df)\n",
        "train, test = dfs\n",
        "\n",
        "ystr = train.columns[-1]\n",
        "base_features = [c for c in train.columns if c != ystr]\n",
        "\n",
        "cols2comb = [\n",
        "    \"exercise_angina\", \"thallium\", \"chest_pain_type\",\n",
        "    \"slope_of_st\", \"sex\", \"st_depression\", \"number_of_vessels_fluro\",\n",
        "    \"ekg_results\", \"fbs_over_120\",\n",
        "]\n",
        "\n",
        "statmetrics = [\"mean\", \"count\"]\n",
        "\n",
        "X = train.drop(columns=ystr)\n",
        "y = (train[ystr] == \"Presence\").astype(int)\n",
        "\n",
        "X_test = test.copy()\n",
        "\n",
        "orig_path = DATA_DIR.parent / \"original-data\" / \"Heart_Disease_Prediction.csv\"\n",
        "orig_df = pd.read_csv(orig_path)\n",
        "orig_df.columns = [c.strip().lower().replace(\" \", \"_\") for c in orig_df.columns]\n",
        "orig_ystr = orig_df.columns[-1]\n",
        "orig_X = orig_df.drop(columns=orig_ystr)\n",
        "orig_y = (orig_df[orig_ystr] == \"Presence\").astype(int)\n",
        "\n",
        "common_cols = sorted(set(orig_X.columns) & set(X.columns))\n",
        "print(f\"Teacher model using {len(common_cols)} shared columns from original dataset\")\n",
        "\n",
        "teacher = cb.CatBoostClassifier(\n",
        "    iterations=400,\n",
        "    depth=4,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.9,\n",
        "    colsample_bylevel=0.9,\n",
        "    random_seed=SEED,\n",
        "    verbose=0,\n",
        ")\n",
        "teacher.fit(orig_X[common_cols], orig_y)\n",
        "\n",
        "X[\"teacher_pred\"] = teacher.predict_proba(X[common_cols])[:, 1]\n",
        "X_test[\"teacher_pred\"] = teacher.predict_proba(X_test[common_cols])[:, 1]\n",
        "\n",
        "adv_X = pd.concat([X, X_test], axis=0).reset_index(drop=True)\n",
        "adv_y = np.concatenate([\n",
        "    np.zeros(len(X), dtype=int),\n",
        "    np.ones(len(X_test), dtype=int),\n",
        "])\n",
        "adv_skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "oof_adv = np.zeros(len(adv_y), dtype=float)\n",
        "for tr_adv, val_adv in adv_skf.split(adv_X, adv_y):\n",
        "    adv_clf = lgb.LGBMClassifier(\n",
        "        objective=\"binary\",\n",
        "        metric=\"auc\",\n",
        "        learning_rate=0.05,\n",
        "        n_estimators=400,\n",
        "        num_leaves=31,\n",
        "        feature_fraction=0.9,\n",
        "        bagging_fraction=0.9,\n",
        "        bagging_freq=1,\n",
        "        min_data_in_leaf=30,\n",
        "        random_state=SEED,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    adv_clf.fit(adv_X.iloc[tr_adv], adv_y[tr_adv])\n",
        "    oof_adv[val_adv] = adv_clf.predict_proba(adv_X.iloc[val_adv])[:, 1]\n",
        "\n",
        "auc_adv = roc_auc_score(adv_y, oof_adv)\n",
        "print(f\"Adversarial AUC (train vs test): {auc_adv:.5f}\")\n",
        "\n",
        "p_test_train = oof_adv[: len(X)]\n",
        "eps = 1e-3\n",
        "w_train = p_test_train / (1.0 - p_test_train + eps)\n",
        "w_train = w_train / w_train.mean()\n",
        "print(\n",
        "    f\"Sample weights (train-like vs test-like) -> min={w_train.min():.3f}, max={w_train.max():.3f}, mean={w_train.mean():.3f}\"\n",
        ")\n",
        "\n",
        "\n",
        "def get_cat_feature_indices(X_):\n",
        "    return [i for i, c in enumerate(X_.columns) if c.startswith(\"CAT_\")]\n",
        "\n",
        "\n",
        "def fe_foldwise(X_tr, X_val, y_tr):\n",
        "    X_tr = X_tr.copy()\n",
        "    X_val = X_val.copy()\n",
        "\n",
        "    temp = pd.concat([X_tr, y_tr], axis=1)\n",
        "\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"age>55\"] = (df[\"age\"] > 55).astype(int)\n",
        "        for col in df.columns:\n",
        "            if col == \"teacher_pred\":\n",
        "                continue\n",
        "            colname = f\"CAT_{col}\"\n",
        "            df[colname] = df[col].astype(str).astype(\"category\")\n",
        "\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"chest_pain_type_bin\"] = (df[\"chest_pain_type\"] >= 3).astype(int)\n",
        "        df[\"st_depression_bin\"] = (df[\"st_depression\"] >= 2).astype(int)\n",
        "        df[\"number_of_vessels_fluro_bin\"] = (df[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "        df[\"hr_age\"] = df[\"max_hr\"] * df[\"age\"]\n",
        "        df[\"bp_age\"] = df[\"bp\"] * df[\"age\"]\n",
        "        df[\"st_slope\"] = df[\"st_depression\"] * df[\"slope_of_st\"]\n",
        "        df[\"chol_exercise\"] = df[\"cholesterol\"] * df[\"exercise_angina\"]\n",
        "        pred_max = (220 - df[\"age\"]).clip(lower=10)\n",
        "        df[\"max_hr_pct_pred\"] = df[\"max_hr\"] / pred_max\n",
        "        df[\"risk_sum\"] = df[\"number_of_vessels_fluro\"] + df[\"thallium\"] + df[\"exercise_angina\"]\n",
        "        df[\"vessels_thallium\"] = df[\"number_of_vessels_fluro\"] * df[\"thallium\"]\n",
        "        df[\"age_chol\"] = df[\"age\"] * df[\"cholesterol\"]\n",
        "        df[\"risk_age\"] = df[\"risk_sum\"] * df[\"age\"]\n",
        "        df[\"teacher_pred_sq\"] = df[\"teacher_pred\"] ** 2\n",
        "\n",
        "    global_mean = float(y_tr.mean())\n",
        "    m_smooth = 10\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            cname = f\"target_{bf}_{s}\"\n",
        "            X_tr[cname] = X_tr[bf].map(stats[s])\n",
        "            X_val[cname] = X_val[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_tr[f\"target_{bf}_smooth\"] = X_tr[bf].map(smoothed).fillna(global_mean)\n",
        "        X_val[f\"target_{bf}_smooth\"] = X_val[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_tr[c2].max(), X_val[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_tr[cname] = (\n",
        "                (X_tr[c1] + 1 + (X_tr[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "            X_val[cname] = (\n",
        "                (X_val[c1] + 1 + (X_val[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    if DROP_BP_MAX_HR:\n",
        "        X_tr = X_tr.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "        X_val = X_val.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "    return X_tr, X_val\n",
        "\n",
        "\n",
        "def fe_test(X_test_, X_train_, y_train_):\n",
        "    X_test_ = X_test_.copy()\n",
        "    temp = pd.concat([X_train_, y_train_], axis=1)\n",
        "\n",
        "    X_test_[\"age>55\"] = (X_test_[\"age\"] > 55).astype(int)\n",
        "    for col in X_test_.columns:\n",
        "        if col == \"teacher_pred\":\n",
        "            continue\n",
        "        colname = f\"CAT_{col}\"\n",
        "        X_test_[colname] = X_test_[col].astype(str).astype(\"category\")\n",
        "\n",
        "    X_test_[\"chest_pain_type_bin\"] = (X_test_[\"chest_pain_type\"] >= 3).astype(int)\n",
        "    X_test_[\"st_depression_bin\"] = (X_test_[\"st_depression\"] >= 2).astype(int)\n",
        "    X_test_[\"number_of_vessels_fluro_bin\"] = (X_test_[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "    X_test_[\"hr_age\"] = X_test_[\"max_hr\"] * X_test_[\"age\"]\n",
        "    X_test_[\"bp_age\"] = X_test_[\"bp\"] * X_test_[\"age\"]\n",
        "    X_test_[\"st_slope\"] = X_test_[\"st_depression\"] * X_test_[\"slope_of_st\"]\n",
        "    X_test_[\"chol_exercise\"] = X_test_[\"cholesterol\"] * X_test_[\"exercise_angina\"]\n",
        "    pred_max = (220 - X_test_[\"age\"]).clip(lower=10)\n",
        "    X_test_[\"max_hr_pct_pred\"] = X_test_[\"max_hr\"] / pred_max\n",
        "    X_test_[\"risk_sum\"] = X_test_[\"number_of_vessels_fluro\"] + X_test_[\"thallium\"] + X_test_[\"exercise_angina\"]\n",
        "    X_test_[\"vessels_thallium\"] = X_test_[\"number_of_vessels_fluro\"] * X_test_[\"thallium\"]\n",
        "    X_test_[\"age_chol\"] = X_test_[\"age\"] * X_test_[\"cholesterol\"]\n",
        "    X_test_[\"risk_age\"] = X_test_[\"risk_sum\"] * X_test_[\"age\"]\n",
        "    X_test_[\"teacher_pred_sq\"] = X_test_[\"teacher_pred\"] ** 2\n",
        "\n",
        "    global_mean = float(y_train_.mean())\n",
        "    m_smooth = 10\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            X_test_[f\"target_{bf}_{s}\"] = X_test_[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_test_[f\"target_{bf}_smooth\"] = X_test_[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_train_[c2].max(), X_test_[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_test_[cname] = (\n",
        "                (X_test_[c1] + 1 + (X_test_[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    if DROP_BP_MAX_HR:\n",
        "        X_test_ = X_test_.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "    return X_test_\n",
        "\n",
        "\n",
        "xgboost_params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"auc\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"max_depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"colsample_bytree\": 0.9,\n",
        "    \"n_estimators\": 2000,\n",
        "    \"min_child_weight\": 10,\n",
        "    \"gamma\": 1,\n",
        "    \"reg_lambda\": 0.01,\n",
        "    \"reg_alpha\": 1.5,\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"n_jobs\": -1,\n",
        "    \"random_state\": SEED,\n",
        "    \"early_stopping_rounds\": 100,\n",
        "    \"enable_categorical\": True,\n",
        "}\n",
        "\n",
        "catboost_params = {\n",
        "    \"loss_function\": \"Logloss\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"iterations\": 2000,\n",
        "    \"min_data_in_leaf\": 1,\n",
        "    \"l2_leaf_reg\": 1.002,\n",
        "    \"thread_count\": -1,\n",
        "    \"random_seed\": SEED,\n",
        "    \"early_stopping_rounds\": 100,\n",
        "    \"bootstrap_type\": \"Bernoulli\",\n",
        "}\n",
        "\n",
        "lgbm_params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"metric\": \"auc\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"n_estimators\": 1200,\n",
        "    \"num_leaves\": 20,\n",
        "    \"feature_fraction\": 0.9,\n",
        "    \"bagging_fraction\": 0.9,\n",
        "    \"bagging_freq\": 1,\n",
        "    \"min_data_in_leaf\": 30,\n",
        "    \"random_state\": SEED,\n",
        "    \"n_jobs\": -1,\n",
        "    \"verbose\": -1,\n",
        "}\n",
        "hgb_params = {\n",
        "    \"max_iter\": 2000,\n",
        "    \"learning_rate\": 0.02,\n",
        "    \"max_depth\": 6,\n",
        "    \"early_stopping\": True,\n",
        "    \"n_iter_no_change\": 80,\n",
        "    \"validation_fraction\": 0.1,\n",
        "    \"random_state\": SEED,\n",
        "}\n",
        "models = {\n",
        "    XGBClassifier: xgboost_params,\n",
        "    CatBoostClassifier: catboost_params,\n",
        "    LGBMClassifier: lgbm_params,\n",
        "    HistGradientBoostingClassifier: hgb_params,\n",
        "}\n",
        "\n",
        "oof_list, test_proba_list = [], []\n",
        "for SEED in SEEDS:\n",
        "    teacher = cb.CatBoostClassifier(\n",
        "        iterations=400, depth=4, learning_rate=0.05, subsample=0.9,\n",
        "        colsample_bylevel=0.9, random_seed=SEED, verbose=0,\n",
        "    )\n",
        "    teacher.fit(orig_X[common_cols], orig_y)\n",
        "    X[\"teacher_pred\"] = teacher.predict_proba(X[common_cols])[:, 1]\n",
        "    X_test[\"teacher_pred\"] = teacher.predict_proba(X_test[common_cols])[:, 1]\n",
        "    adv_skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "    oof_adv = np.zeros(len(adv_y), dtype=float)\n",
        "    for tr_adv, val_adv in adv_skf.split(adv_X, adv_y):\n",
        "        adv_clf = lgb.LGBMClassifier(\n",
        "            objective=\"binary\", metric=\"auc\", learning_rate=0.05, n_estimators=400,\n",
        "            num_leaves=31, feature_fraction=0.9, bagging_fraction=0.9, bagging_freq=1,\n",
        "            min_data_in_leaf=30, random_state=SEED, n_jobs=-1,\n",
        "        )\n",
        "        adv_clf.fit(adv_X.iloc[tr_adv], adv_y[tr_adv])\n",
        "        oof_adv[val_adv] = adv_clf.predict_proba(adv_X.iloc[val_adv])[:, 1]\n",
        "    p_test_train = oof_adv[: len(X)]\n",
        "    w_train = p_test_train / (1.0 - p_test_train + 1e-3)\n",
        "    w_train = w_train / w_train.mean()\n",
        "    w_train = np.clip(w_train, 0.3, 3.0)\n",
        "    w_train = w_train / w_train.mean()\n",
        "    xgboost_params = {**xgboost_params, \"random_state\": SEED}\n",
        "    catboost_params = {**catboost_params, \"random_seed\": SEED}\n",
        "    lgbm_params = {**lgbm_params, \"random_state\": SEED}\n",
        "    hgb_params_s = {**hgb_params, \"random_state\": SEED}\n",
        "    models_run = {\n",
        "        XGBClassifier: xgboost_params,\n",
        "        CatBoostClassifier: catboost_params,\n",
        "        LGBMClassifier: lgbm_params,\n",
        "        HistGradientBoostingClassifier: hgb_params_s,\n",
        "    }\n",
        "    kf = StratifiedKFold(n_splits=NSPLITS, shuffle=True, random_state=SEED)\n",
        "    oof_train_model = {}\n",
        "    oof_test_model = {}\n",
        "    cv_auc_model = defaultdict(list)\n",
        "    for modelClass, param in models_run.items():\n",
        "        model_name = modelClass.__name__\n",
        "        oof_train = np.zeros(len(X))\n",
        "        oof_test = np.zeros(len(X_test))\n",
        "\n",
        "        for fold, (tr, val) in enumerate(kf.split(X, y)):\n",
        "            print(f\"FOLD {fold + 1}/{NSPLITS} - {model_name}\")\n",
        "\n",
        "            X_tr_raw, X_val_raw = X.iloc[tr], X.iloc[val]\n",
        "            y_tr, y_val = y.iloc[tr], y.iloc[val]\n",
        "\n",
        "            X_tr, X_val = fe_foldwise(X_tr_raw, X_val_raw, y_tr)\n",
        "\n",
        "            model = modelClass(**param)\n",
        "            if model_name == \"HistGradientBoostingClassifier\":\n",
        "                X_tr_fit = X_tr.select_dtypes(include=[np.number])\n",
        "                X_val_fit = X_val.select_dtypes(include=[np.number])\n",
        "                model.fit(X_tr_fit, y_tr, sample_weight=w_train[tr])\n",
        "                oof_train[val] = model.predict_proba(X_val_fit)[:, 1]\n",
        "                X_test_fe = fe_test(X_test, X_tr_raw, y_tr)\n",
        "                X_test_fit = X_test_fe.select_dtypes(include=[np.number])\n",
        "                oof_test += model.predict_proba(X_test_fit)[:, 1] / NSPLITS\n",
        "            else:\n",
        "                fit_kwargs = {\n",
        "                    \"X\": X_tr,\n",
        "                    \"y\": y_tr,\n",
        "                    \"eval_set\": [(X_val, y_val)],\n",
        "                    \"sample_weight\": w_train[tr],\n",
        "                }\n",
        "                if model_name != \"LGBMClassifier\":\n",
        "                    fit_kwargs[\"verbose\"] = 2000\n",
        "                if \"cat_features\" in inspect.signature(model.fit).parameters:\n",
        "                    cat_features = get_cat_feature_indices(X_tr)\n",
        "                    fit_kwargs[\"cat_features\"] = cat_features\n",
        "                model.fit(**fit_kwargs)\n",
        "                oof_train[val] = model.predict_proba(X_val)[:, 1]\n",
        "                X_test_fe = fe_test(X_test, X_tr_raw, y_tr)\n",
        "                oof_test += model.predict_proba(X_test_fe)[:, 1] / NSPLITS\n",
        "            cv_auc_model[model_name].append(roc_auc_score(y[val], oof_train[val]))\n",
        "\n",
        "        oof_train_model[model_name] = oof_train\n",
        "        oof_test_model[model_name] = oof_test\n",
        "\n",
        "    for modelClass in models_run.keys():\n",
        "        model_name = modelClass.__name__\n",
        "        print(f\"\\n{model_name} OOF AUC: {roc_auc_score(y, oof_train_model[model_name]):.6f}\")\n",
        "        print(\n",
        "            f\"{model_name} CV AUC mean: {np.mean(cv_auc_model[model_name]):.6f}, std: +-{np.std(cv_auc_model[model_name]):.5f}\"\n",
        "        )\n",
        "\n",
        "    X_oof_tr = pd.DataFrame.from_dict(oof_train_model)\n",
        "    X_oof_test = pd.DataFrame.from_dict(oof_test_model)\n",
        "    cols = list(X_oof_tr.columns)\n",
        "    use_meta = USE_LR_STACK or len(cols) >= 3\n",
        "    meta_auc, blend_auc = 0.0, 0.0\n",
        "    if use_meta:\n",
        "        meta = LogisticRegression(max_iter=500, random_state=SEED, class_weight=\"balanced\")\n",
        "        meta.fit(X_oof_tr, y, sample_weight=w_train)\n",
        "        oof_tr_meta = pd.Series(meta.predict_proba(X_oof_tr)[:, 1], index=X_oof_tr.index)\n",
        "        meta_auc = roc_auc_score(y, oof_tr_meta)\n",
        "    if len(cols) == 2:\n",
        "        a, b = X_oof_tr[cols[0]], X_oof_tr[cols[1]]\n",
        "        best_w, best_auc = 0.5, 0.0\n",
        "        for w in np.linspace(0, 1, 21):\n",
        "            blend = w * a + (1 - w) * b\n",
        "            auc = roc_auc_score(y, blend)\n",
        "            if auc > best_auc:\n",
        "                best_auc, best_w = auc, w\n",
        "        blend_auc = best_auc\n",
        "        oof_tr_blend = best_w * X_oof_tr[cols[0]] + (1 - best_w) * X_oof_tr[cols[1]]\n",
        "        oof_test_blend = best_w * X_oof_test[cols[0]] + (1 - best_w) * X_oof_test[cols[1]]\n",
        "    elif len(cols) >= 3 and not USE_LR_STACK:\n",
        "        grid = np.linspace(0, 1, 6)\n",
        "        best_auc, best_weights = 0.0, None\n",
        "        for w1 in grid:\n",
        "            for w2 in grid:\n",
        "                for w3 in grid:\n",
        "                    w4 = 1.0 - w1 - w2 - w3\n",
        "                    if w4 < -0.01 or (len(cols) == 3 and abs(w4) > 0.01):\n",
        "                        continue\n",
        "                    ws = [w1, w2, w3] if len(cols) == 3 else [w1, w2, w3, max(0, w4)]\n",
        "                    if len(cols) == 4:\n",
        "                        ws[3] = w4\n",
        "                    blend = sum(ws[i] * X_oof_tr[cols[i]] for i in range(len(cols)))\n",
        "                    auc = roc_auc_score(y, blend)\n",
        "                    if auc > best_auc:\n",
        "                        best_auc, best_weights = auc, ws.copy()\n",
        "        if best_weights is not None:\n",
        "            blend_auc = best_auc\n",
        "            oof_tr_blend = sum(best_weights[i] * X_oof_tr[cols[i]] for i in range(len(cols)))\n",
        "            oof_test_blend = sum(best_weights[i] * X_oof_test[cols[i]] for i in range(len(cols)))\n",
        "    use_blend = (len(cols) == 2) or (len(cols) >= 3 and not USE_LR_STACK and blend_auc > meta_auc)\n",
        "    if use_blend:\n",
        "        oof_tr_final = oof_tr_blend if len(cols) == 2 else (oof_tr_blend if blend_auc > meta_auc else oof_tr_meta)\n",
        "        oof_test_final = oof_test_blend if len(cols) == 2 else (oof_test_blend if blend_auc > meta_auc else meta.predict_proba(X_oof_test)[:, 1])\n",
        "        if len(cols) == 2:\n",
        "            print(f\"\\nBlend weight {cols[0]}={best_w:.2f}, {cols[1]}={1-best_w:.2f} -> OOF AUC: {blend_auc:.6f}\")\n",
        "        else:\n",
        "            chosen = \"blend\" if blend_auc > meta_auc else \"LR meta\"\n",
        "            print(f\"\\n{len(cols)}-model: {chosen} (blend={blend_auc:.6f}, meta={meta_auc:.6f}) -> OOF AUC: {max(blend_auc, meta_auc):.6f}\")\n",
        "    else:\n",
        "        oof_tr_final = oof_tr_meta\n",
        "        oof_test_final = pd.Series(meta.predict_proba(X_oof_test)[:, 1], index=X_oof_test.index)\n",
        "        print(f\"\\nStack (LR meta, {len(cols)} models) OOF AUC: {meta_auc:.6f}\")\n",
        "    oof_list.append(oof_tr_final.values if hasattr(oof_tr_final, 'values') else oof_tr_final)\n",
        "    test_proba_list.append(oof_test_final.values if hasattr(oof_test_final, 'values') else oof_test_final)\n",
        "\n",
        "oof = np.mean(oof_list, axis=0)\n",
        "test_proba = np.mean(test_proba_list, axis=0)\n",
        "N_STACK_MODELS = len(oof_train_model)\n",
        "print(f\"Submission: {N_STACK_MODELS}-model stack, {len(SEEDS)}-seed avg. test_proba shape: {test_proba.shape}\")\n",
        "\n",
        "test[\"id\"] = test.index\n",
        "if PSEUDO_LABEL:\n",
        "    mask_1 = test_proba > PSEUDO_THRESH\n",
        "    mask_0 = test_proba < (1 - PSEUDO_THRESH)\n",
        "    n_pl = int(mask_1.sum() + mask_0.sum())\n",
        "    if n_pl > 0:\n",
        "        X_pseudo = pd.concat([X_test[mask_1], X_test[mask_0]], ignore_index=True)\n",
        "        y_pseudo = np.concatenate([np.ones(mask_1.sum()), np.zeros(mask_0.sum())])\n",
        "        X_pl = pd.concat([X.reset_index(drop=True), X_pseudo], ignore_index=True)\n",
        "        y_pl = np.concatenate([y.values, y_pseudo])\n",
        "        w_pl = np.concatenate([w_train, PSEUDO_WEIGHT * np.ones(n_pl)])\n",
        "        w_pl = w_pl / w_pl.mean()\n",
        "        pl_seed = SEEDS[0]\n",
        "        kf_pl = StratifiedKFold(n_splits=NSPLITS, shuffle=True, random_state=pl_seed)\n",
        "        test_pl_list = []\n",
        "        for modelClass, param in models_run.items():\n",
        "            model_name = modelClass.__name__\n",
        "            params_pl = dict(param)\n",
        "            if \"random_state\" in params_pl:\n",
        "                params_pl[\"random_state\"] = pl_seed\n",
        "            if \"random_seed\" in params_pl:\n",
        "                params_pl[\"random_seed\"] = pl_seed\n",
        "            oof_test_pl = np.zeros(len(X_test))\n",
        "            for fold, (tr, val) in enumerate(kf_pl.split(X_pl, y_pl)):\n",
        "                X_tr_raw, X_val_raw = X_pl.iloc[tr], X_pl.iloc[val]\n",
        "                y_tr = pd.Series(y_pl[tr], index=X_tr_raw.index, name=ystr)\n",
        "                X_tr, X_val = fe_foldwise(X_tr_raw, X_val_raw, y_tr)\n",
        "                model = modelClass(**params_pl)\n",
        "                if model_name == \"HistGradientBoostingClassifier\":\n",
        "                    model.fit(X_tr.select_dtypes(include=[np.number]), y_pl[tr], sample_weight=w_pl[tr])\n",
        "                    X_test_fe = fe_test(X_test, X_tr_raw, y_tr)\n",
        "                    oof_test_pl += model.predict_proba(X_test_fe.select_dtypes(include=[np.number]))[:, 1] / NSPLITS\n",
        "                else:\n",
        "                    fit_kwargs = {\"X\": X_tr, \"y\": y_pl[tr], \"eval_set\": [(X_val, y_pl[val])], \"sample_weight\": w_pl[tr]}\n",
        "                    if model_name != \"LGBMClassifier\":\n",
        "                        fit_kwargs[\"verbose\"] = 2000\n",
        "                    if \"cat_features\" in inspect.signature(model.fit).parameters:\n",
        "                        fit_kwargs[\"cat_features\"] = get_cat_feature_indices(X_tr)\n",
        "                    model.fit(**fit_kwargs)\n",
        "                    X_test_fe = fe_test(X_test, X_tr_raw, y_tr)\n",
        "                    oof_test_pl += model.predict_proba(X_test_fe)[:, 1] / NSPLITS\n",
        "            test_pl_list.append(oof_test_pl)\n",
        "        test_proba_pl = np.mean(test_pl_list, axis=0)\n",
        "        test_proba = 0.6 * test_proba + 0.4 * test_proba_pl\n",
        "        print(f\"Pseudo-label: added {n_pl} samples, blended 0.6*pass1 + 0.4*pass2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix (OOF, threshold=0.5)\n",
            "Rows: true, Cols: predicted |  Absence   Presence\n",
            "[[315040  32506]\n",
            " [ 37233 245221]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred = (oof >= 0.5).astype(int)\n",
        "cm = confusion_matrix(y, y_pred)\n",
        "print(\"Confusion matrix (OOF, threshold=0.5)\")\n",
        "print(\"Rows: true, Cols: predicted |  Absence   Presence\")\n",
        "print(cm)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "plt.colorbar()\n",
        "plt.xticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.yticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
        "plt.title(\"Confusion matrix (OOF)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission saved (4-model blend): submission.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>630000</th>\n",
              "      <td>630000</td>\n",
              "      <td>0.956027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630001</th>\n",
              "      <td>630001</td>\n",
              "      <td>0.008281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630002</th>\n",
              "      <td>630002</td>\n",
              "      <td>0.988718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630003</th>\n",
              "      <td>630003</td>\n",
              "      <td>0.004832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630004</th>\n",
              "      <td>630004</td>\n",
              "      <td>0.186157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630005</th>\n",
              "      <td>630005</td>\n",
              "      <td>0.983570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630006</th>\n",
              "      <td>630006</td>\n",
              "      <td>0.005485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630007</th>\n",
              "      <td>630007</td>\n",
              "      <td>0.546530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630008</th>\n",
              "      <td>630008</td>\n",
              "      <td>0.993071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630009</th>\n",
              "      <td>630009</td>\n",
              "      <td>0.011185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  Heart Disease\n",
              "id                           \n",
              "630000  630000       0.956027\n",
              "630001  630001       0.008281\n",
              "630002  630002       0.988718\n",
              "630003  630003       0.004832\n",
              "630004  630004       0.186157\n",
              "630005  630005       0.983570\n",
              "630006  630006       0.005485\n",
              "630007  630007       0.546530\n",
              "630008  630008       0.993071\n",
              "630009  630009       0.011185"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub = pd.DataFrame({\"id\": test[\"id\"], \"Heart Disease\": test_proba})\n",
        "sub.to_csv(OUTPUT_DIR / \"submission.csv\", index=False)\n",
        "print(f\"Submission saved ({N_STACK_MODELS}-model blend): {OUTPUT_DIR / 'submission.csv'}\")\n",
        "sub.head(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
