{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicting Heart Disease\n",
        "\n",
        "## Score: .95370"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict, KFold\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import catboost as cb\n",
        "from catboost import CatBoostClassifier\n",
        "#%pip install torch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "DATA_DIR = Path(\"playground-series-s6e2\")\n",
        "OUTPUT_DIR = Path(\".\")\n",
        "n_splits = 5\n",
        "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (630000, 15)\n",
            "Test: (270000, 14)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Chest pain type</th>\n",
              "      <th>BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FBS over 120</th>\n",
              "      <th>EKG results</th>\n",
              "      <th>Max HR</th>\n",
              "      <th>Exercise angina</th>\n",
              "      <th>ST depression</th>\n",
              "      <th>Slope of ST</th>\n",
              "      <th>Number of vessels fluro</th>\n",
              "      <th>Thallium</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>152</td>\n",
              "      <td>239</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>325</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>160</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>134</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>140</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  Age  Sex  Chest pain type   BP  Cholesterol  FBS over 120  EKG results  \\\n",
              "0   0   58    1                4  152          239             0            0   \n",
              "1   1   52    1                1  125          325             0            2   \n",
              "2   2   56    0                2  160          188             0            2   \n",
              "3   3   44    0                3  134          229             0            2   \n",
              "4   4   58    1                4  140          234             0            2   \n",
              "\n",
              "   Max HR  Exercise angina  ST depression  Slope of ST  \\\n",
              "0     158                1            3.6            2   \n",
              "1     171                0            0.0            1   \n",
              "2     151                0            0.0            1   \n",
              "3     150                0            1.0            2   \n",
              "4     125                1            3.8            2   \n",
              "\n",
              "   Number of vessels fluro  Thallium Heart Disease  \n",
              "0                        2         7      Presence  \n",
              "1                        0         3       Absence  \n",
              "2                        0         3       Absence  \n",
              "3                        0         3       Absence  \n",
              "4                        3         3      Presence  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR / \"test.csv\")\n",
        "print(f\"Train: {train.shape}\")\n",
        "print(f\"Test: {test.shape}\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ol1v3_7dwns5u\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
            "[WinError 2] The system cannot find the file specified\n",
            "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
            "  warnings.warn(\n",
            "  File \"c:\\Users\\ol1v3_7dwns5u\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
            "    cpu_info = subprocess.run(\n",
            "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
            "        capture_output=True,\n",
            "        text=True,\n",
            "    )\n",
            "  File \"c:\\Users\\ol1v3_7dwns5u\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 554, in run\n",
            "    with Popen(*popenargs, **kwargs) as process:\n",
            "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\ol1v3_7dwns5u\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1039, in __init__\n",
            "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "                        pass_fds, cwd, env,\n",
            "                        ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "                        gid, gids, uid, umask,\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
            "                        start_new_session, process_group)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\ol1v3_7dwns5u\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1554, in _execute_child\n",
            "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
            "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
            "                             # no special security\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<4 lines>...\n",
            "                             cwd,\n",
            "                             ^^^^\n",
            "                             startupinfo)\n",
            "                             ^^^^^^^^^^^^\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features: 32 columns\n",
            "Target distribution: {0: 347546, 1: 282454}\n"
          ]
        }
      ],
      "source": [
        "target_col = \"Heart Disease\"\n",
        "id_col = \"id\"\n",
        "feature_cols = [c for c in train.columns if c not in (id_col, target_col)]\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(train[target_col])\n",
        "\n",
        "X_train = train[feature_cols].copy()\n",
        "X_test = test[feature_cols].copy()\n",
        "\n",
        "for col in feature_cols:\n",
        "    if X_train[col].isna().any() or X_test[col].isna().any():\n",
        "        med = X_train[col].median()\n",
        "        X_train[col] = X_train[col].fillna(med)\n",
        "        X_test[col] = X_test[col].fillna(med)\n",
        "\n",
        "X_train[\"chol_exercise\"] = X_train[\"Cholesterol\"] * X_train[\"Exercise angina\"]\n",
        "X_test[\"chol_exercise\"] = X_test[\"Cholesterol\"] * X_test[\"Exercise angina\"]\n",
        "X_train[\"st_slope\"] = X_train[\"ST depression\"] * X_train[\"Slope of ST\"]\n",
        "X_test[\"st_slope\"] = X_test[\"ST depression\"] * X_test[\"Slope of ST\"]\n",
        "X_train[\"hr_age\"] = X_train[\"Max HR\"] * X_train[\"Age\"]\n",
        "X_test[\"hr_age\"] = X_test[\"Max HR\"] * X_test[\"Age\"]\n",
        "X_train[\"bp_age\"] = X_train[\"BP\"] * X_train[\"Age\"]\n",
        "X_test[\"bp_age\"] = X_test[\"BP\"] * X_test[\"Age\"]\n",
        "\n",
        "te_cols = [\"Chest pain type\", \"Slope of ST\", \"Thallium\"]\n",
        "global_mean = float(y.mean())\n",
        "m = 20\n",
        "for col in te_cols:\n",
        "    agg = pd.DataFrame({\"_y\": y}).groupby(X_train[col])[\"_y\"].agg([\"mean\", \"count\"])\n",
        "    smoothed = (agg[\"count\"] * agg[\"mean\"] + m * global_mean) / (agg[\"count\"] + m)\n",
        "    X_train[col + \"_te\"] = X_train[col].map(smoothed).fillna(global_mean)\n",
        "    X_test[col + \"_te\"] = X_test[col].map(smoothed).fillna(global_mean)\n",
        "\n",
        "scaler_feat = StandardScaler()\n",
        "X_tr_s = scaler_feat.fit_transform(X_train)\n",
        "X_te_s = scaler_feat.transform(X_test)\n",
        "kmeans = KMeans(n_clusters=12, random_state=42, n_init=10)\n",
        "kmeans.fit(X_tr_s)\n",
        "for i in range(kmeans.n_clusters):\n",
        "    d_tr = np.linalg.norm(X_tr_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    d_te = np.linalg.norm(X_te_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    X_train[f\"dist_c{i}\"] = d_tr\n",
        "    X_test[f\"dist_c{i}\"] = d_te\n",
        "\n",
        "print(f\"Features: {len(X_train.columns)} columns\")\n",
        "print(f\"Target distribution: {pd.Series(y).value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best OOF AUC: 0.95507, params: {'depth': 6, 'lr': 0.05, 'min_data_in_leaf': 15}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\"depth\": [4, 5, 6], \"lr\": [0.03, 0.04, 0.05], \"min_data_in_leaf\": [15, 25, 35]}\n",
        "n_est = 800\n",
        "best_auc, best_params = 0, None\n",
        "for depth in param_grid[\"depth\"]:\n",
        "    for lr in param_grid[\"lr\"]:\n",
        "        for min_leaf in param_grid[\"min_data_in_leaf\"]:\n",
        "            m = cb.CatBoostClassifier(iterations=n_est, depth=depth, learning_rate=lr, min_data_in_leaf=min_leaf, subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "            oof = cross_val_predict(m, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "            auc = roc_auc_score(y, oof)\n",
        "            if auc > best_auc:\n",
        "                best_auc, best_params = auc, {\"depth\": depth, \"lr\": lr, \"min_data_in_leaf\": min_leaf}\n",
        "print(f\"Best OOF AUC: {best_auc:.5f}, params: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV AUC: 0.95517 (blend w_xgb=0.4)\n"
          ]
        }
      ],
      "source": [
        "model = cb.CatBoostClassifier(iterations=n_est, depth=best_params[\"depth\"], learning_rate=best_params[\"lr\"], min_data_in_leaf=best_params[\"min_data_in_leaf\"], subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "oof_cb = cross_val_predict(model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=n_est, max_depth=5, learning_rate=0.05, min_child_weight=20, subsample=0.75, colsample_bytree=0.75, random_state=42, eval_metric=\"auc\")\n",
        "oof_xgb = cross_val_predict(xgb_model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "best_w, best_auc = 0.0, roc_auc_score(y, oof_cb)\n",
        "for w in [0, 0.1, 0.2, 0.3, 0.4]:\n",
        "    oof_blend = (1 - w) * oof_cb + w * oof_xgb\n",
        "    auc = roc_auc_score(y, oof_blend)\n",
        "    if auc > best_auc:\n",
        "        best_auc, best_w = auc, w\n",
        "oof = (1 - best_w) * oof_cb + best_w * oof_xgb\n",
        "print(f\"CV AUC: {best_auc:.5f} (blend w_xgb={best_w})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train, y)\n",
        "xgb_model.fit(X_train, y)\n",
        "test_cb = model.predict_proba(X_test)[:, 1]\n",
        "test_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
        "test_proba = (1 - best_w) * test_cb + best_w * test_xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher model using 13 shared columns from original dataset\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 180000, number of negative: 420000\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009143 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 668\n",
            "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300000 -> initscore=-0.847298\n",
            "[LightGBM] [Info] Start training from score -0.847298\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 180000, number of negative: 420000\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008865 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 672\n",
            "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300000 -> initscore=-0.847298\n",
            "[LightGBM] [Info] Start training from score -0.847298\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 180000, number of negative: 420000\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011304 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 671\n",
            "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300000 -> initscore=-0.847298\n",
            "[LightGBM] [Info] Start training from score -0.847298\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Adversarial AUC (train vs test): 0.50147\n",
            "Sample weights (train-like vs test-like) -> min=0.350, max=2.793, mean=1.000\n",
            "FOLD 1/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90499\n",
            "[1499]\tvalidation_0-auc:0.95524\n",
            "FOLD 2/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90580\n",
            "[1499]\tvalidation_0-auc:0.95552\n",
            "FOLD 3/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90708\n",
            "[1499]\tvalidation_0-auc:0.95610\n",
            "FOLD 4/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90562\n",
            "[1499]\tvalidation_0-auc:0.95499\n",
            "FOLD 5/5 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90558\n",
            "[1499]\tvalidation_0-auc:0.95523\n",
            "FOLD 1/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713352\ttest: 0.6713531\tbest: 0.6713531 (0)\ttotal: 103ms\tremaining: 2m 33s\n",
            "1499:\tlearn: 0.2676097\ttest: 0.2682199\tbest: 0.2682199 (1499)\ttotal: 2m 24s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2682199412\n",
            "bestIteration = 1499\n",
            "\n",
            "FOLD 2/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713394\ttest: 0.6713447\tbest: 0.6713447 (0)\ttotal: 108ms\tremaining: 2m 42s\n",
            "1499:\tlearn: 0.2678219\ttest: 0.2673233\tbest: 0.2673233 (1498)\ttotal: 2m 28s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.267323266\n",
            "bestIteration = 1498\n",
            "\n",
            "Shrink model to first 1499 iterations.\n",
            "FOLD 3/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6714011\ttest: 0.6712825\tbest: 0.6712825 (0)\ttotal: 140ms\tremaining: 3m 29s\n",
            "1499:\tlearn: 0.2683232\ttest: 0.2655683\tbest: 0.2655683 (1499)\ttotal: 2m 35s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.265568329\n",
            "bestIteration = 1499\n",
            "\n",
            "FOLD 4/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713478\ttest: 0.6713436\tbest: 0.6713436 (0)\ttotal: 102ms\tremaining: 2m 32s\n",
            "1499:\tlearn: 0.2675293\ttest: 0.2689226\tbest: 0.2689226 (1499)\ttotal: 2m 24s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2689226004\n",
            "bestIteration = 1499\n",
            "\n",
            "FOLD 5/5 - CatBoostClassifier\n",
            "0:\tlearn: 0.6714200\ttest: 0.6712798\tbest: 0.6712798 (0)\ttotal: 108ms\tremaining: 2m 41s\n",
            "1499:\tlearn: 0.2676917\ttest: 0.2679777\tbest: 0.2679777 (1499)\ttotal: 2m 23s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2679777122\n",
            "bestIteration = 1499\n",
            "\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955415\n",
            "XGBClassifier CV AUC mean: 0.955416, std: +-0.00038\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955493\n",
            "CatBoostClassifier CV AUC mean: 0.955494, std: +-0.00037\n",
            "\n",
            "Stack (LR meta) OOF AUC: 0.955548\n",
            "Submission: 2-model blend. test_proba shape: (270000,)\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import inspect\n",
        "\n",
        "SEED = 42\n",
        "NSPLITS = 5\n",
        "USE_LR_STACK = True   # True = LR meta-learner (like other notebook), False = tuned weight blend\n",
        "DROP_BP_MAX_HR = False  # True = drop raw bp/max_hr (only keep derived features), from other notebook\n",
        "\n",
        "# Reload data Kaggle-style (lowercase columns, id as index)\n",
        "path = DATA_DIR\n",
        "dfs = []\n",
        "for fl in (\"train.csv\", \"test.csv\"):\n",
        "    df = pd.read_csv(path / fl, index_col=0)\n",
        "    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns.tolist()]\n",
        "    dfs.append(df)\n",
        "train, test = dfs\n",
        "\n",
        "ystr = train.columns[-1]\n",
        "base_features = [c for c in train.columns if c != ystr]\n",
        "\n",
        "cols2comb = [\n",
        "    \"exercise_angina\", \"thallium\", \"chest_pain_type\",\n",
        "    \"slope_of_st\", \"sex\", \"st_depression\", \"number_of_vessels_fluro\",\n",
        "    \"ekg_results\", \"fbs_over_120\",\n",
        "]\n",
        "\n",
        "statmetrics = [\"mean\", \"count\"]\n",
        "\n",
        "X = train.drop(columns=ystr)\n",
        "y = (train[ystr] == \"Presence\").astype(int)\n",
        "\n",
        "X_test = test.copy()\n",
        "\n",
        "# Teacher model from original clinical dataset -> prior feature\n",
        "orig_path = DATA_DIR.parent / \"original-data\" / \"Heart_Disease_Prediction.csv\"\n",
        "orig_df = pd.read_csv(orig_path)\n",
        "orig_df.columns = [c.strip().lower().replace(\" \", \"_\") for c in orig_df.columns]\n",
        "orig_ystr = orig_df.columns[-1]\n",
        "orig_X = orig_df.drop(columns=orig_ystr)\n",
        "orig_y = (orig_df[orig_ystr] == \"Presence\").astype(int)\n",
        "\n",
        "common_cols = sorted(set(orig_X.columns) & set(X.columns))\n",
        "print(f\"Teacher model using {len(common_cols)} shared columns from original dataset\")\n",
        "\n",
        "teacher = cb.CatBoostClassifier(\n",
        "    iterations=400,\n",
        "    depth=4,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.9,\n",
        "    colsample_bylevel=0.9,\n",
        "    random_seed=SEED,\n",
        "    verbose=0,\n",
        ")\n",
        "teacher.fit(orig_X[common_cols], orig_y)\n",
        "\n",
        "X[\"teacher_pred\"] = teacher.predict_proba(X[common_cols])[:, 1]\n",
        "X_test[\"teacher_pred\"] = teacher.predict_proba(X_test[common_cols])[:, 1]\n",
        "\n",
        "# Adversarial validation: train vs test\n",
        "adv_X = pd.concat([X, X_test], axis=0).reset_index(drop=True)\n",
        "adv_y = np.concatenate([\n",
        "    np.zeros(len(X), dtype=int),\n",
        "    np.ones(len(X_test), dtype=int),\n",
        "])\n",
        "adv_skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "oof_adv = np.zeros(len(adv_y), dtype=float)\n",
        "for tr_adv, val_adv in adv_skf.split(adv_X, adv_y):\n",
        "    adv_clf = lgb.LGBMClassifier(\n",
        "        objective=\"binary\",\n",
        "        metric=\"auc\",\n",
        "        learning_rate=0.05,\n",
        "        n_estimators=400,\n",
        "        num_leaves=31,\n",
        "        feature_fraction=0.9,\n",
        "        bagging_fraction=0.9,\n",
        "        bagging_freq=1,\n",
        "        min_data_in_leaf=30,\n",
        "        random_state=SEED,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    adv_clf.fit(adv_X.iloc[tr_adv], adv_y[tr_adv])\n",
        "    oof_adv[val_adv] = adv_clf.predict_proba(adv_X.iloc[val_adv])[:, 1]\n",
        "\n",
        "auc_adv = roc_auc_score(adv_y, oof_adv)\n",
        "print(f\"Adversarial AUC (train vs test): {auc_adv:.5f}\")\n",
        "\n",
        "p_test_train = oof_adv[: len(X)]\n",
        "eps = 1e-3\n",
        "w_train = p_test_train / (1.0 - p_test_train + eps)\n",
        "w_train = w_train / w_train.mean()\n",
        "print(\n",
        "    f\"Sample weights (train-like vs test-like) -> min={w_train.min():.3f}, max={w_train.max():.3f}, mean={w_train.mean():.3f}\"\n",
        ")\n",
        "\n",
        "\n",
        "def get_cat_feature_indices(X_):\n",
        "    return [i for i, c in enumerate(X_.columns) if c.startswith(\"CAT_\")]\n",
        "\n",
        "\n",
        "def fe_foldwise(X_tr, X_val, y_tr):\n",
        "    X_tr = X_tr.copy()\n",
        "    X_val = X_val.copy()\n",
        "\n",
        "    temp = pd.concat([X_tr, y_tr], axis=1)\n",
        "\n",
        "    # casting\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"age>55\"] = (df[\"age\"] > 55).astype(int)\n",
        "        for col in df.columns:\n",
        "            if col == \"teacher_pred\":\n",
        "                continue\n",
        "            colname = f\"CAT_{col}\"\n",
        "            df[colname] = df[col].astype(str).astype(\"category\")\n",
        "\n",
        "    # numeric interactions and derived + bin features (from 0.954 notebook)\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"chest_pain_type_bin\"] = (df[\"chest_pain_type\"] >= 3).astype(int)\n",
        "        df[\"st_depression_bin\"] = (df[\"st_depression\"] >= 2).astype(int)\n",
        "        df[\"number_of_vessels_fluro_bin\"] = (df[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "        df[\"hr_age\"] = df[\"max_hr\"] * df[\"age\"]\n",
        "        df[\"bp_age\"] = df[\"bp\"] * df[\"age\"]\n",
        "        df[\"st_slope\"] = df[\"st_depression\"] * df[\"slope_of_st\"]\n",
        "        df[\"chol_exercise\"] = df[\"cholesterol\"] * df[\"exercise_angina\"]\n",
        "        pred_max = (220 - df[\"age\"]).clip(lower=10)\n",
        "        df[\"max_hr_pct_pred\"] = df[\"max_hr\"] / pred_max\n",
        "        df[\"risk_sum\"] = df[\"number_of_vessels_fluro\"] + df[\"thallium\"] + df[\"exercise_angina\"]\n",
        "\n",
        "    # target statistics + smoothed target encoding\n",
        "    global_mean = float(y_tr.mean())\n",
        "    m_smooth = 20\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            cname = f\"target_{bf}_{s}\"\n",
        "            X_tr[cname] = X_tr[bf].map(stats[s])\n",
        "            X_val[cname] = X_val[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_tr[f\"target_{bf}_smooth\"] = X_tr[bf].map(smoothed).fillna(global_mean)\n",
        "        X_val[f\"target_{bf}_smooth\"] = X_val[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    # categorical combinations\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_tr[c2].max(), X_val[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_tr[cname] = (\n",
        "                (X_tr[c1] + 1 + (X_tr[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "            X_val[cname] = (\n",
        "                (X_val[c1] + 1 + (X_val[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    if DROP_BP_MAX_HR:\n",
        "        X_tr = X_tr.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "        X_val = X_val.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "    return X_tr, X_val\n",
        "\n",
        "\n",
        "def fe_test(X_test_, X_train_, y_train_):\n",
        "    X_test_ = X_test_.copy()\n",
        "    temp = pd.concat([X_train_, y_train_], axis=1)\n",
        "\n",
        "    X_test_[\"age>55\"] = (X_test_[\"age\"] > 55).astype(int)\n",
        "    for col in X_test_.columns:\n",
        "        if col == \"teacher_pred\":\n",
        "            continue\n",
        "        colname = f\"CAT_{col}\"\n",
        "        X_test_[colname] = X_test_[col].astype(str).astype(\"category\")\n",
        "\n",
        "    X_test_[\"chest_pain_type_bin\"] = (X_test_[\"chest_pain_type\"] >= 3).astype(int)\n",
        "    X_test_[\"st_depression_bin\"] = (X_test_[\"st_depression\"] >= 2).astype(int)\n",
        "    X_test_[\"number_of_vessels_fluro_bin\"] = (X_test_[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "    X_test_[\"hr_age\"] = X_test_[\"max_hr\"] * X_test_[\"age\"]\n",
        "    X_test_[\"bp_age\"] = X_test_[\"bp\"] * X_test_[\"age\"]\n",
        "    X_test_[\"st_slope\"] = X_test_[\"st_depression\"] * X_test_[\"slope_of_st\"]\n",
        "    X_test_[\"chol_exercise\"] = X_test_[\"cholesterol\"] * X_test_[\"exercise_angina\"]\n",
        "    pred_max = (220 - X_test_[\"age\"]).clip(lower=10)\n",
        "    X_test_[\"max_hr_pct_pred\"] = X_test_[\"max_hr\"] / pred_max\n",
        "    X_test_[\"risk_sum\"] = X_test_[\"number_of_vessels_fluro\"] + X_test_[\"thallium\"] + X_test_[\"exercise_angina\"]\n",
        "\n",
        "    global_mean = float(y_train_.mean())\n",
        "    m_smooth = 20\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            X_test_[f\"target_{bf}_{s}\"] = X_test_[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_test_[f\"target_{bf}_smooth\"] = X_test_[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_train_[c2].max(), X_test_[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_test_[cname] = (\n",
        "                (X_test_[c1] + 1 + (X_test_[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    if DROP_BP_MAX_HR:\n",
        "        X_test_ = X_test_.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "    return X_test_\n",
        "\n",
        "\n",
        "xgboost_params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"auc\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"max_depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"colsample_bytree\": 0.9,\n",
        "    \"n_estimators\": 1500,\n",
        "    \"min_child_weight\": 10,\n",
        "    \"gamma\": 1,\n",
        "    \"reg_lambda\": 0.01,\n",
        "    \"reg_alpha\": 1.5,\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"n_jobs\": -1,\n",
        "    \"random_state\": SEED,\n",
        "    \"early_stopping_rounds\": 80,\n",
        "    \"enable_categorical\": True,\n",
        "}\n",
        "\n",
        "catboost_params = {\n",
        "    \"loss_function\": \"Logloss\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"iterations\": 1500,\n",
        "    \"min_data_in_leaf\": 1,\n",
        "    \"l2_leaf_reg\": 1.002,\n",
        "    \"thread_count\": -1,\n",
        "    \"random_seed\": SEED,\n",
        "    \"early_stopping_rounds\": 80,\n",
        "    \"bootstrap_type\": \"Bernoulli\",\n",
        "}\n",
        "\n",
        "models = {\n",
        "    XGBClassifier: xgboost_params,\n",
        "    CatBoostClassifier: catboost_params,\n",
        "}\n",
        "\n",
        "kf = KFold(n_splits=NSPLITS, shuffle=True, random_state=SEED)\n",
        "\n",
        "oof_train_model = {}\n",
        "oof_test_model = {}\n",
        "cv_auc_model = defaultdict(list)\n",
        "\n",
        "for modelClass, param in models.items():\n",
        "    model_name = modelClass.__name__\n",
        "    oof_train = np.zeros(len(X))\n",
        "    oof_test = np.zeros(len(X_test))\n",
        "\n",
        "    for fold, (tr, val) in enumerate(kf.split(X)):\n",
        "        print(f\"FOLD {fold + 1}/{NSPLITS} - {model_name}\")\n",
        "\n",
        "        X_tr_raw, X_val_raw = X.iloc[tr], X.iloc[val]\n",
        "        y_tr, y_val = y.iloc[tr], y.iloc[val]\n",
        "\n",
        "        X_tr, X_val = fe_foldwise(X_tr_raw, X_val_raw, y_tr)\n",
        "\n",
        "        model = modelClass(**param)\n",
        "        fit_kwargs = {\n",
        "            \"X\": X_tr,\n",
        "            \"y\": y_tr,\n",
        "            \"eval_set\": [(X_val, y_val)],\n",
        "            \"sample_weight\": w_train[tr],\n",
        "        }\n",
        "        if model_name != \"LGBMClassifier\":\n",
        "            fit_kwargs[\"verbose\"] = 2000\n",
        "        if \"cat_features\" in inspect.signature(model.fit).parameters:\n",
        "            cat_features = get_cat_feature_indices(X_tr)\n",
        "            fit_kwargs[\"cat_features\"] = cat_features\n",
        "        model.fit(**fit_kwargs)\n",
        "        oof_train[val] = model.predict_proba(X_val)[:, 1]\n",
        "        X_test_fe = fe_test(X_test, X_tr_raw, y_tr)\n",
        "        oof_test += model.predict_proba(X_test_fe)[:, 1] / NSPLITS\n",
        "        cv_auc_model[model_name].append(roc_auc_score(y[val], oof_train[val]))\n",
        "\n",
        "    oof_train_model[model_name] = oof_train\n",
        "    oof_test_model[model_name] = oof_test\n",
        "\n",
        "# Evaluation per model\n",
        "for modelClass in models.keys():\n",
        "    model_name = modelClass.__name__\n",
        "    print(f\"\\n{model_name} OOF AUC: {roc_auc_score(y, oof_train_model[model_name]):.6f}\")\n",
        "    print(\n",
        "        f\"{model_name} CV AUC mean: {np.mean(cv_auc_model[model_name]):.6f}, std: +-{np.std(cv_auc_model[model_name]):.5f}\"\n",
        "    )\n",
        "\n",
        "# Stack: LR meta-learner on OOF (adopted from other notebook) or tuned weight blend\n",
        "X_oof_tr = pd.DataFrame.from_dict(oof_train_model)\n",
        "X_oof_test = pd.DataFrame.from_dict(oof_test_model)\n",
        "if USE_LR_STACK:\n",
        "    meta = LogisticRegression(max_iter=500, random_state=SEED)\n",
        "    meta.fit(X_oof_tr, y, sample_weight=w_train)\n",
        "    oof_tr_final = pd.Series(meta.predict_proba(X_oof_tr)[:, 1], index=X_oof_tr.index)\n",
        "    oof_test_final = pd.Series(meta.predict_proba(X_oof_test)[:, 1], index=X_oof_test.index)\n",
        "    stack_auc = roc_auc_score(y, oof_tr_final)\n",
        "    print(f\"\\nStack (LR meta) OOF AUC: {stack_auc:.6f}\")\n",
        "else:\n",
        "    cols = list(X_oof_tr.columns)\n",
        "    a, b = X_oof_tr[cols[0]], X_oof_tr[cols[1]]\n",
        "    best_w, best_auc = 0.5, 0.0\n",
        "    for w in np.linspace(0, 1, 21):\n",
        "        blend = w * a + (1 - w) * b\n",
        "        auc = roc_auc_score(y, blend)\n",
        "        if auc > best_auc:\n",
        "            best_auc, best_w = auc, w\n",
        "    oof_tr_final = best_w * X_oof_tr[cols[0]] + (1 - best_w) * X_oof_tr[cols[1]]\n",
        "    oof_test_final = best_w * X_oof_test[cols[0]] + (1 - best_w) * X_oof_test[cols[1]]\n",
        "    print(f\"\\nBlend weight {cols[0]}={best_w:.2f}, {cols[1]}={1-best_w:.2f} -> OOF AUC: {best_auc:.6f}\")\n",
        "\n",
        "# Set variables used by later cells\n",
        "oof = oof_tr_final.values\n",
        "test_proba = oof_test_final.values\n",
        "N_STACK_MODELS = len(oof_train_model)\n",
        "print(f\"Submission: {N_STACK_MODELS}-model blend. test_proba shape: {test_proba.shape}\")\n",
        "\n",
        "# Ensure id column exists for submission\n",
        "test[\"id\"] = test.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix (OOF, threshold=0.5)\n",
            "Rows: true, Cols: predicted |  Absence   Presence\n",
            "[[314832  32714]\n",
            " [ 37234 245220]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred = (oof >= 0.5).astype(int)\n",
        "cm = confusion_matrix(y, y_pred)\n",
        "print(\"Confusion matrix (OOF, threshold=0.5)\")\n",
        "print(\"Rows: true, Cols: predicted |  Absence   Presence\")\n",
        "print(cm)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "plt.colorbar()\n",
        "plt.xticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.yticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
        "plt.title(\"Confusion matrix (OOF)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission saved (2-model blend): submission.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>630000</th>\n",
              "      <td>630000</td>\n",
              "      <td>0.947295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630001</th>\n",
              "      <td>630001</td>\n",
              "      <td>0.040031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630002</th>\n",
              "      <td>630002</td>\n",
              "      <td>0.958731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630003</th>\n",
              "      <td>630003</td>\n",
              "      <td>0.038921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630004</th>\n",
              "      <td>630004</td>\n",
              "      <td>0.131712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630005</th>\n",
              "      <td>630005</td>\n",
              "      <td>0.958233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630006</th>\n",
              "      <td>630006</td>\n",
              "      <td>0.038656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630007</th>\n",
              "      <td>630007</td>\n",
              "      <td>0.579937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630008</th>\n",
              "      <td>630008</td>\n",
              "      <td>0.960202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630009</th>\n",
              "      <td>630009</td>\n",
              "      <td>0.040743</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  Heart Disease\n",
              "id                           \n",
              "630000  630000       0.947295\n",
              "630001  630001       0.040031\n",
              "630002  630002       0.958731\n",
              "630003  630003       0.038921\n",
              "630004  630004       0.131712\n",
              "630005  630005       0.958233\n",
              "630006  630006       0.038656\n",
              "630007  630007       0.579937\n",
              "630008  630008       0.960202\n",
              "630009  630009       0.040743"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub = pd.DataFrame({\"id\": test[\"id\"], \"Heart Disease\": test_proba})\n",
        "sub.to_csv(OUTPUT_DIR / \"submission.csv\", index=False)\n",
        "print(f\"Submission saved ({N_STACK_MODELS}-model blend): {OUTPUT_DIR / 'submission.csv'}\")\n",
        "sub.head(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
