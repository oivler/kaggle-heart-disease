{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicting Heart Disease\n",
        "\n",
        "## Score: .95378"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict, KFold\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import catboost as cb\n",
        "from catboost import CatBoostClassifier\n",
        "#%pip install torch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "DATA_DIR = Path(\"playground-series-s6e2\")\n",
        "OUTPUT_DIR = Path(\".\")\n",
        "n_splits = 5\n",
        "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (630000, 15)\n",
            "Test: (270000, 14)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Chest pain type</th>\n",
              "      <th>BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FBS over 120</th>\n",
              "      <th>EKG results</th>\n",
              "      <th>Max HR</th>\n",
              "      <th>Exercise angina</th>\n",
              "      <th>ST depression</th>\n",
              "      <th>Slope of ST</th>\n",
              "      <th>Number of vessels fluro</th>\n",
              "      <th>Thallium</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>152</td>\n",
              "      <td>239</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>325</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>160</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>134</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>140</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  Age  Sex  Chest pain type   BP  Cholesterol  FBS over 120  EKG results  \\\n",
              "0   0   58    1                4  152          239             0            0   \n",
              "1   1   52    1                1  125          325             0            2   \n",
              "2   2   56    0                2  160          188             0            2   \n",
              "3   3   44    0                3  134          229             0            2   \n",
              "4   4   58    1                4  140          234             0            2   \n",
              "\n",
              "   Max HR  Exercise angina  ST depression  Slope of ST  \\\n",
              "0     158                1            3.6            2   \n",
              "1     171                0            0.0            1   \n",
              "2     151                0            0.0            1   \n",
              "3     150                0            1.0            2   \n",
              "4     125                1            3.8            2   \n",
              "\n",
              "   Number of vessels fluro  Thallium Heart Disease  \n",
              "0                        2         7      Presence  \n",
              "1                        0         3       Absence  \n",
              "2                        0         3       Absence  \n",
              "3                        0         3       Absence  \n",
              "4                        3         3      Presence  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR / \"test.csv\")\n",
        "print(f\"Train: {train.shape}\")\n",
        "print(f\"Test: {test.shape}\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features: 32 columns\n",
            "Target distribution: {0: 347546, 1: 282454}\n"
          ]
        }
      ],
      "source": [
        "target_col = \"Heart Disease\"\n",
        "id_col = \"id\"\n",
        "feature_cols = [c for c in train.columns if c not in (id_col, target_col)]\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(train[target_col])\n",
        "\n",
        "X_train = train[feature_cols].copy()\n",
        "X_test = test[feature_cols].copy()\n",
        "\n",
        "for col in feature_cols:\n",
        "    if X_train[col].isna().any() or X_test[col].isna().any():\n",
        "        med = X_train[col].median()\n",
        "        X_train[col] = X_train[col].fillna(med)\n",
        "        X_test[col] = X_test[col].fillna(med)\n",
        "\n",
        "X_train[\"chol_exercise\"] = X_train[\"Cholesterol\"] * X_train[\"Exercise angina\"]\n",
        "X_test[\"chol_exercise\"] = X_test[\"Cholesterol\"] * X_test[\"Exercise angina\"]\n",
        "X_train[\"st_slope\"] = X_train[\"ST depression\"] * X_train[\"Slope of ST\"]\n",
        "X_test[\"st_slope\"] = X_test[\"ST depression\"] * X_test[\"Slope of ST\"]\n",
        "X_train[\"hr_age\"] = X_train[\"Max HR\"] * X_train[\"Age\"]\n",
        "X_test[\"hr_age\"] = X_test[\"Max HR\"] * X_test[\"Age\"]\n",
        "X_train[\"bp_age\"] = X_train[\"BP\"] * X_train[\"Age\"]\n",
        "X_test[\"bp_age\"] = X_test[\"BP\"] * X_test[\"Age\"]\n",
        "\n",
        "te_cols = [\"Chest pain type\", \"Slope of ST\", \"Thallium\"]\n",
        "global_mean = float(y.mean())\n",
        "m = 20\n",
        "for col in te_cols:\n",
        "    agg = pd.DataFrame({\"_y\": y}).groupby(X_train[col])[\"_y\"].agg([\"mean\", \"count\"])\n",
        "    smoothed = (agg[\"count\"] * agg[\"mean\"] + m * global_mean) / (agg[\"count\"] + m)\n",
        "    X_train[col + \"_te\"] = X_train[col].map(smoothed).fillna(global_mean)\n",
        "    X_test[col + \"_te\"] = X_test[col].map(smoothed).fillna(global_mean)\n",
        "\n",
        "scaler_feat = StandardScaler()\n",
        "X_tr_s = scaler_feat.fit_transform(X_train)\n",
        "X_te_s = scaler_feat.transform(X_test)\n",
        "kmeans = KMeans(n_clusters=12, random_state=42, n_init=10)\n",
        "kmeans.fit(X_tr_s)\n",
        "for i in range(kmeans.n_clusters):\n",
        "    d_tr = np.linalg.norm(X_tr_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    d_te = np.linalg.norm(X_te_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    X_train[f\"dist_c{i}\"] = d_tr\n",
        "    X_test[f\"dist_c{i}\"] = d_te\n",
        "\n",
        "print(f\"Features: {len(X_train.columns)} columns\")\n",
        "print(f\"Target distribution: {pd.Series(y).value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best OOF AUC: 0.95507, params: {'depth': 6, 'lr': 0.05, 'min_data_in_leaf': 15}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\"depth\": [4, 5, 6], \"lr\": [0.03, 0.04, 0.05], \"min_data_in_leaf\": [15, 25, 35]}\n",
        "n_est = 800\n",
        "best_auc, best_params = 0, None\n",
        "for depth in param_grid[\"depth\"]:\n",
        "    for lr in param_grid[\"lr\"]:\n",
        "        for min_leaf in param_grid[\"min_data_in_leaf\"]:\n",
        "            m = cb.CatBoostClassifier(iterations=n_est, depth=depth, learning_rate=lr, min_data_in_leaf=min_leaf, subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "            oof = cross_val_predict(m, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "            auc = roc_auc_score(y, oof)\n",
        "            if auc > best_auc:\n",
        "                best_auc, best_params = auc, {\"depth\": depth, \"lr\": lr, \"min_data_in_leaf\": min_leaf}\n",
        "print(f\"Best OOF AUC: {best_auc:.5f}, params: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV AUC: 0.95517 (blend w_xgb=0.4)\n"
          ]
        }
      ],
      "source": [
        "model = cb.CatBoostClassifier(iterations=n_est, depth=best_params[\"depth\"], learning_rate=best_params[\"lr\"], min_data_in_leaf=best_params[\"min_data_in_leaf\"], subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "oof_cb = cross_val_predict(model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=n_est, max_depth=5, learning_rate=0.05, min_child_weight=20, subsample=0.75, colsample_bytree=0.75, random_state=42, eval_metric=\"auc\")\n",
        "oof_xgb = cross_val_predict(xgb_model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "best_w, best_auc = 0.0, roc_auc_score(y, oof_cb)\n",
        "for w in [0, 0.1, 0.2, 0.3, 0.4]:\n",
        "    oof_blend = (1 - w) * oof_cb + w * oof_xgb\n",
        "    auc = roc_auc_score(y, oof_blend)\n",
        "    if auc > best_auc:\n",
        "        best_auc, best_w = auc, w\n",
        "oof = (1 - best_w) * oof_cb + best_w * oof_xgb\n",
        "print(f\"CV AUC: {best_auc:.5f} (blend w_xgb={best_w})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train, y)\n",
        "xgb_model.fit(X_train, y)\n",
        "test_cb = model.predict_proba(X_test)[:, 1]\n",
        "test_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
        "test_proba = (1 - best_w) * test_cb + best_w * test_xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher model using 13 shared columns from original dataset\n",
            "Adversarial AUC (train vs test): 0.50147\n",
            "Sample weights (train-like vs test-like) -> min=0.350, max=2.793, mean=1.000\n",
            "FOLD 1/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90587\n",
            "[1999]\tvalidation_0-auc:0.95570\n",
            "FOLD 2/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90476\n",
            "[1999]\tvalidation_0-auc:0.95458\n",
            "FOLD 3/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90604\n",
            "[1999]\tvalidation_0-auc:0.95630\n",
            "FOLD 4/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90532\n",
            "[1999]\tvalidation_0-auc:0.95468\n",
            "FOLD 5/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90749\n",
            "[1999]\tvalidation_0-auc:0.95600\n",
            "FOLD 6/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90715\n",
            "[1999]\tvalidation_0-auc:0.95592\n",
            "FOLD 7/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90602\n",
            "[1776]\tvalidation_0-auc:0.95587\n",
            "FOLD 8/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90472\n",
            "[1999]\tvalidation_0-auc:0.95500\n",
            "FOLD 9/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90544\n",
            "[1677]\tvalidation_0-auc:0.95505\n",
            "FOLD 1/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6715027\ttest: 0.6715358\tbest: 0.6715358 (0)\ttotal: 131ms\tremaining: 4m 22s\n",
            "1999:\tlearn: 0.2675424\ttest: 0.2667633\tbest: 0.2667632 (1998)\ttotal: 3m 56s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2667632299\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 2/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6715244\ttest: 0.6715107\tbest: 0.6715107 (0)\ttotal: 127ms\tremaining: 4m 14s\n",
            "1999:\tlearn: 0.2670879\ttest: 0.2699484\tbest: 0.2699484 (1999)\ttotal: 3m 57s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2699483654\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 3/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6715197\ttest: 0.6714802\tbest: 0.6714802 (0)\ttotal: 140ms\tremaining: 4m 39s\n",
            "1999:\tlearn: 0.2677436\ttest: 0.2651223\tbest: 0.2651223 (1999)\ttotal: 3m 50s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2651222902\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 4/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6714954\ttest: 0.6715398\tbest: 0.6715398 (0)\ttotal: 125ms\tremaining: 4m 9s\n",
            "1999:\tlearn: 0.2671895\ttest: 0.2692928\tbest: 0.2692928 (1999)\ttotal: 3m 55s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2692928034\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 5/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6715417\ttest: 0.6714739\tbest: 0.6714739 (0)\ttotal: 124ms\tremaining: 4m 8s\n",
            "1999:\tlearn: 0.2676575\ttest: 0.2654751\tbest: 0.2654749 (1998)\ttotal: 3m 49s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2654748631\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 6/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6715362\ttest: 0.6714143\tbest: 0.6714143 (0)\ttotal: 130ms\tremaining: 4m 19s\n",
            "1999:\tlearn: 0.2676499\ttest: 0.2662949\tbest: 0.2662949 (1999)\ttotal: 3m 57s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2662949485\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 7/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6715627\ttest: 0.6714544\tbest: 0.6714544 (0)\ttotal: 124ms\tremaining: 4m 8s\n",
            "1999:\tlearn: 0.2676598\ttest: 0.2659935\tbest: 0.2659935 (1999)\ttotal: 4m 1s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2659935166\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 8/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6715335\ttest: 0.6714332\tbest: 0.6714332 (0)\ttotal: 137ms\tremaining: 4m 32s\n",
            "1999:\tlearn: 0.2673558\ttest: 0.2685909\tbest: 0.2685909 (1999)\ttotal: 3m 57s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2685909145\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 9/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6715413\ttest: 0.6714551\tbest: 0.6714551 (0)\ttotal: 122ms\tremaining: 4m 4s\n",
            "1999:\tlearn: 0.2672981\ttest: 0.2685131\tbest: 0.2685127 (1997)\ttotal: 3m 55s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2685127117\n",
            "bestIteration = 1997\n",
            "\n",
            "Shrink model to first 1998 iterations.\n",
            "FOLD 1/9 - LGBMClassifier\n",
            "FOLD 2/9 - LGBMClassifier\n",
            "FOLD 3/9 - LGBMClassifier\n",
            "FOLD 4/9 - LGBMClassifier\n",
            "FOLD 5/9 - LGBMClassifier\n",
            "FOLD 6/9 - LGBMClassifier\n",
            "FOLD 7/9 - LGBMClassifier\n",
            "FOLD 8/9 - LGBMClassifier\n",
            "FOLD 9/9 - LGBMClassifier\n",
            "FOLD 1/9 - HistGradientBoostingClassifier\n",
            "FOLD 2/9 - HistGradientBoostingClassifier\n",
            "FOLD 3/9 - HistGradientBoostingClassifier\n",
            "FOLD 4/9 - HistGradientBoostingClassifier\n",
            "FOLD 5/9 - HistGradientBoostingClassifier\n",
            "FOLD 6/9 - HistGradientBoostingClassifier\n",
            "FOLD 7/9 - HistGradientBoostingClassifier\n",
            "FOLD 8/9 - HistGradientBoostingClassifier\n",
            "FOLD 9/9 - HistGradientBoostingClassifier\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955451\n",
            "XGBClassifier CV AUC mean: 0.955456, std: +-0.00060\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955573\n",
            "CatBoostClassifier CV AUC mean: 0.955577, std: +-0.00061\n",
            "\n",
            "LGBMClassifier OOF AUC: 0.954979\n",
            "LGBMClassifier CV AUC mean: 0.954983, std: +-0.00060\n",
            "\n",
            "HistGradientBoostingClassifier OOF AUC: 0.955300\n",
            "HistGradientBoostingClassifier CV AUC mean: 0.955304, std: +-0.00057\n",
            "\n",
            "Stack (4-model optimized blend) OOF AUC: 0.955623\n",
            "FOLD 1/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89109\n",
            "[1999]\tvalidation_0-auc:0.95567\n",
            "FOLD 2/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89163\n",
            "[1999]\tvalidation_0-auc:0.95470\n",
            "FOLD 3/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89319\n",
            "[1914]\tvalidation_0-auc:0.95706\n",
            "FOLD 4/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88955\n",
            "[1999]\tvalidation_0-auc:0.95480\n",
            "FOLD 5/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89090\n",
            "[1999]\tvalidation_0-auc:0.95591\n",
            "FOLD 6/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89052\n",
            "[1999]\tvalidation_0-auc:0.95544\n",
            "FOLD 7/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88931\n",
            "[1979]\tvalidation_0-auc:0.95415\n",
            "FOLD 8/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89204\n",
            "[1999]\tvalidation_0-auc:0.95496\n",
            "FOLD 9/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89184\n",
            "[1896]\tvalidation_0-auc:0.95640\n",
            "FOLD 1/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713891\ttest: 0.6712609\tbest: 0.6712609 (0)\ttotal: 129ms\tremaining: 4m 18s\n",
            "1999:\tlearn: 0.2675728\ttest: 0.2667792\tbest: 0.2667792 (1999)\ttotal: 4m 1s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2667791621\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 2/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713331\ttest: 0.6714041\tbest: 0.6714041 (0)\ttotal: 129ms\tremaining: 4m 18s\n",
            "1999:\tlearn: 0.2672270\ttest: 0.2694953\tbest: 0.2694953 (1999)\ttotal: 3m 57s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2694953074\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 3/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6714059\ttest: 0.6712200\tbest: 0.6712200 (0)\ttotal: 125ms\tremaining: 4m 10s\n",
            "1999:\tlearn: 0.2680858\ttest: 0.2630388\tbest: 0.2630379 (1998)\ttotal: 4m\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2630379348\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 4/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713721\ttest: 0.6713384\tbest: 0.6713384 (0)\ttotal: 138ms\tremaining: 4m 35s\n",
            "1999:\tlearn: 0.2672159\ttest: 0.2694894\tbest: 0.2694894 (1999)\ttotal: 3m 54s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2694894311\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 5/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713891\ttest: 0.6712833\tbest: 0.6712833 (0)\ttotal: 129ms\tremaining: 4m 16s\n",
            "1999:\tlearn: 0.2677458\ttest: 0.2656268\tbest: 0.2656268 (1999)\ttotal: 3m 56s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2656268047\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 6/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713529\ttest: 0.6713911\tbest: 0.6713911 (0)\ttotal: 126ms\tremaining: 4m 12s\n",
            "1999:\tlearn: 0.2674690\ttest: 0.2675880\tbest: 0.2675880 (1998)\ttotal: 4m 16s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2675880085\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 7/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713184\ttest: 0.6715119\tbest: 0.6715119 (0)\ttotal: 157ms\tremaining: 5m 14s\n",
            "1999:\tlearn: 0.2670407\ttest: 0.2711092\tbest: 0.2711087 (1993)\ttotal: 5m 3s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2711087158\n",
            "bestIteration = 1993\n",
            "\n",
            "Shrink model to first 1994 iterations.\n",
            "FOLD 8/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713974\ttest: 0.6712084\tbest: 0.6712084 (0)\ttotal: 179ms\tremaining: 5m 57s\n",
            "1999:\tlearn: 0.2673478\ttest: 0.2685501\tbest: 0.2685498 (1996)\ttotal: 5m 27s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2685497903\n",
            "bestIteration = 1996\n",
            "\n",
            "Shrink model to first 1997 iterations.\n",
            "FOLD 9/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6714114\ttest: 0.6712526\tbest: 0.6712526 (0)\ttotal: 169ms\tremaining: 5m 38s\n",
            "1999:\tlearn: 0.2677705\ttest: 0.2647585\tbest: 0.2647585 (1999)\ttotal: 5m 18s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2647584796\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 1/9 - LGBMClassifier\n",
            "FOLD 2/9 - LGBMClassifier\n",
            "FOLD 3/9 - LGBMClassifier\n",
            "FOLD 4/9 - LGBMClassifier\n",
            "FOLD 5/9 - LGBMClassifier\n",
            "FOLD 6/9 - LGBMClassifier\n",
            "FOLD 7/9 - LGBMClassifier\n",
            "FOLD 8/9 - LGBMClassifier\n",
            "FOLD 9/9 - LGBMClassifier\n",
            "FOLD 1/9 - HistGradientBoostingClassifier\n",
            "FOLD 2/9 - HistGradientBoostingClassifier\n",
            "FOLD 3/9 - HistGradientBoostingClassifier\n",
            "FOLD 4/9 - HistGradientBoostingClassifier\n",
            "FOLD 5/9 - HistGradientBoostingClassifier\n",
            "FOLD 6/9 - HistGradientBoostingClassifier\n",
            "FOLD 7/9 - HistGradientBoostingClassifier\n",
            "FOLD 8/9 - HistGradientBoostingClassifier\n",
            "FOLD 9/9 - HistGradientBoostingClassifier\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955455\n",
            "XGBClassifier CV AUC mean: 0.955457, std: +-0.00086\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955556\n",
            "CatBoostClassifier CV AUC mean: 0.955557, std: +-0.00087\n",
            "\n",
            "LGBMClassifier OOF AUC: 0.954976\n",
            "LGBMClassifier CV AUC mean: 0.954979, std: +-0.00087\n",
            "\n",
            "HistGradientBoostingClassifier OOF AUC: 0.955308\n",
            "HistGradientBoostingClassifier CV AUC mean: 0.955313, std: +-0.00086\n",
            "\n",
            "Stack (4-model optimized blend) OOF AUC: 0.955618\n",
            "FOLD 1/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88837\n",
            "[1992]\tvalidation_0-auc:0.95411\n",
            "FOLD 2/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89035\n",
            "[1999]\tvalidation_0-auc:0.95558\n",
            "FOLD 3/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89001\n",
            "[1999]\tvalidation_0-auc:0.95589\n",
            "FOLD 4/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88983\n",
            "[1999]\tvalidation_0-auc:0.95558\n",
            "FOLD 5/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89041\n",
            "[1779]\tvalidation_0-auc:0.95605\n",
            "FOLD 6/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89073\n",
            "[1999]\tvalidation_0-auc:0.95534\n",
            "FOLD 7/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88871\n",
            "[1999]\tvalidation_0-auc:0.95516\n",
            "FOLD 8/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89035\n",
            "[1961]\tvalidation_0-auc:0.95549\n",
            "FOLD 9/9 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89079\n",
            "[1999]\tvalidation_0-auc:0.95592\n",
            "FOLD 1/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716204\ttest: 0.6716074\tbest: 0.6716074 (0)\ttotal: 150ms\tremaining: 4m 58s\n",
            "1999:\tlearn: 0.2671397\ttest: 0.2711389\tbest: 0.2711389 (1999)\ttotal: 4m 10s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2711388963\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 2/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716570\ttest: 0.6715153\tbest: 0.6715153 (0)\ttotal: 175ms\tremaining: 5m 49s\n",
            "1999:\tlearn: 0.2675704\ttest: 0.2673270\tbest: 0.2673270 (1999)\ttotal: 4m 58s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2673270019\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 3/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716324\ttest: 0.6715162\tbest: 0.6715162 (0)\ttotal: 161ms\tremaining: 5m 21s\n",
            "1999:\tlearn: 0.2677681\ttest: 0.2657234\tbest: 0.2657233 (1997)\ttotal: 4m 27s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2657232888\n",
            "bestIteration = 1997\n",
            "\n",
            "Shrink model to first 1998 iterations.\n",
            "FOLD 4/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716168\ttest: 0.6715841\tbest: 0.6715841 (0)\ttotal: 152ms\tremaining: 5m 4s\n",
            "1999:\tlearn: 0.2676237\ttest: 0.2668224\tbest: 0.2668219 (1998)\ttotal: 4m 29s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2668218838\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 5/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716464\ttest: 0.6715073\tbest: 0.6715073 (0)\ttotal: 246ms\tremaining: 8m 12s\n",
            "1999:\tlearn: 0.2677973\ttest: 0.2655374\tbest: 0.2655374 (1999)\ttotal: 4m 23s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2655374054\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 6/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6715880\ttest: 0.6716010\tbest: 0.6716010 (0)\ttotal: 139ms\tremaining: 4m 38s\n",
            "1999:\tlearn: 0.2674848\ttest: 0.2680135\tbest: 0.2680135 (1999)\ttotal: 4m 10s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2680135208\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 7/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716007\ttest: 0.6715688\tbest: 0.6715688 (0)\ttotal: 135ms\tremaining: 4m 30s\n",
            "1999:\tlearn: 0.2675135\ttest: 0.2681228\tbest: 0.2681228 (1998)\ttotal: 4m 14s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2681227649\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 8/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716116\ttest: 0.6715911\tbest: 0.6715911 (0)\ttotal: 136ms\tremaining: 4m 32s\n",
            "1999:\tlearn: 0.2676265\ttest: 0.2673148\tbest: 0.2673148 (1999)\ttotal: 4m 10s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.267314843\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 9/9 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716361\ttest: 0.6715649\tbest: 0.6715649 (0)\ttotal: 140ms\tremaining: 4m 40s\n",
            "1999:\tlearn: 0.2677640\ttest: 0.2661662\tbest: 0.2661662 (1999)\ttotal: 4m 11s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2661662032\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 1/9 - LGBMClassifier\n",
            "FOLD 2/9 - LGBMClassifier\n",
            "FOLD 3/9 - LGBMClassifier\n",
            "FOLD 4/9 - LGBMClassifier\n",
            "FOLD 5/9 - LGBMClassifier\n",
            "FOLD 6/9 - LGBMClassifier\n",
            "FOLD 7/9 - LGBMClassifier\n",
            "FOLD 8/9 - LGBMClassifier\n",
            "FOLD 9/9 - LGBMClassifier\n",
            "FOLD 1/9 - HistGradientBoostingClassifier\n",
            "FOLD 2/9 - HistGradientBoostingClassifier\n",
            "FOLD 3/9 - HistGradientBoostingClassifier\n",
            "FOLD 4/9 - HistGradientBoostingClassifier\n",
            "FOLD 5/9 - HistGradientBoostingClassifier\n",
            "FOLD 6/9 - HistGradientBoostingClassifier\n",
            "FOLD 7/9 - HistGradientBoostingClassifier\n",
            "FOLD 8/9 - HistGradientBoostingClassifier\n",
            "FOLD 9/9 - HistGradientBoostingClassifier\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955456\n",
            "XGBClassifier CV AUC mean: 0.955459, std: +-0.00055\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955566\n",
            "CatBoostClassifier CV AUC mean: 0.955567, std: +-0.00053\n",
            "\n",
            "LGBMClassifier OOF AUC: 0.954956\n",
            "LGBMClassifier CV AUC mean: 0.954958, std: +-0.00052\n",
            "\n",
            "HistGradientBoostingClassifier OOF AUC: 0.955312\n",
            "HistGradientBoostingClassifier CV AUC mean: 0.955314, std: +-0.00056\n",
            "\n",
            "Stack (4-model optimized blend) OOF AUC: 0.955623\n",
            "Submission: 4-model stack, 3-seed avg. test_proba shape: (270000,)\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import inspect\n",
        "\n",
        "SEED = 42\n",
        "NSPLITS = 9\n",
        "SEEDS = [42, 43, 44]  # 3-seed averaging to push past .954\n",
        "USE_LR_STACK = False\n",
        "DROP_BP_MAX_HR = True\n",
        "OPTIMIZE_4MODEL_BLEND = True  # grid-search blend weights; use if beats LR meta\n",
        "\n",
        "# Reload data Kaggle-style (lowercase columns, id as index)\n",
        "path = DATA_DIR\n",
        "dfs = []\n",
        "for fl in (\"train.csv\", \"test.csv\"):\n",
        "    df = pd.read_csv(path / fl, index_col=0)\n",
        "    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns.tolist()]\n",
        "    dfs.append(df)\n",
        "train, test = dfs\n",
        "\n",
        "ystr = train.columns[-1]\n",
        "base_features = [c for c in train.columns if c != ystr]\n",
        "\n",
        "cols2comb = [\n",
        "    \"exercise_angina\", \"thallium\", \"chest_pain_type\",\n",
        "    \"slope_of_st\", \"sex\", \"st_depression\", \"number_of_vessels_fluro\",\n",
        "    \"ekg_results\", \"fbs_over_120\",\n",
        "]\n",
        "\n",
        "statmetrics = [\"mean\", \"count\"]\n",
        "\n",
        "X = train.drop(columns=ystr)\n",
        "y = (train[ystr] == \"Presence\").astype(int)\n",
        "\n",
        "X_test = test.copy()\n",
        "\n",
        "# Teacher model from original clinical dataset -> prior feature\n",
        "orig_path = DATA_DIR.parent / \"original-data\" / \"Heart_Disease_Prediction.csv\"\n",
        "orig_df = pd.read_csv(orig_path)\n",
        "orig_df.columns = [c.strip().lower().replace(\" \", \"_\") for c in orig_df.columns]\n",
        "orig_ystr = orig_df.columns[-1]\n",
        "orig_X = orig_df.drop(columns=orig_ystr)\n",
        "orig_y = (orig_df[orig_ystr] == \"Presence\").astype(int)\n",
        "\n",
        "common_cols = sorted(set(orig_X.columns) & set(X.columns))\n",
        "print(f\"Teacher model using {len(common_cols)} shared columns from original dataset\")\n",
        "\n",
        "teacher = cb.CatBoostClassifier(\n",
        "    iterations=400,\n",
        "    depth=4,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.9,\n",
        "    colsample_bylevel=0.9,\n",
        "    random_seed=SEED,\n",
        "    verbose=0,\n",
        ")\n",
        "teacher.fit(orig_X[common_cols], orig_y)\n",
        "\n",
        "X[\"teacher_pred\"] = teacher.predict_proba(X[common_cols])[:, 1]\n",
        "X_test[\"teacher_pred\"] = teacher.predict_proba(X_test[common_cols])[:, 1]\n",
        "\n",
        "# Adversarial validation: train vs test\n",
        "adv_X = pd.concat([X, X_test], axis=0).reset_index(drop=True)\n",
        "adv_y = np.concatenate([\n",
        "    np.zeros(len(X), dtype=int),\n",
        "    np.ones(len(X_test), dtype=int),\n",
        "])\n",
        "adv_skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "oof_adv = np.zeros(len(adv_y), dtype=float)\n",
        "for tr_adv, val_adv in adv_skf.split(adv_X, adv_y):\n",
        "    adv_clf = lgb.LGBMClassifier(\n",
        "        objective=\"binary\",\n",
        "        metric=\"auc\",\n",
        "        learning_rate=0.05,\n",
        "        n_estimators=400,\n",
        "        num_leaves=31,\n",
        "        feature_fraction=0.9,\n",
        "        bagging_fraction=0.9,\n",
        "        bagging_freq=1,\n",
        "        min_data_in_leaf=30,\n",
        "        random_state=SEED,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    adv_clf.fit(adv_X.iloc[tr_adv], adv_y[tr_adv])\n",
        "    oof_adv[val_adv] = adv_clf.predict_proba(adv_X.iloc[val_adv])[:, 1]\n",
        "\n",
        "auc_adv = roc_auc_score(adv_y, oof_adv)\n",
        "print(f\"Adversarial AUC (train vs test): {auc_adv:.5f}\")\n",
        "\n",
        "p_test_train = oof_adv[: len(X)]\n",
        "eps = 1e-3\n",
        "w_train = p_test_train / (1.0 - p_test_train + eps)\n",
        "w_train = w_train / w_train.mean()\n",
        "print(\n",
        "    f\"Sample weights (train-like vs test-like) -> min={w_train.min():.3f}, max={w_train.max():.3f}, mean={w_train.mean():.3f}\"\n",
        ")\n",
        "\n",
        "\n",
        "def get_cat_feature_indices(X_):\n",
        "    return [i for i, c in enumerate(X_.columns) if c.startswith(\"CAT_\")]\n",
        "\n",
        "\n",
        "def fe_foldwise(X_tr, X_val, y_tr):\n",
        "    X_tr = X_tr.copy()\n",
        "    X_val = X_val.copy()\n",
        "\n",
        "    temp = pd.concat([X_tr, y_tr], axis=1)\n",
        "\n",
        "    # casting\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"age>55\"] = (df[\"age\"] > 55).astype(int)\n",
        "        for col in df.columns:\n",
        "            if col == \"teacher_pred\":\n",
        "                continue\n",
        "            colname = f\"CAT_{col}\"\n",
        "            df[colname] = df[col].astype(str).astype(\"category\")\n",
        "\n",
        "    # numeric interactions and derived + bin features (from 0.954 notebook)\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"chest_pain_type_bin\"] = (df[\"chest_pain_type\"] >= 3).astype(int)\n",
        "        df[\"st_depression_bin\"] = (df[\"st_depression\"] >= 2).astype(int)\n",
        "        df[\"number_of_vessels_fluro_bin\"] = (df[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "        df[\"hr_age\"] = df[\"max_hr\"] * df[\"age\"]\n",
        "        df[\"bp_age\"] = df[\"bp\"] * df[\"age\"]\n",
        "        df[\"st_slope\"] = df[\"st_depression\"] * df[\"slope_of_st\"]\n",
        "        df[\"chol_exercise\"] = df[\"cholesterol\"] * df[\"exercise_angina\"]\n",
        "        pred_max = (220 - df[\"age\"]).clip(lower=10)\n",
        "        df[\"max_hr_pct_pred\"] = df[\"max_hr\"] / pred_max\n",
        "        df[\"risk_sum\"] = df[\"number_of_vessels_fluro\"] + df[\"thallium\"] + df[\"exercise_angina\"]\n",
        "\n",
        "    # target statistics + smoothed target encoding\n",
        "    global_mean = float(y_tr.mean())\n",
        "    m_smooth = 20\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            cname = f\"target_{bf}_{s}\"\n",
        "            X_tr[cname] = X_tr[bf].map(stats[s])\n",
        "            X_val[cname] = X_val[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_tr[f\"target_{bf}_smooth\"] = X_tr[bf].map(smoothed).fillna(global_mean)\n",
        "        X_val[f\"target_{bf}_smooth\"] = X_val[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    # categorical combinations\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_tr[c2].max(), X_val[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_tr[cname] = (\n",
        "                (X_tr[c1] + 1 + (X_tr[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "            X_val[cname] = (\n",
        "                (X_val[c1] + 1 + (X_val[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    if DROP_BP_MAX_HR:\n",
        "        X_tr = X_tr.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "        X_val = X_val.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "    return X_tr, X_val\n",
        "\n",
        "\n",
        "def fe_test(X_test_, X_train_, y_train_):\n",
        "    X_test_ = X_test_.copy()\n",
        "    temp = pd.concat([X_train_, y_train_], axis=1)\n",
        "\n",
        "    X_test_[\"age>55\"] = (X_test_[\"age\"] > 55).astype(int)\n",
        "    for col in X_test_.columns:\n",
        "        if col == \"teacher_pred\":\n",
        "            continue\n",
        "        colname = f\"CAT_{col}\"\n",
        "        X_test_[colname] = X_test_[col].astype(str).astype(\"category\")\n",
        "\n",
        "    X_test_[\"chest_pain_type_bin\"] = (X_test_[\"chest_pain_type\"] >= 3).astype(int)\n",
        "    X_test_[\"st_depression_bin\"] = (X_test_[\"st_depression\"] >= 2).astype(int)\n",
        "    X_test_[\"number_of_vessels_fluro_bin\"] = (X_test_[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "    X_test_[\"hr_age\"] = X_test_[\"max_hr\"] * X_test_[\"age\"]\n",
        "    X_test_[\"bp_age\"] = X_test_[\"bp\"] * X_test_[\"age\"]\n",
        "    X_test_[\"st_slope\"] = X_test_[\"st_depression\"] * X_test_[\"slope_of_st\"]\n",
        "    X_test_[\"chol_exercise\"] = X_test_[\"cholesterol\"] * X_test_[\"exercise_angina\"]\n",
        "    pred_max = (220 - X_test_[\"age\"]).clip(lower=10)\n",
        "    X_test_[\"max_hr_pct_pred\"] = X_test_[\"max_hr\"] / pred_max\n",
        "    X_test_[\"risk_sum\"] = X_test_[\"number_of_vessels_fluro\"] + X_test_[\"thallium\"] + X_test_[\"exercise_angina\"]\n",
        "\n",
        "    global_mean = float(y_train_.mean())\n",
        "    m_smooth = 20\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            X_test_[f\"target_{bf}_{s}\"] = X_test_[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_test_[f\"target_{bf}_smooth\"] = X_test_[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_train_[c2].max(), X_test_[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_test_[cname] = (\n",
        "                (X_test_[c1] + 1 + (X_test_[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    if DROP_BP_MAX_HR:\n",
        "        X_test_ = X_test_.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "    return X_test_\n",
        "\n",
        "\n",
        "xgboost_params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"auc\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"max_depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"colsample_bytree\": 0.9,\n",
        "    \"n_estimators\": 2000,\n",
        "    \"min_child_weight\": 10,\n",
        "    \"gamma\": 1,\n",
        "    \"reg_lambda\": 0.01,\n",
        "    \"reg_alpha\": 1.5,\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"n_jobs\": -1,\n",
        "    \"random_state\": SEED,\n",
        "    \"early_stopping_rounds\": 100,\n",
        "    \"enable_categorical\": True,\n",
        "}\n",
        "\n",
        "catboost_params = {\n",
        "    \"loss_function\": \"Logloss\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"iterations\": 2000,\n",
        "    \"min_data_in_leaf\": 1,\n",
        "    \"l2_leaf_reg\": 1.002,\n",
        "    \"thread_count\": -1,\n",
        "    \"random_seed\": SEED,\n",
        "    \"early_stopping_rounds\": 100,\n",
        "    \"bootstrap_type\": \"Bernoulli\",\n",
        "}\n",
        "\n",
        "lgbm_params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"metric\": \"auc\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"n_estimators\": 1200,\n",
        "    \"num_leaves\": 20,\n",
        "    \"feature_fraction\": 0.9,\n",
        "    \"bagging_fraction\": 0.9,\n",
        "    \"bagging_freq\": 1,\n",
        "    \"min_data_in_leaf\": 30,\n",
        "    \"random_state\": SEED,\n",
        "    \"n_jobs\": -1,\n",
        "    \"verbose\": -1,\n",
        "}\n",
        "hgb_params = {\n",
        "    \"max_iter\": 2000,\n",
        "    \"learning_rate\": 0.02,\n",
        "    \"max_depth\": 6,\n",
        "    \"early_stopping\": True,\n",
        "    \"n_iter_no_change\": 80,\n",
        "    \"validation_fraction\": 0.1,\n",
        "    \"random_state\": SEED,\n",
        "}\n",
        "models = {\n",
        "    XGBClassifier: xgboost_params,\n",
        "    CatBoostClassifier: catboost_params,\n",
        "    LGBMClassifier: lgbm_params,\n",
        "    HistGradientBoostingClassifier: hgb_params,\n",
        "}\n",
        "\n",
        "oof_list, test_proba_list = [], []\n",
        "for SEED in SEEDS:\n",
        "    teacher = cb.CatBoostClassifier(\n",
        "        iterations=400, depth=4, learning_rate=0.05, subsample=0.9,\n",
        "        colsample_bylevel=0.9, random_seed=SEED, verbose=0,\n",
        "    )\n",
        "    teacher.fit(orig_X[common_cols], orig_y)\n",
        "    X[\"teacher_pred\"] = teacher.predict_proba(X[common_cols])[:, 1]\n",
        "    X_test[\"teacher_pred\"] = teacher.predict_proba(X_test[common_cols])[:, 1]\n",
        "    adv_skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "    oof_adv = np.zeros(len(adv_y), dtype=float)\n",
        "    for tr_adv, val_adv in adv_skf.split(adv_X, adv_y):\n",
        "        adv_clf = lgb.LGBMClassifier(\n",
        "            objective=\"binary\", metric=\"auc\", learning_rate=0.05, n_estimators=400,\n",
        "            num_leaves=31, feature_fraction=0.9, bagging_fraction=0.9, bagging_freq=1,\n",
        "            min_data_in_leaf=30, random_state=SEED, n_jobs=-1,\n",
        "        )\n",
        "        adv_clf.fit(adv_X.iloc[tr_adv], adv_y[tr_adv])\n",
        "        oof_adv[val_adv] = adv_clf.predict_proba(adv_X.iloc[val_adv])[:, 1]\n",
        "    p_test_train = oof_adv[: len(X)]\n",
        "    w_train = p_test_train / (1.0 - p_test_train + 1e-3)\n",
        "    w_train = w_train / w_train.mean()\n",
        "    xgboost_params = {**xgboost_params, \"random_state\": SEED}\n",
        "    catboost_params = {**catboost_params, \"random_seed\": SEED}\n",
        "    lgbm_params = {**lgbm_params, \"random_state\": SEED}\n",
        "    hgb_params_s = {**hgb_params, \"random_state\": SEED}\n",
        "    models_run = {\n",
        "        XGBClassifier: xgboost_params,\n",
        "        CatBoostClassifier: catboost_params,\n",
        "        LGBMClassifier: lgbm_params,\n",
        "        HistGradientBoostingClassifier: hgb_params_s,\n",
        "    }\n",
        "    kf = KFold(n_splits=NSPLITS, shuffle=True, random_state=SEED)\n",
        "    oof_train_model = {}\n",
        "    oof_test_model = {}\n",
        "    cv_auc_model = defaultdict(list)\n",
        "    for modelClass, param in models_run.items():\n",
        "        model_name = modelClass.__name__\n",
        "        oof_train = np.zeros(len(X))\n",
        "        oof_test = np.zeros(len(X_test))\n",
        "\n",
        "        for fold, (tr, val) in enumerate(kf.split(X)):\n",
        "            print(f\"FOLD {fold + 1}/{NSPLITS} - {model_name}\")\n",
        "\n",
        "            X_tr_raw, X_val_raw = X.iloc[tr], X.iloc[val]\n",
        "            y_tr, y_val = y.iloc[tr], y.iloc[val]\n",
        "\n",
        "            X_tr, X_val = fe_foldwise(X_tr_raw, X_val_raw, y_tr)\n",
        "\n",
        "            model = modelClass(**param)\n",
        "            if model_name == \"HistGradientBoostingClassifier\":\n",
        "                X_tr_fit = X_tr.select_dtypes(include=[np.number])\n",
        "                X_val_fit = X_val.select_dtypes(include=[np.number])\n",
        "                model.fit(X_tr_fit, y_tr, sample_weight=w_train[tr])\n",
        "                oof_train[val] = model.predict_proba(X_val_fit)[:, 1]\n",
        "                X_test_fe = fe_test(X_test, X_tr_raw, y_tr)\n",
        "                X_test_fit = X_test_fe.select_dtypes(include=[np.number])\n",
        "                oof_test += model.predict_proba(X_test_fit)[:, 1] / NSPLITS\n",
        "            else:\n",
        "                fit_kwargs = {\n",
        "                    \"X\": X_tr,\n",
        "                    \"y\": y_tr,\n",
        "                    \"eval_set\": [(X_val, y_val)],\n",
        "                    \"sample_weight\": w_train[tr],\n",
        "                }\n",
        "                if model_name != \"LGBMClassifier\":\n",
        "                    fit_kwargs[\"verbose\"] = 2000\n",
        "                if \"cat_features\" in inspect.signature(model.fit).parameters:\n",
        "                    cat_features = get_cat_feature_indices(X_tr)\n",
        "                    fit_kwargs[\"cat_features\"] = cat_features\n",
        "                model.fit(**fit_kwargs)\n",
        "                oof_train[val] = model.predict_proba(X_val)[:, 1]\n",
        "                X_test_fe = fe_test(X_test, X_tr_raw, y_tr)\n",
        "                oof_test += model.predict_proba(X_test_fe)[:, 1] / NSPLITS\n",
        "            cv_auc_model[model_name].append(roc_auc_score(y[val], oof_train[val]))\n",
        "\n",
        "        oof_train_model[model_name] = oof_train\n",
        "        oof_test_model[model_name] = oof_test\n",
        "\n",
        "    # Evaluation per model (inside seed loop)\n",
        "    for modelClass in models_run.keys():\n",
        "        model_name = modelClass.__name__\n",
        "        print(f\"\\n{model_name} OOF AUC: {roc_auc_score(y, oof_train_model[model_name]):.6f}\")\n",
        "        print(\n",
        "            f\"{model_name} CV AUC mean: {np.mean(cv_auc_model[model_name]):.6f}, std: +-{np.std(cv_auc_model[model_name]):.5f}\"\n",
        "        )\n",
        "\n",
        "    # Stack: LR meta for 3+ models or when USE_LR_STACK; else tuned 2-model weight blend\n",
        "    X_oof_tr = pd.DataFrame.from_dict(oof_train_model)\n",
        "    X_oof_test = pd.DataFrame.from_dict(oof_test_model)\n",
        "    cols = list(X_oof_tr.columns)\n",
        "    use_meta = USE_LR_STACK or len(cols) >= 3\n",
        "    if use_meta:\n",
        "        meta = LogisticRegression(max_iter=500, random_state=SEED)\n",
        "        meta.fit(X_oof_tr, y, sample_weight=w_train)\n",
        "        oof_tr_final_lr = pd.Series(meta.predict_proba(X_oof_tr)[:, 1], index=X_oof_tr.index)\n",
        "        oof_test_final_lr = pd.Series(meta.predict_proba(X_oof_test)[:, 1], index=X_oof_test.index)\n",
        "        lr_auc = roc_auc_score(y, oof_tr_final_lr)\n",
        "        if OPTIMIZE_4MODEL_BLEND and len(cols) == 4:\n",
        "            best_blend_auc, best_ws = 0.0, None\n",
        "            for w1 in (0, 0.25, 0.5, 0.75, 1):\n",
        "                for w2 in (0, 0.25, 0.5, 0.75, 1):\n",
        "                    for w3 in (0, 0.25, 0.5, 0.75, 1):\n",
        "                        w4 = 1.0 - w1 - w2 - w3\n",
        "                        if w4 < -0.01:\n",
        "                            continue\n",
        "                        w4 = max(0.0, w4)\n",
        "                        b = w1 * X_oof_tr[cols[0]] + w2 * X_oof_tr[cols[1]] + w3 * X_oof_tr[cols[2]] + w4 * X_oof_tr[cols[3]]\n",
        "                        auc = roc_auc_score(y, b)\n",
        "                        if auc > best_blend_auc:\n",
        "                            best_blend_auc, best_ws = auc, (w1, w2, w3, w4)\n",
        "            if best_ws is not None and best_blend_auc > lr_auc:\n",
        "                w1, w2, w3, w4 = best_ws\n",
        "                oof_tr_final = w1 * X_oof_tr[cols[0]] + w2 * X_oof_tr[cols[1]] + w3 * X_oof_tr[cols[2]] + w4 * X_oof_tr[cols[3]]\n",
        "                oof_test_final = w1 * X_oof_test[cols[0]] + w2 * X_oof_test[cols[1]] + w3 * X_oof_test[cols[2]] + w4 * X_oof_test[cols[3]]\n",
        "                stack_auc = best_blend_auc\n",
        "                print(f\"\\nStack (4-model optimized blend) OOF AUC: {stack_auc:.6f}\")\n",
        "            else:\n",
        "                oof_tr_final, oof_test_final = oof_tr_final_lr, oof_test_final_lr\n",
        "                stack_auc = lr_auc\n",
        "                print(f\"\\nStack (LR meta, {len(cols)} models) OOF AUC: {stack_auc:.6f}\")\n",
        "        else:\n",
        "            oof_tr_final, oof_test_final = oof_tr_final_lr, oof_test_final_lr\n",
        "            stack_auc = lr_auc\n",
        "            print(f\"\\nStack (LR meta, {len(cols)} models) OOF AUC: {stack_auc:.6f}\")\n",
        "        oof_list.append(oof_tr_final.values)\n",
        "        test_proba_list.append(oof_test_final.values)\n",
        "    else:\n",
        "        a, b = X_oof_tr[cols[0]], X_oof_tr[cols[1]]\n",
        "        best_w, best_auc = 0.5, 0.0\n",
        "        for w in np.linspace(0, 1, 21):\n",
        "            blend = w * a + (1 - w) * b\n",
        "            auc = roc_auc_score(y, blend)\n",
        "            if auc > best_auc:\n",
        "                best_auc, best_w = auc, w\n",
        "        oof_tr_final = best_w * X_oof_tr[cols[0]] + (1 - best_w) * X_oof_tr[cols[1]]\n",
        "        oof_test_final = best_w * X_oof_test[cols[0]] + (1 - best_w) * X_oof_test[cols[1]]\n",
        "        print(f\"\\nBlend weight {cols[0]}={best_w:.2f}, {cols[1]}={1-best_w:.2f} -> OOF AUC: {best_auc:.6f}\")\n",
        "        oof_list.append(oof_tr_final.values)\n",
        "        test_proba_list.append(oof_test_final.values)\n",
        "\n",
        "# Seed averaging (outside SEED loop)\n",
        "oof = np.mean(oof_list, axis=0)\n",
        "test_proba = np.mean(test_proba_list, axis=0)\n",
        "N_STACK_MODELS = len(oof_train_model)\n",
        "print(f\"Submission: {N_STACK_MODELS}-model stack, {len(SEEDS)}-seed avg. test_proba shape: {test_proba.shape}\")\n",
        "\n",
        "# Ensure id column exists for submission\n",
        "test[\"id\"] = test.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix (OOF, threshold=0.5)\n",
            "Rows: true, Cols: predicted |  Absence   Presence\n",
            "[[314952  32594]\n",
            " [ 37217 245237]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred = (oof >= 0.5).astype(int)\n",
        "cm = confusion_matrix(y, y_pred)\n",
        "print(\"Confusion matrix (OOF, threshold=0.5)\")\n",
        "print(\"Rows: true, Cols: predicted |  Absence   Presence\")\n",
        "print(cm)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "plt.colorbar()\n",
        "plt.xticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.yticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
        "plt.title(\"Confusion matrix (OOF)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission saved (4-model blend): submission.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>630000</th>\n",
              "      <td>630000</td>\n",
              "      <td>0.951484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630001</th>\n",
              "      <td>630001</td>\n",
              "      <td>0.008320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630002</th>\n",
              "      <td>630002</td>\n",
              "      <td>0.987648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630003</th>\n",
              "      <td>630003</td>\n",
              "      <td>0.005034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630004</th>\n",
              "      <td>630004</td>\n",
              "      <td>0.203481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630005</th>\n",
              "      <td>630005</td>\n",
              "      <td>0.982334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630006</th>\n",
              "      <td>630006</td>\n",
              "      <td>0.004615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630007</th>\n",
              "      <td>630007</td>\n",
              "      <td>0.543485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630008</th>\n",
              "      <td>630008</td>\n",
              "      <td>0.991151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630009</th>\n",
              "      <td>630009</td>\n",
              "      <td>0.012669</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  Heart Disease\n",
              "id                           \n",
              "630000  630000       0.951484\n",
              "630001  630001       0.008320\n",
              "630002  630002       0.987648\n",
              "630003  630003       0.005034\n",
              "630004  630004       0.203481\n",
              "630005  630005       0.982334\n",
              "630006  630006       0.004615\n",
              "630007  630007       0.543485\n",
              "630008  630008       0.991151\n",
              "630009  630009       0.012669"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub = pd.DataFrame({\"id\": test[\"id\"], \"Heart Disease\": test_proba})\n",
        "sub.to_csv(OUTPUT_DIR / \"submission.csv\", index=False)\n",
        "print(f\"Submission saved ({N_STACK_MODELS}-model blend): {OUTPUT_DIR / 'submission.csv'}\")\n",
        "sub.head(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
