{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicting Heart Disease\n",
        "\n",
        "## Score: .95375"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict, KFold\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import catboost as cb\n",
        "from catboost import CatBoostClassifier\n",
        "#%pip install torch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "DATA_DIR = Path(\"playground-series-s6e2\")\n",
        "OUTPUT_DIR = Path(\".\")\n",
        "n_splits = 5\n",
        "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (630000, 15)\n",
            "Test: (270000, 14)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Chest pain type</th>\n",
              "      <th>BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FBS over 120</th>\n",
              "      <th>EKG results</th>\n",
              "      <th>Max HR</th>\n",
              "      <th>Exercise angina</th>\n",
              "      <th>ST depression</th>\n",
              "      <th>Slope of ST</th>\n",
              "      <th>Number of vessels fluro</th>\n",
              "      <th>Thallium</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>152</td>\n",
              "      <td>239</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>325</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>160</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>134</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>140</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  Age  Sex  Chest pain type   BP  Cholesterol  FBS over 120  EKG results  \\\n",
              "0   0   58    1                4  152          239             0            0   \n",
              "1   1   52    1                1  125          325             0            2   \n",
              "2   2   56    0                2  160          188             0            2   \n",
              "3   3   44    0                3  134          229             0            2   \n",
              "4   4   58    1                4  140          234             0            2   \n",
              "\n",
              "   Max HR  Exercise angina  ST depression  Slope of ST  \\\n",
              "0     158                1            3.6            2   \n",
              "1     171                0            0.0            1   \n",
              "2     151                0            0.0            1   \n",
              "3     150                0            1.0            2   \n",
              "4     125                1            3.8            2   \n",
              "\n",
              "   Number of vessels fluro  Thallium Heart Disease  \n",
              "0                        2         7      Presence  \n",
              "1                        0         3       Absence  \n",
              "2                        0         3       Absence  \n",
              "3                        0         3       Absence  \n",
              "4                        3         3      Presence  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR / \"test.csv\")\n",
        "print(f\"Train: {train.shape}\")\n",
        "print(f\"Test: {test.shape}\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features: 32 columns\n",
            "Target distribution: {0: 347546, 1: 282454}\n"
          ]
        }
      ],
      "source": [
        "target_col = \"Heart Disease\"\n",
        "id_col = \"id\"\n",
        "feature_cols = [c for c in train.columns if c not in (id_col, target_col)]\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(train[target_col])\n",
        "\n",
        "X_train = train[feature_cols].copy()\n",
        "X_test = test[feature_cols].copy()\n",
        "\n",
        "for col in feature_cols:\n",
        "    if X_train[col].isna().any() or X_test[col].isna().any():\n",
        "        med = X_train[col].median()\n",
        "        X_train[col] = X_train[col].fillna(med)\n",
        "        X_test[col] = X_test[col].fillna(med)\n",
        "\n",
        "X_train[\"chol_exercise\"] = X_train[\"Cholesterol\"] * X_train[\"Exercise angina\"]\n",
        "X_test[\"chol_exercise\"] = X_test[\"Cholesterol\"] * X_test[\"Exercise angina\"]\n",
        "X_train[\"st_slope\"] = X_train[\"ST depression\"] * X_train[\"Slope of ST\"]\n",
        "X_test[\"st_slope\"] = X_test[\"ST depression\"] * X_test[\"Slope of ST\"]\n",
        "X_train[\"hr_age\"] = X_train[\"Max HR\"] * X_train[\"Age\"]\n",
        "X_test[\"hr_age\"] = X_test[\"Max HR\"] * X_test[\"Age\"]\n",
        "X_train[\"bp_age\"] = X_train[\"BP\"] * X_train[\"Age\"]\n",
        "X_test[\"bp_age\"] = X_test[\"BP\"] * X_test[\"Age\"]\n",
        "\n",
        "te_cols = [\"Chest pain type\", \"Slope of ST\", \"Thallium\"]\n",
        "global_mean = float(y.mean())\n",
        "m = 20\n",
        "for col in te_cols:\n",
        "    agg = pd.DataFrame({\"_y\": y}).groupby(X_train[col])[\"_y\"].agg([\"mean\", \"count\"])\n",
        "    smoothed = (agg[\"count\"] * agg[\"mean\"] + m * global_mean) / (agg[\"count\"] + m)\n",
        "    X_train[col + \"_te\"] = X_train[col].map(smoothed).fillna(global_mean)\n",
        "    X_test[col + \"_te\"] = X_test[col].map(smoothed).fillna(global_mean)\n",
        "\n",
        "scaler_feat = StandardScaler()\n",
        "X_tr_s = scaler_feat.fit_transform(X_train)\n",
        "X_te_s = scaler_feat.transform(X_test)\n",
        "kmeans = KMeans(n_clusters=12, random_state=42, n_init=10)\n",
        "kmeans.fit(X_tr_s)\n",
        "for i in range(kmeans.n_clusters):\n",
        "    d_tr = np.linalg.norm(X_tr_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    d_te = np.linalg.norm(X_te_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    X_train[f\"dist_c{i}\"] = d_tr\n",
        "    X_test[f\"dist_c{i}\"] = d_te\n",
        "\n",
        "print(f\"Features: {len(X_train.columns)} columns\")\n",
        "print(f\"Target distribution: {pd.Series(y).value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best OOF AUC: 0.95507, params: {'depth': 6, 'lr': 0.05, 'min_data_in_leaf': 15}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\"depth\": [4, 5, 6], \"lr\": [0.03, 0.04, 0.05], \"min_data_in_leaf\": [15, 25, 35]}\n",
        "n_est = 800\n",
        "best_auc, best_params = 0, None\n",
        "for depth in param_grid[\"depth\"]:\n",
        "    for lr in param_grid[\"lr\"]:\n",
        "        for min_leaf in param_grid[\"min_data_in_leaf\"]:\n",
        "            m = cb.CatBoostClassifier(iterations=n_est, depth=depth, learning_rate=lr, min_data_in_leaf=min_leaf, subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "            oof = cross_val_predict(m, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "            auc = roc_auc_score(y, oof)\n",
        "            if auc > best_auc:\n",
        "                best_auc, best_params = auc, {\"depth\": depth, \"lr\": lr, \"min_data_in_leaf\": min_leaf}\n",
        "print(f\"Best OOF AUC: {best_auc:.5f}, params: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV AUC: 0.95517 (blend w_xgb=0.4)\n"
          ]
        }
      ],
      "source": [
        "model = cb.CatBoostClassifier(iterations=n_est, depth=best_params[\"depth\"], learning_rate=best_params[\"lr\"], min_data_in_leaf=best_params[\"min_data_in_leaf\"], subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "oof_cb = cross_val_predict(model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=n_est, max_depth=5, learning_rate=0.05, min_child_weight=20, subsample=0.75, colsample_bytree=0.75, random_state=42, eval_metric=\"auc\")\n",
        "oof_xgb = cross_val_predict(xgb_model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "best_w, best_auc = 0.0, roc_auc_score(y, oof_cb)\n",
        "for w in [0, 0.1, 0.2, 0.3, 0.4]:\n",
        "    oof_blend = (1 - w) * oof_cb + w * oof_xgb\n",
        "    auc = roc_auc_score(y, oof_blend)\n",
        "    if auc > best_auc:\n",
        "        best_auc, best_w = auc, w\n",
        "oof = (1 - best_w) * oof_cb + best_w * oof_xgb\n",
        "print(f\"CV AUC: {best_auc:.5f} (blend w_xgb={best_w})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train, y)\n",
        "xgb_model.fit(X_train, y)\n",
        "test_cb = model.predict_proba(X_test)[:, 1]\n",
        "test_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
        "test_proba = (1 - best_w) * test_cb + best_w * test_xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher model using 13 shared columns from original dataset\n",
            "Adversarial AUC (train vs test): 0.50147\n",
            "Sample weights (train-like vs test-like) -> min=0.350, max=2.793, mean=1.000\n",
            "FOLD 1/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90656\n",
            "[1999]\tvalidation_0-auc:0.95593\n",
            "FOLD 2/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90619\n",
            "[1999]\tvalidation_0-auc:0.95512\n",
            "FOLD 3/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90469\n",
            "[1931]\tvalidation_0-auc:0.95472\n",
            "FOLD 4/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90561\n",
            "[1992]\tvalidation_0-auc:0.95548\n",
            "FOLD 5/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90538\n",
            "[1999]\tvalidation_0-auc:0.95456\n",
            "FOLD 6/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90684\n",
            "[1984]\tvalidation_0-auc:0.95664\n",
            "FOLD 7/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90538\n",
            "[1970]\tvalidation_0-auc:0.95558\n",
            "FOLD 1/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717216\ttest: 0.6716387\tbest: 0.6716387 (0)\ttotal: 149ms\tremaining: 4m 57s\n",
            "1999:\tlearn: 0.2676937\ttest: 0.2660282\tbest: 0.2660282 (1999)\ttotal: 4m 35s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2660282044\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 2/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6717023\ttest: 0.6715683\tbest: 0.6715683 (0)\ttotal: 145ms\tremaining: 4m 49s\n",
            "1999:\tlearn: 0.2673015\ttest: 0.2683028\tbest: 0.2683028 (1999)\ttotal: 4m 41s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2683027584\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 3/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716624\ttest: 0.6716832\tbest: 0.6716832 (0)\ttotal: 161ms\tremaining: 5m 22s\n",
            "1999:\tlearn: 0.2671509\ttest: 0.2694561\tbest: 0.2694561 (1999)\ttotal: 4m 40s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.269456057\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 4/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716827\ttest: 0.6716559\tbest: 0.6716559 (0)\ttotal: 149ms\tremaining: 4m 58s\n",
            "1999:\tlearn: 0.2675724\ttest: 0.2673072\tbest: 0.2673072 (1999)\ttotal: 4m 44s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2673071617\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 5/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716776\ttest: 0.6716586\tbest: 0.6716586 (0)\ttotal: 173ms\tremaining: 5m 46s\n",
            "1999:\tlearn: 0.2670627\ttest: 0.2703700\tbest: 0.2703700 (1999)\ttotal: 4m 48s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2703700095\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 6/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716958\ttest: 0.6716513\tbest: 0.6716513 (0)\ttotal: 158ms\tremaining: 5m 16s\n",
            "1999:\tlearn: 0.2680833\ttest: 0.2639790\tbest: 0.2639790 (1999)\ttotal: 4m 37s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2639790372\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 7/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716790\ttest: 0.6716890\tbest: 0.6716890 (0)\ttotal: 167ms\tremaining: 5m 34s\n",
            "1999:\tlearn: 0.2676584\ttest: 0.2669598\tbest: 0.2669598 (1998)\ttotal: 4m 37s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2669598231\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 1/7 - LGBMClassifier\n",
            "FOLD 2/7 - LGBMClassifier\n",
            "FOLD 3/7 - LGBMClassifier\n",
            "FOLD 4/7 - LGBMClassifier\n",
            "FOLD 5/7 - LGBMClassifier\n",
            "FOLD 6/7 - LGBMClassifier\n",
            "FOLD 7/7 - LGBMClassifier\n",
            "FOLD 1/7 - HistGradientBoostingClassifier\n",
            "FOLD 2/7 - HistGradientBoostingClassifier\n",
            "FOLD 3/7 - HistGradientBoostingClassifier\n",
            "FOLD 4/7 - HistGradientBoostingClassifier\n",
            "FOLD 5/7 - HistGradientBoostingClassifier\n",
            "FOLD 6/7 - HistGradientBoostingClassifier\n",
            "FOLD 7/7 - HistGradientBoostingClassifier\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955431\n",
            "XGBClassifier CV AUC mean: 0.955435, std: +-0.00067\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955521\n",
            "CatBoostClassifier CV AUC mean: 0.955525, std: +-0.00069\n",
            "\n",
            "LGBMClassifier OOF AUC: 0.954909\n",
            "LGBMClassifier CV AUC mean: 0.954913, std: +-0.00068\n",
            "\n",
            "HistGradientBoostingClassifier OOF AUC: 0.955266\n",
            "HistGradientBoostingClassifier CV AUC mean: 0.955271, std: +-0.00068\n",
            "\n",
            "Stack (LR meta, 4 models) OOF AUC: 0.955543\n",
            "FOLD 1/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90458\n",
            "[1895]\tvalidation_0-auc:0.95439\n",
            "FOLD 2/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90591\n",
            "[1999]\tvalidation_0-auc:0.95463\n",
            "FOLD 3/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90800\n",
            "[1999]\tvalidation_0-auc:0.95679\n",
            "FOLD 4/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90490\n",
            "[1999]\tvalidation_0-auc:0.95473\n",
            "FOLD 5/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90700\n",
            "[1914]\tvalidation_0-auc:0.95556\n",
            "FOLD 6/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90837\n",
            "[1999]\tvalidation_0-auc:0.95678\n",
            "FOLD 7/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90663\n",
            "[1931]\tvalidation_0-auc:0.95507\n",
            "FOLD 1/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713182\ttest: 0.6714391\tbest: 0.6714391 (0)\ttotal: 160ms\tremaining: 5m 20s\n",
            "1999:\tlearn: 0.2669739\ttest: 0.2708226\tbest: 0.2708226 (1999)\ttotal: 4m 34s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.270822551\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 2/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713904\ttest: 0.6713418\tbest: 0.6713418 (0)\ttotal: 150ms\tremaining: 5m\n",
            "1999:\tlearn: 0.2671129\ttest: 0.2698504\tbest: 0.2698502 (1998)\ttotal: 4m 29s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2698501584\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 3/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6714334\ttest: 0.6712631\tbest: 0.6712631 (0)\ttotal: 184ms\tremaining: 6m 8s\n",
            "1999:\tlearn: 0.2682220\ttest: 0.2632702\tbest: 0.2632702 (1999)\ttotal: 4m 26s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2632701707\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 4/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713357\ttest: 0.6713897\tbest: 0.6713897 (0)\ttotal: 164ms\tremaining: 5m 26s\n",
            "1999:\tlearn: 0.2672507\ttest: 0.2692321\tbest: 0.2692317 (1998)\ttotal: 4m 20s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2692316602\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 5/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713990\ttest: 0.6712892\tbest: 0.6712892 (0)\ttotal: 145ms\tremaining: 4m 50s\n",
            "1999:\tlearn: 0.2676016\ttest: 0.2672303\tbest: 0.2672303 (1999)\ttotal: 4m 12s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.267230292\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 6/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6714109\ttest: 0.6712668\tbest: 0.6712668 (0)\ttotal: 149ms\tremaining: 4m 57s\n",
            "1999:\tlearn: 0.2682387\ttest: 0.2635503\tbest: 0.2635503 (1999)\ttotal: 4m 11s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2635503287\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 7/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6713976\ttest: 0.6713114\tbest: 0.6713114 (0)\ttotal: 164ms\tremaining: 5m 26s\n",
            "1999:\tlearn: 0.2673277\ttest: 0.2685575\tbest: 0.2685575 (1999)\ttotal: 4m 13s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2685574671\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 1/7 - LGBMClassifier\n",
            "FOLD 2/7 - LGBMClassifier\n",
            "FOLD 3/7 - LGBMClassifier\n",
            "FOLD 4/7 - LGBMClassifier\n",
            "FOLD 5/7 - LGBMClassifier\n",
            "FOLD 6/7 - LGBMClassifier\n",
            "FOLD 7/7 - LGBMClassifier\n",
            "FOLD 1/7 - HistGradientBoostingClassifier\n",
            "FOLD 2/7 - HistGradientBoostingClassifier\n",
            "FOLD 3/7 - HistGradientBoostingClassifier\n",
            "FOLD 4/7 - HistGradientBoostingClassifier\n",
            "FOLD 5/7 - HistGradientBoostingClassifier\n",
            "FOLD 6/7 - HistGradientBoostingClassifier\n",
            "FOLD 7/7 - HistGradientBoostingClassifier\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955424\n",
            "XGBClassifier CV AUC mean: 0.955425, std: +-0.00093\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955515\n",
            "CatBoostClassifier CV AUC mean: 0.955515, std: +-0.00092\n",
            "\n",
            "LGBMClassifier OOF AUC: 0.954930\n",
            "LGBMClassifier CV AUC mean: 0.954931, std: +-0.00093\n",
            "\n",
            "HistGradientBoostingClassifier OOF AUC: 0.955289\n",
            "HistGradientBoostingClassifier CV AUC mean: 0.955292, std: +-0.00096\n",
            "\n",
            "Stack (LR meta, 4 models) OOF AUC: 0.955538\n",
            "Submission: 4-model stack, 2-seed avg. test_proba shape: (270000,)\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import inspect\n",
        "\n",
        "SEED = 42\n",
        "NSPLITS = 7\n",
        "SEEDS = [42, 43]  # best version: 2-seed averaging\n",
        "USE_LR_STACK = False\n",
        "DROP_BP_MAX_HR = True\n",
        "\n",
        "# Reload data Kaggle-style (lowercase columns, id as index)\n",
        "path = DATA_DIR\n",
        "dfs = []\n",
        "for fl in (\"train.csv\", \"test.csv\"):\n",
        "    df = pd.read_csv(path / fl, index_col=0)\n",
        "    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns.tolist()]\n",
        "    dfs.append(df)\n",
        "train, test = dfs\n",
        "\n",
        "ystr = train.columns[-1]\n",
        "base_features = [c for c in train.columns if c != ystr]\n",
        "\n",
        "cols2comb = [\n",
        "    \"exercise_angina\", \"thallium\", \"chest_pain_type\",\n",
        "    \"slope_of_st\", \"sex\", \"st_depression\", \"number_of_vessels_fluro\",\n",
        "    \"ekg_results\", \"fbs_over_120\",\n",
        "]\n",
        "\n",
        "statmetrics = [\"mean\", \"count\"]\n",
        "\n",
        "X = train.drop(columns=ystr)\n",
        "y = (train[ystr] == \"Presence\").astype(int)\n",
        "\n",
        "X_test = test.copy()\n",
        "\n",
        "# Teacher model from original clinical dataset -> prior feature\n",
        "orig_path = DATA_DIR.parent / \"original-data\" / \"Heart_Disease_Prediction.csv\"\n",
        "orig_df = pd.read_csv(orig_path)\n",
        "orig_df.columns = [c.strip().lower().replace(\" \", \"_\") for c in orig_df.columns]\n",
        "orig_ystr = orig_df.columns[-1]\n",
        "orig_X = orig_df.drop(columns=orig_ystr)\n",
        "orig_y = (orig_df[orig_ystr] == \"Presence\").astype(int)\n",
        "\n",
        "common_cols = sorted(set(orig_X.columns) & set(X.columns))\n",
        "print(f\"Teacher model using {len(common_cols)} shared columns from original dataset\")\n",
        "\n",
        "teacher = cb.CatBoostClassifier(\n",
        "    iterations=400,\n",
        "    depth=4,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.9,\n",
        "    colsample_bylevel=0.9,\n",
        "    random_seed=SEED,\n",
        "    verbose=0,\n",
        ")\n",
        "teacher.fit(orig_X[common_cols], orig_y)\n",
        "\n",
        "X[\"teacher_pred\"] = teacher.predict_proba(X[common_cols])[:, 1]\n",
        "X_test[\"teacher_pred\"] = teacher.predict_proba(X_test[common_cols])[:, 1]\n",
        "\n",
        "# Adversarial validation: train vs test\n",
        "adv_X = pd.concat([X, X_test], axis=0).reset_index(drop=True)\n",
        "adv_y = np.concatenate([\n",
        "    np.zeros(len(X), dtype=int),\n",
        "    np.ones(len(X_test), dtype=int),\n",
        "])\n",
        "adv_skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "oof_adv = np.zeros(len(adv_y), dtype=float)\n",
        "for tr_adv, val_adv in adv_skf.split(adv_X, adv_y):\n",
        "    adv_clf = lgb.LGBMClassifier(\n",
        "        objective=\"binary\",\n",
        "        metric=\"auc\",\n",
        "        learning_rate=0.05,\n",
        "        n_estimators=400,\n",
        "        num_leaves=31,\n",
        "        feature_fraction=0.9,\n",
        "        bagging_fraction=0.9,\n",
        "        bagging_freq=1,\n",
        "        min_data_in_leaf=30,\n",
        "        random_state=SEED,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    adv_clf.fit(adv_X.iloc[tr_adv], adv_y[tr_adv])\n",
        "    oof_adv[val_adv] = adv_clf.predict_proba(adv_X.iloc[val_adv])[:, 1]\n",
        "\n",
        "auc_adv = roc_auc_score(adv_y, oof_adv)\n",
        "print(f\"Adversarial AUC (train vs test): {auc_adv:.5f}\")\n",
        "\n",
        "p_test_train = oof_adv[: len(X)]\n",
        "eps = 1e-3\n",
        "w_train = p_test_train / (1.0 - p_test_train + eps)\n",
        "w_train = w_train / w_train.mean()\n",
        "print(\n",
        "    f\"Sample weights (train-like vs test-like) -> min={w_train.min():.3f}, max={w_train.max():.3f}, mean={w_train.mean():.3f}\"\n",
        ")\n",
        "\n",
        "\n",
        "def get_cat_feature_indices(X_):\n",
        "    return [i for i, c in enumerate(X_.columns) if c.startswith(\"CAT_\")]\n",
        "\n",
        "\n",
        "def fe_foldwise(X_tr, X_val, y_tr):\n",
        "    X_tr = X_tr.copy()\n",
        "    X_val = X_val.copy()\n",
        "\n",
        "    temp = pd.concat([X_tr, y_tr], axis=1)\n",
        "\n",
        "    # casting\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"age>55\"] = (df[\"age\"] > 55).astype(int)\n",
        "        for col in df.columns:\n",
        "            if col == \"teacher_pred\":\n",
        "                continue\n",
        "            colname = f\"CAT_{col}\"\n",
        "            df[colname] = df[col].astype(str).astype(\"category\")\n",
        "\n",
        "    # numeric interactions and derived + bin features (from 0.954 notebook)\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"chest_pain_type_bin\"] = (df[\"chest_pain_type\"] >= 3).astype(int)\n",
        "        df[\"st_depression_bin\"] = (df[\"st_depression\"] >= 2).astype(int)\n",
        "        df[\"number_of_vessels_fluro_bin\"] = (df[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "        df[\"hr_age\"] = df[\"max_hr\"] * df[\"age\"]\n",
        "        df[\"bp_age\"] = df[\"bp\"] * df[\"age\"]\n",
        "        df[\"st_slope\"] = df[\"st_depression\"] * df[\"slope_of_st\"]\n",
        "        df[\"chol_exercise\"] = df[\"cholesterol\"] * df[\"exercise_angina\"]\n",
        "        pred_max = (220 - df[\"age\"]).clip(lower=10)\n",
        "        df[\"max_hr_pct_pred\"] = df[\"max_hr\"] / pred_max\n",
        "        df[\"risk_sum\"] = df[\"number_of_vessels_fluro\"] + df[\"thallium\"] + df[\"exercise_angina\"]\n",
        "        df[\"vessels_thallium\"] = df[\"number_of_vessels_fluro\"] * df[\"thallium\"]\n",
        "        df[\"age_chol\"] = df[\"age\"] * df[\"cholesterol\"]\n",
        "        df[\"risk_age\"] = df[\"risk_sum\"] * df[\"age\"]\n",
        "        df[\"teacher_pred_sq\"] = df[\"teacher_pred\"] ** 2\n",
        "\n",
        "    # target statistics + smoothed target encoding\n",
        "    global_mean = float(y_tr.mean())\n",
        "    m_smooth = 20\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            cname = f\"target_{bf}_{s}\"\n",
        "            X_tr[cname] = X_tr[bf].map(stats[s])\n",
        "            X_val[cname] = X_val[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_tr[f\"target_{bf}_smooth\"] = X_tr[bf].map(smoothed).fillna(global_mean)\n",
        "        X_val[f\"target_{bf}_smooth\"] = X_val[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    # categorical combinations\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_tr[c2].max(), X_val[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_tr[cname] = (\n",
        "                (X_tr[c1] + 1 + (X_tr[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "            X_val[cname] = (\n",
        "                (X_val[c1] + 1 + (X_val[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    if DROP_BP_MAX_HR:\n",
        "        X_tr = X_tr.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "        X_val = X_val.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "    return X_tr, X_val\n",
        "\n",
        "\n",
        "def fe_test(X_test_, X_train_, y_train_):\n",
        "    X_test_ = X_test_.copy()\n",
        "    temp = pd.concat([X_train_, y_train_], axis=1)\n",
        "\n",
        "    X_test_[\"age>55\"] = (X_test_[\"age\"] > 55).astype(int)\n",
        "    for col in X_test_.columns:\n",
        "        if col == \"teacher_pred\":\n",
        "            continue\n",
        "        colname = f\"CAT_{col}\"\n",
        "        X_test_[colname] = X_test_[col].astype(str).astype(\"category\")\n",
        "\n",
        "    X_test_[\"chest_pain_type_bin\"] = (X_test_[\"chest_pain_type\"] >= 3).astype(int)\n",
        "    X_test_[\"st_depression_bin\"] = (X_test_[\"st_depression\"] >= 2).astype(int)\n",
        "    X_test_[\"number_of_vessels_fluro_bin\"] = (X_test_[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "    X_test_[\"hr_age\"] = X_test_[\"max_hr\"] * X_test_[\"age\"]\n",
        "    X_test_[\"bp_age\"] = X_test_[\"bp\"] * X_test_[\"age\"]\n",
        "    X_test_[\"st_slope\"] = X_test_[\"st_depression\"] * X_test_[\"slope_of_st\"]\n",
        "    X_test_[\"chol_exercise\"] = X_test_[\"cholesterol\"] * X_test_[\"exercise_angina\"]\n",
        "    pred_max = (220 - X_test_[\"age\"]).clip(lower=10)\n",
        "    X_test_[\"max_hr_pct_pred\"] = X_test_[\"max_hr\"] / pred_max\n",
        "    X_test_[\"risk_sum\"] = X_test_[\"number_of_vessels_fluro\"] + X_test_[\"thallium\"] + X_test_[\"exercise_angina\"]\n",
        "    X_test_[\"vessels_thallium\"] = X_test_[\"number_of_vessels_fluro\"] * X_test_[\"thallium\"]\n",
        "    X_test_[\"age_chol\"] = X_test_[\"age\"] * X_test_[\"cholesterol\"]\n",
        "    X_test_[\"risk_age\"] = X_test_[\"risk_sum\"] * X_test_[\"age\"]\n",
        "    X_test_[\"teacher_pred_sq\"] = X_test_[\"teacher_pred\"] ** 2\n",
        "\n",
        "    global_mean = float(y_train_.mean())\n",
        "    m_smooth = 20\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            X_test_[f\"target_{bf}_{s}\"] = X_test_[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_test_[f\"target_{bf}_smooth\"] = X_test_[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_train_[c2].max(), X_test_[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_test_[cname] = (\n",
        "                (X_test_[c1] + 1 + (X_test_[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    if DROP_BP_MAX_HR:\n",
        "        X_test_ = X_test_.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "    return X_test_\n",
        "\n",
        "\n",
        "xgboost_params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"auc\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"max_depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"colsample_bytree\": 0.9,\n",
        "    \"n_estimators\": 2000,\n",
        "    \"min_child_weight\": 10,\n",
        "    \"gamma\": 1,\n",
        "    \"reg_lambda\": 0.01,\n",
        "    \"reg_alpha\": 1.5,\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"n_jobs\": -1,\n",
        "    \"random_state\": SEED,\n",
        "    \"early_stopping_rounds\": 100,\n",
        "    \"enable_categorical\": True,\n",
        "}\n",
        "\n",
        "catboost_params = {\n",
        "    \"loss_function\": \"Logloss\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"iterations\": 2000,\n",
        "    \"min_data_in_leaf\": 1,\n",
        "    \"l2_leaf_reg\": 1.002,\n",
        "    \"thread_count\": -1,\n",
        "    \"random_seed\": SEED,\n",
        "    \"early_stopping_rounds\": 100,\n",
        "    \"bootstrap_type\": \"Bernoulli\",\n",
        "}\n",
        "\n",
        "lgbm_params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"metric\": \"auc\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"n_estimators\": 1200,\n",
        "    \"num_leaves\": 20,\n",
        "    \"feature_fraction\": 0.9,\n",
        "    \"bagging_fraction\": 0.9,\n",
        "    \"bagging_freq\": 1,\n",
        "    \"min_data_in_leaf\": 30,\n",
        "    \"random_state\": SEED,\n",
        "    \"n_jobs\": -1,\n",
        "    \"verbose\": -1,\n",
        "}\n",
        "hgb_params = {\n",
        "    \"max_iter\": 2000,\n",
        "    \"learning_rate\": 0.02,\n",
        "    \"max_depth\": 6,\n",
        "    \"early_stopping\": True,\n",
        "    \"n_iter_no_change\": 80,\n",
        "    \"validation_fraction\": 0.1,\n",
        "    \"random_state\": SEED,\n",
        "}\n",
        "models = {\n",
        "    XGBClassifier: xgboost_params,\n",
        "    CatBoostClassifier: catboost_params,\n",
        "    LGBMClassifier: lgbm_params,\n",
        "    HistGradientBoostingClassifier: hgb_params,\n",
        "}\n",
        "\n",
        "oof_list, test_proba_list = [], []\n",
        "for SEED in SEEDS:\n",
        "    teacher = cb.CatBoostClassifier(\n",
        "        iterations=400, depth=4, learning_rate=0.05, subsample=0.9,\n",
        "        colsample_bylevel=0.9, random_seed=SEED, verbose=0,\n",
        "    )\n",
        "    teacher.fit(orig_X[common_cols], orig_y)\n",
        "    X[\"teacher_pred\"] = teacher.predict_proba(X[common_cols])[:, 1]\n",
        "    X_test[\"teacher_pred\"] = teacher.predict_proba(X_test[common_cols])[:, 1]\n",
        "    adv_skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "    oof_adv = np.zeros(len(adv_y), dtype=float)\n",
        "    for tr_adv, val_adv in adv_skf.split(adv_X, adv_y):\n",
        "        adv_clf = lgb.LGBMClassifier(\n",
        "            objective=\"binary\", metric=\"auc\", learning_rate=0.05, n_estimators=400,\n",
        "            num_leaves=31, feature_fraction=0.9, bagging_fraction=0.9, bagging_freq=1,\n",
        "            min_data_in_leaf=30, random_state=SEED, n_jobs=-1,\n",
        "        )\n",
        "        adv_clf.fit(adv_X.iloc[tr_adv], adv_y[tr_adv])\n",
        "        oof_adv[val_adv] = adv_clf.predict_proba(adv_X.iloc[val_adv])[:, 1]\n",
        "    p_test_train = oof_adv[: len(X)]\n",
        "    w_train = p_test_train / (1.0 - p_test_train + 1e-3)\n",
        "    w_train = w_train / w_train.mean()\n",
        "    w_train = np.clip(w_train, 0.3, 3.0)\n",
        "    w_train = w_train / w_train.mean()\n",
        "    xgboost_params = {**xgboost_params, \"random_state\": SEED}\n",
        "    catboost_params = {**catboost_params, \"random_seed\": SEED}\n",
        "    lgbm_params = {**lgbm_params, \"random_state\": SEED}\n",
        "    hgb_params_s = {**hgb_params, \"random_state\": SEED}\n",
        "    models_run = {\n",
        "        XGBClassifier: xgboost_params,\n",
        "        CatBoostClassifier: catboost_params,\n",
        "        LGBMClassifier: lgbm_params,\n",
        "        HistGradientBoostingClassifier: hgb_params_s,\n",
        "    }\n",
        "    kf = StratifiedKFold(n_splits=NSPLITS, shuffle=True, random_state=SEED)\n",
        "    oof_train_model = {}\n",
        "    oof_test_model = {}\n",
        "    cv_auc_model = defaultdict(list)\n",
        "    for modelClass, param in models_run.items():\n",
        "        model_name = modelClass.__name__\n",
        "        oof_train = np.zeros(len(X))\n",
        "        oof_test = np.zeros(len(X_test))\n",
        "\n",
        "        for fold, (tr, val) in enumerate(kf.split(X, y)):\n",
        "            print(f\"FOLD {fold + 1}/{NSPLITS} - {model_name}\")\n",
        "\n",
        "            X_tr_raw, X_val_raw = X.iloc[tr], X.iloc[val]\n",
        "            y_tr, y_val = y.iloc[tr], y.iloc[val]\n",
        "\n",
        "            X_tr, X_val = fe_foldwise(X_tr_raw, X_val_raw, y_tr)\n",
        "\n",
        "            model = modelClass(**param)\n",
        "            if model_name == \"HistGradientBoostingClassifier\":\n",
        "                X_tr_fit = X_tr.select_dtypes(include=[np.number])\n",
        "                X_val_fit = X_val.select_dtypes(include=[np.number])\n",
        "                model.fit(X_tr_fit, y_tr, sample_weight=w_train[tr])\n",
        "                oof_train[val] = model.predict_proba(X_val_fit)[:, 1]\n",
        "                X_test_fe = fe_test(X_test, X_tr_raw, y_tr)\n",
        "                X_test_fit = X_test_fe.select_dtypes(include=[np.number])\n",
        "                oof_test += model.predict_proba(X_test_fit)[:, 1] / NSPLITS\n",
        "            else:\n",
        "                fit_kwargs = {\n",
        "                    \"X\": X_tr,\n",
        "                    \"y\": y_tr,\n",
        "                    \"eval_set\": [(X_val, y_val)],\n",
        "                    \"sample_weight\": w_train[tr],\n",
        "                }\n",
        "                if model_name != \"LGBMClassifier\":\n",
        "                    fit_kwargs[\"verbose\"] = 2000\n",
        "                if \"cat_features\" in inspect.signature(model.fit).parameters:\n",
        "                    cat_features = get_cat_feature_indices(X_tr)\n",
        "                    fit_kwargs[\"cat_features\"] = cat_features\n",
        "                model.fit(**fit_kwargs)\n",
        "                oof_train[val] = model.predict_proba(X_val)[:, 1]\n",
        "                X_test_fe = fe_test(X_test, X_tr_raw, y_tr)\n",
        "                oof_test += model.predict_proba(X_test_fe)[:, 1] / NSPLITS\n",
        "            cv_auc_model[model_name].append(roc_auc_score(y[val], oof_train[val]))\n",
        "\n",
        "        oof_train_model[model_name] = oof_train\n",
        "        oof_test_model[model_name] = oof_test\n",
        "\n",
        "    # Evaluation per model (inside seed loop)\n",
        "    for modelClass in models_run.keys():\n",
        "        model_name = modelClass.__name__\n",
        "        print(f\"\\n{model_name} OOF AUC: {roc_auc_score(y, oof_train_model[model_name]):.6f}\")\n",
        "        print(\n",
        "            f\"{model_name} CV AUC mean: {np.mean(cv_auc_model[model_name]):.6f}, std: +-{np.std(cv_auc_model[model_name]):.5f}\"\n",
        "        )\n",
        "\n",
        "    # Stack: LR meta for 3+ models or when USE_LR_STACK; else tuned 2-model weight blend\n",
        "    X_oof_tr = pd.DataFrame.from_dict(oof_train_model)\n",
        "    X_oof_test = pd.DataFrame.from_dict(oof_test_model)\n",
        "    cols = list(X_oof_tr.columns)\n",
        "    use_meta = USE_LR_STACK or len(cols) >= 3\n",
        "    if use_meta:\n",
        "        meta = LogisticRegression(max_iter=500, random_state=SEED, class_weight=\"balanced\")\n",
        "        meta.fit(X_oof_tr, y, sample_weight=w_train)\n",
        "        oof_tr_final = pd.Series(meta.predict_proba(X_oof_tr)[:, 1], index=X_oof_tr.index)\n",
        "        oof_test_final = pd.Series(meta.predict_proba(X_oof_test)[:, 1], index=X_oof_test.index)\n",
        "        stack_auc = roc_auc_score(y, oof_tr_final)\n",
        "        print(f\"\\nStack (LR meta, {len(cols)} models) OOF AUC: {stack_auc:.6f}\")\n",
        "        oof_list.append(oof_tr_final.values)\n",
        "        test_proba_list.append(oof_test_final.values)\n",
        "    else:\n",
        "        a, b = X_oof_tr[cols[0]], X_oof_tr[cols[1]]\n",
        "        best_w, best_auc = 0.5, 0.0\n",
        "        for w in np.linspace(0, 1, 21):\n",
        "            blend = w * a + (1 - w) * b\n",
        "            auc = roc_auc_score(y, blend)\n",
        "            if auc > best_auc:\n",
        "                best_auc, best_w = auc, w\n",
        "        oof_tr_final = best_w * X_oof_tr[cols[0]] + (1 - best_w) * X_oof_tr[cols[1]]\n",
        "        oof_test_final = best_w * X_oof_test[cols[0]] + (1 - best_w) * X_oof_test[cols[1]]\n",
        "        print(f\"\\nBlend weight {cols[0]}={best_w:.2f}, {cols[1]}={1-best_w:.2f} -> OOF AUC: {best_auc:.6f}\")\n",
        "        oof_list.append(oof_tr_final.values)\n",
        "        test_proba_list.append(oof_test_final.values)\n",
        "\n",
        "# Seed averaging (outside SEED loop)\n",
        "oof = np.mean(oof_list, axis=0)\n",
        "test_proba = np.mean(test_proba_list, axis=0)\n",
        "N_STACK_MODELS = len(oof_train_model)\n",
        "print(f\"Submission: {N_STACK_MODELS}-model stack, {len(SEEDS)}-seed avg. test_proba shape: {test_proba.shape}\")\n",
        "\n",
        "# Ensure id column exists for submission\n",
        "test[\"id\"] = test.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix (OOF, threshold=0.5)\n",
            "Rows: true, Cols: predicted |  Absence   Presence\n",
            "[[311947  35599]\n",
            " [ 34325 248129]]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAF1CAYAAADBdGLoAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVQRJREFUeJzt3Qd4U+XbBvCnu2WPMmUVkLJBNrJE9hIEPpayh/CvArJRZImgoAwFAQEFEWSo7C0b2SDKEGTvvVugLW2+637wxKSLNPRIU+6fV2yT856TkzTkOc873SwWi0WIiIjIZbg/7xMgIiKi+GHwJiIicjEM3kRERC6GwZuIiMjFMHgTERG5GAZvIiIiF8PgTURE5GIYvImIiFwMgzcREZGLYfCmJOn48eNSs2ZNSZ06tbi5ucnixYsT9PhnzpzR486cOTNBj5sU5MqVS9q1a5egx9y9e7d4e3vL2bNnJTFavXq1pEiRQq5fv/68T4VeEAzeZJqTJ0/KO++8I7lz5xZfX19JlSqVVKhQQSZMmCAPHz409bnbtm0rBw8elE8++URmz54tpUqVMvX5kqIjR47I0KFD9ULlefvwww+lZcuWkjNnTrvHMbsz/r6VK1eWNGnSSLJkyaRIkSIyfPhwCQkJifFY8d3ntdde0wu1mG5Hjx7VMrVr15a8efPKqFGjTHoHiOy5cW5zMsOKFSvk//7v/8THx0fatGkjhQsXlrCwMNm2bZv8/PPPmpl98803pjw3LgzwhYwv/BEjRpjyHPhnExoaKl5eXuLh4SFJ0U8//aR/w40bN2oAcxTeF3d3d31vEsKBAwfklVdeke3bt0v58uWtj0dEREirVq1kwYIFUqlSJWncuLH+3bdu3Spz586VggULyq+//iqZMmV6pn3w2nEhGlNgfuONN/SiFCZPnix9+vSRK1euSMqUKRPktRPFCsGbKCGdOnXKkiJFCkv+/Pktly5dirb9+PHjlvHjx5v2/GfPnsUFqWXMmDGmPceLYOHChfo+bty48allIyMjLQ8ePDDlPLp3727JkSOHPoetkSNH6vn16dMn2j5Lly61uLu7W2rXrv3M+1SpUsVSqFChp57n1atXLR4eHpYZM2bE49UROYfBmxJc165d9Qvyt99+c6h8eHi4Zfjw4ZbcuXNbvL29LTlz5rQMHDjQ8ujRI7tyeLxevXqWrVu3WkqXLm3x8fGxBAQEWGbNmmUtM2TIEH1u2xv2g7Zt21p/t2XsY2vt2rWWChUqWFKnTm1Jnjy5JV++fHpOhtOnT+s+3333nd1+69evt1SsWNGSLFky3feNN96wHDlyJMbnw0UMzgnlUqVKZWnXrp0lJCTkqe+XEUz++OMPS+XKlS1+fn6WPHnyaLCFTZs2WcqUKWPx9fXV8163bp3d/mfOnLF069ZNt6FMunTpLE2bNtXXZMDrivo+2gZy42+xevVqS8mSJfVvMW7cOOs2vC5AwH3ttdcs/v7+GtwMoaGhlsKFC+vfPDg4OM7Xi8CN98YWLhTSpk2rrwGfn5i0b99ez3nHjh1O72P7fjvilVde0b85kdnY5k0JbtmyZdrO/eqrrzpUvlOnTjJ48GApUaKEjBs3TqpUqaJVlC1atIhW9sSJE9K0aVOpUaOGfPHFF5I2bVqtgj98+LBuRzUojgFoI0Xb5vjx4+N1/jhW/fr1tfoX7aB4HlSP/vbbb3Huh+rWWrVqybVr17StuFevXlrVi3b+mNqNmzVrJvfv39fXit/R+W3YsGEOnePt27f1HMuWLSujR4/W5gm8X/Pnz9efdevWlU8//VTbcPF+4XkMe/bs0fNCuS+//FK6du0q69ev1+rhBw8eaBm0B3fv3l1//+CDD/R9xK1AgQLW4xw7dkzfY/wt0I+hePHi0c4T7cLffvutPHr0SJ/HMGTIEH2fv/vuO0mePHmsr/PixYty7tw5/WzYQvML3gNUgXt6esa4L5prYPny5U7vY1vdfuPGDbtbcHBwtP1Lliyp7y2R6Uy/PKAXyt27dzVzadiwoUPlDxw4oOU7depk9ziqNfH4hg0brI8ho8NjW7ZssT527do1zfp69+4dLSuOWm3uaOaNDBL3r1+/Hut5x5R5Fy9e3JIxY0bLzZs3rY8hO0ZVbJs2baI9X4cOHeyO+eabb1rSp09veRpkgth/7ty51seOHj2qj+G5du7caX18zZo10c4zpuptZJoo9/333ztUbW78LZB5x7TNyLwNU6dO1fI//PCDnh+ql3v27PnU1/rrr7/qfsuWLbN7HM0ueHzRokWx7nvr1i0t07hxY6f3sX2/o96ivkbbannbWgYiMzDzpgR17949/eloh52VK1fqT2Sptnr37m3t+GYLHYrQ0ciQIUMGCQwMlFOnTklCQQ9kWLJkiURGRjq0z+XLl7VjFWoB0qVLZ328aNGimpkar9OWbSYKeF03b960vodxwbAk25oJvAc4b2TGyMYNxu+274+fn5/19/DwcH1O9JTG/vv37xdHBQQEaE2DI7p06aJl33vvPWndurXkyZNHRo4c+dT9cG6AGhZbRk1CXJ8zY5vxfjqzj+3wt3Xr1tnd+vXrF21/4zyRmROZicGbEpTR89a2mjYuGLeLnskIHrYyZ86swSTquN4cOXLE+IWJ6tCE0rx5c63qRnU+eh0jSKJ3clyB3DhPBNGoEFDxZR51GFLU12J88TvyWrJly6ZV0rYwpj179uzRHot6TPTGRzMFyqK63d/fXy+C7ty5I3fv3pX4BO/4mDFjhlbLYww+mghsLyKeJuqgGCPIxvU5ixqsndnHgKr96tWr291wIRnbeUb92xAlNAZvSvDgnTVrVjl06FC89nP0yy62YVmOjHiM7TnQnmkLQWXLli3aho0s8c8//9SAjgw6atln8SyvJbZ9HTkmsl+Mf0c7Oy5K1q5dq5lk+vTpHa5pgPgEX9i0aZP2IwCMwXcEzimmCxqj7R1/m9gY24wg68w+8WWcJy6IiMzE4E0JDh2pMC52x44dTy2LSTcQMJCN2bp69apmglEn5XgWyGxxzKhimrULtQHVqlWTsWPH6mQlCHYbNmzQMc+xvQ6jE1dUmMgDX+Zxdcz6r8dvYxIbdMQzOv9VrFgx2nuTkNkjmhVw0YBZ7/D5wHhoR2ZLy58/v/48ffq03eM4X9TMYGx2bBdU33//vf7E8zm7T3zhPI2aDCIzMXhTgkNbIAIVqp0RhKNCYEfvZECvaIjaIxxBE+rVq5dg54V2VlQL22ZeCCqLFi2yK3fr1q1o+xo9qY3MMaosWbJomVmzZtkFQdRAILM1XmdigOw8anb/1VdfRQtoxsVGTBc88dW5c2e9SEPVOSbnQW/vjh07PrWW4aWXXtLq/b1799o9jolVcAGAiyVMxhMV+kqgah7t7OXKlXN6n/jat2+f3UQyRGaJebwE0TMGSWQ3qGpGVaXtDGsYRrNw4ULr3NfFihXTLBBf6AgSGCaGeawRBBs1aiRVq1ZNsPNC23X//v3lzTff1GFQaH/FrFj58uWz66iF4WGoNseFAzJqDP36+uuvtZ0Z2VtsxowZI3Xq1NEvbwQmtC0jKKLdGUPHEgtklRj2hfNC9TBqSNBEYFRRG3AxgkD/2Wef6UUP2sdff/11yZgxY7yeD8PBjMCI9xDwvrz99tv6/v/vf/+Lc/+GDRvqBRYCvW1twIABA+T333/X88NraNKkiVblY0jYDz/8oJ89fI5sObOPo/A5wYVhUFCQU/snRRgiiH/3zsJ89phamWJgSh92IovF8vfff1s6d+5syZUrl06+kjJlSp345KuvvrKbgAUTZgwbNkwnXPHy8rJkz549zklaosJQHtyeNlTMmHwFk4PgfAIDA3XoUtShYphoBUPdsmbNquXws2XLlvp6njZJC4Y24TVi4hRMvNKgQYNYJ2mJOhTNmBjFdrKUmMQ2aUhs7w+OGRQUZL1/+/ZtnYwEE6dgJrxatWrpULOYhnhNmzZNJ1LB0K6YJmmJie1xzp8/r5PQ4H2ICkPjMAEOZuSLy/79+/W5MTlPVBEREfq+4T3H+41JZ/De4PMU2+Qv8d3H0UlaJk+erJPz3Lt376llXwQPHz60iGeyGIfZOXrLnDmzHoei49zmRJToof8BOkKixiCxwvzrmOjGmCToRYfhdqjd8SnYVsTDO/4HiAiT0COztNbHGMVC/2K1ORElehgTjnHwWGgmITsxJuSSoOh0uWbNmud9KomPp6+4ORG8LW7skhUXBm8iSvQw2cyztJ2aDUuCxjRdKmHYgg5dcG4/ihWDNxERmQcZtDNZNDPvODF4ExGReZB1O5V5M/WOC4M3ERGZh5m3KRi8EyFMZnHp0iWdX5lzJBPRfwkDkDDHO3r3Y6bBZ8bM2xQM3okQAnfUBSaIiP5L58+ft06qQ4kPg3ciZKxo5F2wrVNDLIjObhzzvE+BXNT9+/fk5YAcDi/r+3ROVptz9u44MXgnQkZVOQI3gzc5g5Na0LNKsCa7/6DafPLkyXo7c+aM3i9UqJAue4vpio1pWnv37i3z5s3T9Qkwfz2mPMaSv4Zz585Jt27ddPGhFClS6LTNo0aN0nn4bVfG69Wrlxw+fFhrRwcNGmSd6tkwadIknSr5ypUrOv0zpgIuU6aMdbsj5+IIXtoQEZH5HdacuTkoW7Zs8umnn+rCMFjEBnPwY058BFl4//33ZdmyZbquwubNm7VpsnHjxtb9sSgP1jIw1l/A/PaYix8XALYrxqEM1ls4cOCA9OzZUxdfsp2YZ/78+RrchwwZouslIHgjOGPee8PTzsXht5XToybiaQWLdGbmTU65tfur530K5MLfP5n90zzztKTW77EyvcXN0yfe+1seh0ro7i+07d32PLBAjo/P04+XLl06zYCx7C2WaMViSfjdWKYXi9BgcRqsILdq1SpdsAeB1MiAp0yZogsZXb9+XRdIwe9YYAcrBdoudoQFlTDDnjGZUOnSpWXixInWzsfI0LEcLhbFwXv6tHNxFDNvIiJKtJk3gh8uAowbqrLjgiwaVdIhISG6wh+y8fDwcKlevbrdOvE5cuTQgAn4WaRIEbuqa2TMuAAxsneUsT2GUcY4BrJ2PJdtGfTWx32jjCPn4ii2eRMRUaIVU+Ydk4MHD2qwRpsy2qyxjCyWvEUVNzLnNGnS2JVHoEa7NOBn1DZn4/7TyiDAY/nf27dv64VDTGWQXRvHeNq5OIrBm4iIzPOMHdYQuB2pvg8MDNRAjarpn376STucoU05qWLwJiIil59hzdvbW/Lmzau/lyxZUvbs2SMTJkyQ5s2ba5U22qZtM96rV69K5syZ9Xf83L17t93xsN3YZvw0HrMtgwsLPz8/8fDw0FtMZWyP8bRzcRTbvImIyOTM25k272cbqhYZGalDsRDIvby8ZP369dZtx44d06FhqGYH/ES1u22v8HXr1mlgRtW7Ucb2GEYZ4xi4eMBz2ZbBOeC+UcaRc3EUM28iIjKPu9uTmzP7OWjgwIE6phsdvzC1K3pzY0w2hnGhk1vHjh11CBd6oCMgo/c3gqXRu7tmzZoapFu3bi2jR4/W9meM4Q4KCrK2sXft2lV7kffr1086dOggGzZskAULFmgPdAOeA9X1pUqV0rHd48eP145z7du31+2OnIujGLyJiMilq82vXbsmbdq0kcuXL2uALFq0qAbuGjVq6PZx48Zpz+8mTZrYTYxiQHX38uXLdZIWBNLkyZNrEB4+fLi1TEBAgAZqjNNGdTzGlk+fPl2PZUAVPYaWYXw4LgCKFy+uw8hsO7E97Vwcfns4zjvx4ThvelYc502JZpx3pUHi5ukb7/0tjx9J6NYRz3weSRUzbyIiMg9XFTMFgzcREZmH63mbgsGbiIjMw8zbFAzeRERkHmbepmDwJiIi8zDzNgWDNxERmYeZtyn47hAREbkYZt5ERGQeVpubgsGbiIhM5GS1OSuG48TgTURE5mHmbQoGbyIiMn9VMWf2o1gxeBMRkXnY29wUfHeIiIhcDDNvIiIyD9u8TcHgTURE5mG1uSkYvImIyDzMvE3B4E1EROZh5m0KBm8iIjIPM29T8NKGiIjIxTDzJiIi07i5uenNiR3NOJ0kg8GbiIhMw+BtDgZvIiIyD2KwM3GYsTtODN5ERGQaZt7mYPAmIiLTMHibg73NiYiIXAwzbyIiMg0zb3MweBMRkWkYvM3B4E1EROZhb3NTMHgTEZFpmHmbg8GbiIhMntrcmeBtxtkkHQzeRERkGjf851QWzegdFw4VIyIicjHMvImIyDRs8zYHgzcREZmHvc1NweBNRETmcTLztjDzjhODNxERJbpqc+c6ub04GLyJiMg0DN7mYG9zIiIiF8PMm4iIzMMOa6Zg8CYiItOw2twcDN5ERGQaBm9zMHgTEZFpGLzNweBNRESmYfA2B3ubExERuRgGbyIiMr+3uTM3B40aNUpKly4tKVOmlIwZM0qjRo3k2LFjdmVee+01ay2AcevatatdmXPnzkm9evUkWbJkepy+ffvK48eP7cps2rRJSpQoIT4+PpI3b16ZOXNmtPOZNGmS5MqVS3x9faVs2bKye/duu+2PHj2SoKAgSZ8+vaRIkUKaNGkiV69edfwFM3gTEZGZogbM+NwctXnzZg2GO3fulHXr1kl4eLjUrFlTQkJC7Mp17txZLl++bL2NHj3aui0iIkIDd1hYmGzfvl1mzZqlgXnw4MHWMqdPn9YyVatWlQMHDkjPnj2lU6dOsmbNGmuZ+fPnS69evWTIkCGyf/9+KVasmNSqVUuuXbtmLfP+++/LsmXLZOHChXruly5dksaNG8fvfbVYLJZ47UGmu3fvnqROnVp8inQWNw/v53065IJu7f7qeZ8CufD3T2b/NHL37l1JlSrVM3+PZek4R9y9k8V7/8iwB3J5xlty/vx5u/NAxuvj4xPnvtevX9fMGYGxcuXK1sy7ePHiMn78+Bj3WbVqldSvX18DaaZMmfSxKVOmSP/+/fV43t7e+vuKFSvk0KFD1v1atGghd+7ckdWrV+t9ZNqoBZg4ceKT1xEZKdmzZ5f33ntPBgwYoO9rhgwZZO7cudK0aVMtc/ToUSlQoIDs2LFDypUr59D7w8ybiIgSbeaNwIeLAOOGKvKnQYCEdOnS2T0+Z84c8ff3l8KFC8vAgQPlwYMH1m0InEWKFLEGbkDGjIuQw4cPW8tUr17d7pgog8cBWfu+ffvsyri7u+t9owy2o2bAtkz+/PklR44c1jKOYG9zIiJKtDOsxZR5xwWZLqqzK1SooEHa0KpVK8mZM6dkzZpV/vzzT82i0S7+yy+/6PYrV67YBW4w7mNbXGUQ4B8+fCi3b9/W6veYyiC7No6BLD5NmjTRyhjP4wgGbyIiSrRDxRC441N9HxQUpNXa27Zts3u8S5cu1t+RYWfJkkWqVasmJ0+elDx58oirYbU5ERElCe+++64sX75cNm7cKNmyZYuzLNqm4cSJE/ozc+bM0Xp8G/exLa4yuLjw8/PTKnkPD48Yy9geA9XraCePrYwjGLyJiMile5tbLBYN3IsWLZINGzZIQEDAU/dBb3FABg7ly5eXgwcP2vUKR891BOaCBQtay6xfv97uOCiDxwHV4SVLlrQrg2p83DfKYLuXl5ddGVTfY5iaUcYRrDYnIiLTuImT1ebxaCgPCgrS3ttLlizRsd5G2zE6uCEjRtU4ttetW1fHVqPNG8O10BO9aNGiWhZDyxCkW7durUPIcIxBgwbpsY12dowLRy/yfv36SYcOHfRCYcGCBdoD3YBhYm3btpVSpUpJmTJltHc7hqy1b9/eek4dO3bUcuhQh4sD9ERH4Ha0pzkweBMRkUtPjzp58mTrcDBb3333nbRr104z4l9//dUaSNGDHROjIDgbUN2NKvdu3bppIE2ePLkG4eHDh1vLIKNHoEbgnzBhglbNT58+XXucG5o3b65DyzA+HBcAGJ6GYWS2ndjGjRunvdBxDqGhobr/119/Hb/3h+O8Ex9XH+f9+MYhibhxSCxh9/S+m2868cxcWjxS5fxn+2GJuP23WB5eF4kMF5/CncTN074H6eMreyXi3lmxPLwh4uYuvkU7R3ueiPvn5fHl3WJ5dFPE3VM80uUXzyzlxM0temtQZOgdCTu2QK/nbY8VenyRWEIuRSvvniqneOeuL64qKY3z/mbqZJk+dYqcPXtG7xcoWEgGfviR1KpdR+/Xql5Vtm7ZbLdPx85d5KtJU6z3k3lH/0zMmj1X/q95C+v9KZMnydSvJ+nzZM+eQ/oN+EDeat3Guh3De8Z8Nkrm/PC9XLp4UfLlC5SPR34qNWvVlqQkocd55+i2QNx9nBjnHfpAzk1u9sznkVS5TOaNKekwqw264kftYk+Ji5tXcvHMWk7cfNKIWEQibh+V8NMrxS1fM3H3Sy8S+Vg8UuUQSZVDHl/eGeMxLJYI8UiTRyzJM0nEzb+ibY98eEPCTy0Xz0ylxD1nNZHwEAk/v1keWyzi9VKFaMcKP7NO3JNnkcgQ+6EY3gF1RCwR/5Z9/EjCjs0X99Su1/s0qXrppWwy/JNRkjfvy9q2+cPsWdKsSSPZsXu/FCxUSMu079hJPhryb4aE6S2jmjr9W6lR899Aa/s9gguEIYM+kEmTv5GSpUrL3j27JahbF0mTNq3Uq99AywwbPEh+/HGOlgkMzC/r1q2RFv/XWDZs/k2Kv/KKye+C6+LCJC9I8MYg9YoVK0rt2rXt2hHIdXiktu8s4p6lnGbikQ+uavD2zFhMH4+4fzHWY3hledIT9HEMgVv3vX1c3Hz9NaNXPmnEM2t5CT+zRh+zrbF4fHmXuPmmEfcU2aIFbzdP3yjHPfEki0+TN74vm0xiBE/DsI8/kenfTJHdu3dagzeC9dN66qZOnSbWMj/O+UGz9abNmuv9gNy5Zd++PTL289HW55879wfNxmvXqav3u7zTTTauXy9fjh8r386anSCvlchle5vPmDFDG++3bNmi09SRa7NYIjXQonrcPXnmBDxwhIi7h/1j7p76eOSD69aHIu5fkMg7J8UrWxWHDhtx64h4pH1Z3Dy8Eu5cKcFgAoyF8+dpu2XZsv/2zJ3/41zJniWDlCpeRAZ/aD9zluH9Hu9qmUqvlpVZM7/VLN6AdkcfH/sLOV9fP83AUV0OYaGhutCELXSG2r7dfjwx/fe9zV9EiSp4BwcH66Tu6DCAyd9jWq3lt99+096B+EeEnnm2c8yePXtWGjRoIGnTptXOBoUKFZKVK1dat6NsnTp1dBUXdB5Ar8IbN25Yt6OzQ/fu3bUnIXoB4ip96NChds+PsXnvvPOO7o9zwAw+6ORgwMQAlSpV0n/U6BSB40WdHD8qfHGgfcj25uoiH96UR39OldA/pkj4+U3iFVBH3H3tpyp8Fu4pc4gl5MqTtnNLpFjCguXxlT1PNj4OsVaBh59bL145qjnUdyAy5KpYHt0Sj3RPhoVQ4nHo4EHJkDalpEnhK93f7SbzFv4iBf4ZvtOsRUuZMXO2rFq7Qfr0G6AZcoe2re32/2jIMPlh7nxZtnKtNHqzsfR8L0gmT/q3X0D1GjVl5nczZP/+fRrU9+3bq/cRuI3viOo1aslX48fJiePHnwz/+XWdLFn8i1y5fPk/fjdcC2KwszdykeCNLveY4zUwMFDefvtt+fZb+6tjwBJtX3zxhezZs0cnd0ewNq6M0aUfgRBZO8brffbZZxqojaD7+uuvyyuvvCJ79+7V3n8YFN+sWTO742MlGQT+Xbt26XAB9DTEOD7AP1gEf1xA/PDDD3LkyBH59NNPtZciYDgCqvvRgxBDEXAhgmCO8YdxwVy9tnP3Iui7OrR3ewc2F+98TcXDv7CEn10vkY9uJdjx0WbumfVVbefGBULo0TnWDnHGvIrh5zeKR9p84p4iq8NZt5tvenFPbj+1IT1/+QIDZeee32Xzbzulc5eu0qVjO/nryBHd1rFTF6lRs5YULlJEWrR6S6Z/O0uWLlkkp06etO6PDm7lX62gbdO9+/aX93v3lXFjP7fbjo5nr1UsL6mSeWub+ttvP+mshl7BMGbseMmT92UpXqSApE7uI716vCet27azbqeYPQnEzmTez/vME7dE1dscc9EimPbo0UPXUMXgeSyZhozY6LA2b9487YoPt27d0q76yNCxHzJyBE4sxRbViBEjZOvWrXZLt124cEEDJQbI58uXT58H1XIoZ8A4PQR9BOm1a9dq8P7rr7+0fFRYGg6BfOrUqdbHELyrVKmi2XfUKjcDLjhwMyDzxnm5am/zmISdWCJuPqnEK3tV62No8w4/uTjG3uYGtHk/vrgtxt7moB/fxw9EPHy0d3vY0R/1gsE9WSZ59Oc0ra6PsocGd8/sr4ln+n8zbEtEuIQenimeWcqIZ4YnbfKuLCn1No9Jvdo1tF164tf//lsz4N8asvQly1dpUI/JqpUrpEmjBnL7/kO7ubKRCOCiHt89M6Z/Ix99MEAuX79tF6CxFvPNmzd1jmxsx7H2/fFvDaCrS+je5rm7/yQePsnjvX9EaIic+rIpe5sn9g5rCKBYsBwz5ICnp6cGabSB247ds52BBlXbyNIRTAFV1KhyR5DFii0I5MYA/D/++EOnzDMycVvImI1gbJQ34B+xMeMOZuTBxUJMgdt4DmTcWLnGNrggY8c6sFjyLSaOLHHn+ixiiYxM8KNqu5jXky+Gx2hb90ohbn4Z9L53vib4A1jLRt49LY+v7Rfvl5toj3hbEXdOaHu5R9rABD9HSnj4NxUWGhbjtj//eDJzVubMT2bOiq0Mmtei/rvDzFfGtJo/LZgvderWj5ZZ4yL8pZde0kC/ePEv0rjJ/yXAK0q62Ns8iQdvBGlk27iatQ18+MdlrIv6NMh8MdgdvdQRwFEdjSp2dIBDezqq2FGVHpUxPZ7xjzfqBwhfFIB27LjgOdAejouIqLDc24si/NKOJ1XYXik080W7dGTwRfHK84Zut4SHiCX8gVjCnizbh3HaFncvcfNOae39bQm7r23WEh6sgd/ohObmk9paG4FA7J7ySVV55N1TEnFtv3jlrGUd5x21jT3yAS7C3J4MV4si4tZf4p46IFrvc3r+0AGtZu06Ovb6/v37smDeXNmyeZMsXbFaq8bnz5srterUlfTp0svBg39K/769pGKlylLknwvxFcuXybVrV6VMmXIaeNevX6fjtXu839v6HMf//ls7p5UuU1Zu37mtbdtHDh+SaTP+7Xeze/cuHd9drFhxuXTponzy8TD9bujVp99zeV/oxZYogjeC9vfff6+BFlPU2WrUqJH8+OOP2hYOO3futAZCjPn++++/7TJaVDdjCjvcsF7rtGnTNHiXKFFCfv75Z8mVK5dm9c5AVo6qdjxnTNk3ngPt4HnzvuDDjB4/lLCzvz7pOObhI+6+6TVwe6TM/u8kLVf32FSp/1Pbkv118Uz/5G8Zfnm3RN4++m+ZvzHBiohXnkbikfIl/T3y3jl5fGWfZsxufv7iFVDXpt3bcZGPbosl5LJ4/nNxQYnLtevXpFOHttoxDNWwhYsU1cBdrXoNuXD+vGzcsF4mfTVBq8uzZc8ujRo1lv4fDLK7IJ86+Wvp36eXJgS58+SVT8d8IR06/tsUg+ayCePHyvG/j2n5ylWq6vjtnLlyWcuEPnokw4d8JKdPn9IavFq168r0777nvBNP4WznMybeLtDmvXjxYq0iR/U0/nHawpqrmD92zJgx2uaNHuSYlg69vT/88EOtyj5+/LhOf4c1XNEmjcCKwP6///1P129FxzEMO8M0dWh/NnqTYzUZtKFjeju0VaN6HmUwhZ7txQP+cRo933EO6H06duxYDdJYoxXZOTqqococPeAx5y1qAdDxDcEcHd4crT1ICjOs0fOX1Nu8yXXavPP1+sXpNu+/xzZmm3cs3BNLlTnaqKMGbkC7NXqHIzACOo6hQxtWZsG8scuWLdPAbVw9o8c5MnEEUwRxY75YVMejlzjKILvHeq4I9gjM8ektiuy9dOnS0rJlS53EHhcCOKaRmW/evFkzcwwXQ892zG9r2xRARPQi4VCxJJx5kz1m3vSsmHlTYsm88/dZ5HTmffTzN5l5J+Y2byIiSprY5p2Eq82JiIjIccy8iYjINBznbQ4GbyIiMg2DtzkYvImIyDRs8zYHgzcREZnGTZzMvP9ZYIhixuBNRESmYeZtDgZvIiIyDdu8zcGhYkRERC6GmTcREZmG1ebmYPAmIiLTsNrcHAzeRERkGmbe5mDwJiIi0zDzNgeDNxERmcfZ5T0Zu+PE3uZEREQuhpk3ERGZhtXm5mDwJiIi07DDmjkYvImIyDTMvM3B4E1ERKZh5m0OBm8iIjINM29zsLc5ERGRi2HmTUREpmHmbQ4GbyIiMg3bvM3B4E1ERKZh5m0OBm8iIjINM29zMHgTEZFpmHmbg8GbiIhMgxDsVOZtxskkIRwqRkRE5GKYeRMRkWnc3dz05sx+FDsGbyIiMg07rJmDwZuIiEzDDmvmYPAmIiLTuLs9uTmzH8WOHdaIiMg8bv9m3/G5xae7+ahRo6R06dKSMmVKyZgxozRq1EiOHTtmV+bRo0cSFBQk6dOnlxQpUkiTJk3k6tWrdmXOnTsn9erVk2TJkulx+vbtK48fP7Yrs2nTJilRooT4+PhI3rx5ZebMmdHOZ9KkSZIrVy7x9fWVsmXLyu7du+N9Lk/D4E1ERC5t8+bNGgx37twp69atk/DwcKlZs6aEhIRYy7z//vuybNkyWbhwoZa/dOmSNG7c2Lo9IiJCA3dYWJhs375dZs2apYF58ODB1jKnT5/WMlWrVpUDBw5Iz549pVOnTrJmzRprmfnz50uvXr1kyJAhsn//filWrJjUqlVLrl275vC5OMLNYrFYnuE9IxPcu3dPUqdOLT5FOoubh/fzPh1yQbd2f/W8T4Fc+Psns38auXv3rqRKleqZv8dqjFsvXn4p4r1/+MNgWfd+NTl//rzdeSDj9fHxiXPf69eva+aMwFi5cmV9LRkyZJC5c+dK06ZNtczRo0elQIECsmPHDilXrpysWrVK6tevr4E0U6ZMWmbKlCnSv39/PZ63t7f+vmLFCjl06JD1uVq0aCF37tyR1atX631k2qgFmDhxot6PjIyU7Nmzy3vvvScDBgxw6FwcwcybiIhM4/YM/wECHy4CjBuqyJ8GARLSpUunP/ft26fZePXq1a1l8ufPLzly5NCACfhZpEgRa+AGZMy4CDl8+LC1jO0xjDLGMZC147lsy7i7u+t9o4wj5+IIdlgjIqJE22Etpsw7Lsh0UZ1doUIFKVy4sD525coVzZzTpEljVxaBGtuMMraB29hubIurDAL8w4cP5fbt21r9HlMZZNeOnosjGLyJiCjRDhVD4I5P9X1QUJBWa2/btk2SMlabExGR6ZO0OHOLr3fffVeWL18uGzdulGzZslkfz5w5s1Zpo23aFnp4Y5tRJmqPb+P+08rg4sLPz0/8/f3Fw8MjxjK2x3jauTiCwZuIiFyaxWLRwL1o0SLZsGGDBAQE2G0vWbKkeHl5yfr1662PYSgZhoaVL19e7+PnwYMH7XqFo+c6AnPBggWtZWyPYZQxjoHqcDyXbRlU4+O+UcaRc3EEq82JiMil5zYPCgrS3ttLlizRsd5G2zE6uCEjxs+OHTvqEC50YkNARu9vBEujdzeGliFIt27dWkaPHq3HGDRokB7baGfv2rWr9iLv16+fdOjQQS8UFixYoD3QDXiOtm3bSqlSpaRMmTIyfvx4HbLWvn176zk97VwcweBNREQuPbf55MmT9edrr71m9/h3330n7dq109/HjRunPb8xIUpoaKj2Ev/666+tZVHdjSr3bt26aSBNnjy5BuHhw4dbyyCjR6DGOO0JEyZo1fz06dP1WIbmzZvr0DKMD8cFQPHixXUYmW0ntqedi0PvD8d5Jz4c503PiuO8KbGM835j0manx3kvDaryzOeRVDHzJiIi03BVMXMweBMRkWm4nrc52NuciIjIxTDzJiIi0yB/diaHZt4dNwZvIiJKtDOsUcwYvImIKNHObU4xY/AmIiLTMPM2B4M3ERGZinE44TF4ExGRaZh5J6KhYlu3bpW3335bp5C7ePGiPjZ79uwkvwQbERGRSwbvn3/+WedhxWTvv//+u87LCpjCbuTIkWacIxERuXiHNWdulIDBe8SIETJlyhSZNm2aLmtmqFChguzfvz++hyMioheg2tyZGyVgmzfWHa1cuXK0xzEBfdTFxYmI6MXGSVoSSeadOXNmOXHiRLTH0d6dO3fuhDovIiJKQnObO3OjBAzenTt3lh49esiuXbu0WuPSpUsyZ84c6dOnj66DSkREFHVVMWdulIDV5gMGDJDIyEipVq2aPHjwQKvQfXx8NHi/99578T0cERERmR28kW1/+OGH0rdvX60+Dw4OloIFC0qKFPFfbJ2IiJI2jvNOZJO0eHt7a9AmIiKKjbNV4IzdCRy8q1atGucV0YYNG+J7SCIiSqKc7XzGDmsJHLyLFy9udz88PFwOHDgghw4dkrZt28b3cERElIQx804kwXvcuHExPj506FBt/yYiIjKwzTuRL0yCuc7LlCkjn3/+eUId8oV3btPnkipVqud9GuSCXu655HmfArmoyLAHz/sU6L8M3jt27BBfX9+EOhwRESWRyUTc/6tVs14g8Q7ejRs3trtvsVjk8uXLsnfvXvnoo48S8tyIiMjFsdo8kQRvzGFuy93dXQIDA2X48OFSs2bNhDw3IiJycW5OrhDG2J2AwTsiIkLat28vRYoUkbRp08ZnVyIiegE5u7wnlwRNwGYFDw8Pza65ehgRETmCS4KaI959AgoXLiynTp0y52yIiChJMTJvZ26UgMF7xIgRugjJ8uXLtaPavXv37G5ERESUSNq80SGtd+/eUrduXb3/xhtv2FVroNc57qNdnIiICDjD2nMO3sOGDZOuXbvKxo0bTToVIiJKaji3+XMO3sisoUqVKiadChERJTWcpCURDBVj7z8iIooPVpsnguCdL1++pwbwW7duPes5ERFREuEuTlabC6N3ggVvtHtHnWGNiIiIEnHwbtGihWTMmNG8syEioiSF1ebPOXizvZuIiOKL06Mmkt7mRERE8VuYxJlVxUw5nRcveEdGRpp7JkRElOSw2jyRLAlKRETkKFabm4Pj4ImIiFwMM28iIjKN2z//ObMfxY7Bm4iITMNqc3Ow2pyIiFx+Pe8tW7ZIgwYNJGvWrDq0efHixXbb27Vrp4/b3mrXrh1thtC33npLUqVKJWnSpJGOHTtKcHCwXZk///xTKlWqJL6+vpI9e3YZPXp0tHNZuHCh5M+fX8sUKVJEVq5cGW301uDBgyVLlizi5+cn1atXl+PHj8fr9TJ4ExGRaaIGzPjc4iMkJESKFSsmkyZNirUMgvXly5ettx9//NFuOwL34cOHZd26dbJ8+XK9IOjSpYt1+71796RmzZqSM2dO2bdvn4wZM0aGDh0q33zzjbXM9u3bpWXLlhr4f//9d2nUqJHeDh06ZC2DgP/ll1/KlClTZNeuXZI8eXKpVauWPHr0yOHXy2pzIiJy+WrzOnXq6C0uPj4+kjlz5hi3/fXXX7J69WrZs2ePlCpVSh/76quvpG7duvL5559rRj9nzhwJCwuTb7/9Vry9vaVQoUJy4MABGTt2rDXIT5gwQS8S+vbtq/c//vhjvRiYOHGiBmtk3ePHj5dBgwZJw4YNtcz3338vmTJl0toCzGTqCGbeRESUaCHbtb2FhoY6faxNmzbpFN+BgYHSrVs3uXnzpnXbjh07tKrcCNyA6mx3d3fNjo0ylStX1sBtQMZ87NgxuX37trUM9rOFMngcTp8+LVeuXLErgzVDypYtay3jCAZvIiIyfZIWZ26AdmUEN+M2atQop84D2TAy3PXr18tnn30mmzdv1kw9IiJCtyOgRl27w9PTU9KlS6fbjDLIkG0Z959Wxna77X4xlXEEq82JiMg0mBrVqSVB/9nn/Pnz2oHMturbGbbV0ehEVrRoUcmTJ49m49WqVRNXw8ybiIgSbW9zBG7bm7PBO6rcuXOLv7+/nDhxQu+jLfzatWt2ZR4/fqw90I12cvy8evWqXRnj/tPK2G633S+mMo5g8CYiIvM4W2Vu8jjvCxcuaJs3hmtB+fLl5c6dO9qL3LBhwwZd1wPt0UYZ9EAPDw+3lkFnNLShp02b1loGVfO2UAaPQ0BAgAZp2zJoy0e7ulHGEQzeRERkGndxc/oWH8HBwdrzGzejYxh+P3funG5D7++dO3fKmTNnNHCip3fevHm1MxkUKFBA28U7d+4su3fvlt9++03effddrW5HT3No1aqVdlbDMDAMKZs/f772Lu/Vq5f1PHr06KG91r/44gs5evSoDiXbu3evHgswBK5nz54yYsQIWbp0qRw8eFDatGmjz4EhZY5imzcREbn8qmJ79+6VqlWrWu8bAbVt27YyefJknVxl1qxZml0jUGK8NoZx2VbDYygYgizawNHLvEmTJjoe24AOc2vXrpWgoCApWbKkVrtjshXbseCvvvqqzJ07V4eCffDBB/Lyyy/rELDChQtby/Tr10/HpWM/nE/FihU14GNSF4ffHwsX6k50UIWCD8nVm3ftOmoQOerlnkue9ymQi4oMeyCXprWSu3ef7fvH+B77fO2f4pc8Zbz3fxhyX/rULPrM55FUMfMmIiLTcG5zczB4ExFRoh0qRjFj8CYiIpdv837RMHgTEZFptOe4M5k31/OOE4M3ERGZhpm3OTjOm4iIyMUw8yYiIlMzRGeyRGaWcWPwJiIi02BGMdyc2Y9ix+BNRESmcXaacobuuDF4ExGRaTjO2xwM3kREZCqG4YTHPgFEREQuhpk3ERGZhuO8zcHgTUREpmFvc3MweBMRkWk4ztscDN5ERGQaZt7mYPAmIiLTcJy3ORi8iYjINMy8zcFmBSIiIhfDzJuIiEzDDmvmYPAmIiLTsNrcHAzeRERkGnZYMweDNxERmYYzrJmDwZuIiEzjLm56c2Y/ih37BBAREbkYZt5ERGQaVpubg8GbiIhM4/bPf87sR7Fj8CYiItMw8zYHgzcREZkGGbQznc+YeceNwZuIiEzDzNsc7G1ORETkYph5ExGRaZh5m4PBm4iITMPe5uZg8CYiItO4uz25ObMfxY7Bm4iITMPM2xzssEam+2bKZCn9SlHJmC6V3qpULC9rVq+KVs5isUjD+nXEz8tNli5ZbH385s2b8ka92hKQI6ukTu4jeQOyS8/u78q9e/esZRYv+kXq1a4h2bNksD7HurVr7I4/YvhQPbbtrVjh/Ca/eoqve/t+kqsL+8jFb1rIpW/byo2VIyX89sUYy+Izc33ZcLkwqZE8PLXTblvY1eNyffFHcnFaK7k4/S25vnSohN04/e++j8Pk1voJcuXH7nLh68b6PFE9PLlDri8ZIpdmtJGL37SUaz/1l0fnfrcrExn2UO5snS6XZ3WWC1OaybWf++tzk32btzM3SqTBu127dta1Xr29vSVv3rwyfPhwefz48fM8LUpgL2XLJh+P/FS279onv+3cK69VfV3+r3FDOXL4sF25ryaMj3ENX3d3d6nfoKH89MtS+fPI3zJtxkzZuOFXeS+oq7XMtq1b5PXqNWTR0pX6PFVeqypNGjWQA7/bf9EWLFRITp+/bL2t37TNxFdOzgi9dFhSFK4jGZuMFv83hopERsiNpUMlMvxRtLLBfyyLMT9DQL2xbLh4pMwgGZuOkYxvjhJ3bz+5sXSYWCKefL9YLJHi5uEjKYrWF5/sxWI9F9/sxcS//keSsdkX4vNSYbmx4hMJu37KWub2xony6Pwfkq5GT8ncYoL4ZC8u15cOkYjgmwn4rrj6kqDO/EeJutq8du3a8t1330loaKisXLlSgoKCxMvLSwYOHGhXLiwsTAM8uZ569RvY3R/28Scybepk2b1rpwZT+OPAAZkw/gsN7gHZs9iVT5s2rXTp2s16P2fOnNLlnf/JuLFjrI99Pna83T7DR4yU5cuWyMoVy6T4K69YH/f08JTMmTMn+GukhJOhwRC7+2mrdZfL37aV8OsnxSfrk88LIIAGH1giGf/vc7k8s73dPo/vXJTI0PuSqkxL8UyZQR9LVbq5XJ3XUyLuXxfPNFnE3ctX0r725AIw7MpfEhkaEu1c0lTqZHc/dfnW8vD0bnl0Zo94Z8gtlsehmp2nr/uB9dxSl2mp24MPrZbU5d5KwHeGKBFVm/v4+OiXKb6Qu3XrJtWrV5elS5dqVt6oUSP55JNPJGvWrBIYGKjlz58/L82aNZM0adJIunTppGHDhnLmzBnr8TZt2iRlypSR5MmTa5kKFSrI2bNnrduXLFkiJUqUEF9fX8mdO7cMGzbMLtNH5jd9+nR58803JVmyZPLyyy/r+dg6fPiw1K9fX1KlSiUpU6aUSpUqycmTJ63bsX+BAgX0OfLnzy9ff/21ye+i64iIiJAF8+dJSEiIlC1XXh978OCBtGvTSsZ/OcmhwHrp0iVZsvgXqVSpSqxlIiMj5f79+5I2bTq7x0+cOK7V7wXy5ZZ2rd+Sc+fOJcCrIjNZQh/oT3efFNbHIsND5da6sZKmchfxSJ422j6eaV4Sd9+UEvLXr2KJCNcgG3LkV/FMm008UmV0/lwskWIJf2g9F0tkJP4nbh5eduXcPH0k9PIRp58nKXZYc+ZGiTh4R+Xn56dZNqxfv16OHTsm69atk+XLl0t4eLjUqlVLA+bWrVvlt99+kxQpUmj2jn0QhBHwq1SpIn/++afs2LFDunTpYq2KxT5t2rSRHj16yJEjR2Tq1Kkyc+ZMvUCwhYCOCwQco27duvLWW2/JrVu3dNvFixelcuXKetGxYcMG2bdvn3To0MF6ATBnzhwZPHiwHvOvv/6SkSNHykcffSSzZs2K9TWj1gHtt7a3pObQwYPinyaFtll3D+oq839aJAUKFtRt/Xq/L+XKvSoN3mgY5zHavN1S0qVKJnlyvqQXTpO/mR5r2XFjP5eQ4GBp8n/NrI+VLlNWvpkxU5YuXy1fTpwsZ86clupVK2mQp8QJwfLOthninaWAeKXPaX38Lh7LnF/8cpeNcT9UkWdoNEIeHNssF6c21/ZqtFX71x8sbu4eTp9P8O+LtfreL28F6/N4Zw6Ue3sXSETILbFERkjIsU0SduWYRD647fTzJCXOVZmz4vxpnnu1uW3HEwTrNWvWyHvvvSfXr1/X7BlZrFFd/sMPP2hGhceMgIwqd2TYyLhLlSold+/e1aw4T548uh0ZsG1QHjBggLRt21bvI/P++OOPpV+/fjJkyL9Vdcj6W7Zsqb8j+H755Zeye/duvUiYNGmSpE6dWubNm6fV+5AvXz7rvjjOF198IY0bN9b7AQEB1gsF43mjGjVqlJ5bUpYvMFB27T2gf59Fv/wknTu0lbXrN8vJkydk06YNsnOPfdt0TEZ/Pk4+HDREjh//WwYPGij9+/SSCROj12rM+3GujPx4mCz8ZYlkzPhvllWrdh3r70WKFtVgHpgnp/y8cIG069AxAV8tJZQ7m7+R8FtnJUPjUdbHUG0devGgZGw2Ntb9kGnf2jBRfLIUkBQ1e+tFQPCBxXJjxQjJ9H9jNDOOrwd/b5Z7e+ZrFblHsjTWx9NV76nPdXlmBxE3d/HKkEeSvVxJwq7/Wxv3IuMkLUk0eCOjRvaMrBqBuVWrVjJ06FBt+y5SpIhdO/cff/whJ06c0Mzb1qNHj7TaumbNmhp4kZ3XqFFDq+CRQWfJksW6P7J120wb1bjYH1W3qCaHokWLWrfjAgJZ3rVr1/T+gQMHtJrcCNy2UBWM8+jYsaN07tzZ+jiycgT82KB9v1evXtb7yLyzZ88uSQn+jnny5tXfS5QsKfv27pFJX00QXz8/OXXypGT2//fLEFo2ayIVKlaStes3WR9DlTpugfnza3U4suYBH35k/fsCquT/904nmTNvobxerXqc54SLvrwv59MLCEp8bm/5Rh6d3SMZ3hwpnin8rY+HXvhTHt+9Ipem27cn31w9WjP0jG9+Ig/+3iIR969JxqafiZvbkwpG7xq95NL0tzX4I7jGx4PjW+X2xkmSrlY/7cBmyzN1Fn1OZOSWsAfikTyd3FwzRjxTZXqm15+0Oqw5tx8l4uBdtWpVmTx5sn65o23b09PTLnDaCg4OlpIlS2rVdFQZMmSwZuLdu3eX1atXy/z582XQoEFa7V6uXDndHxmukRXbQvu0IWpgRpaPCwujWj82OD5MmzZNypa1r87z8Ii9qg5V8Li9SPB+orlg0JBh0r6DfaegUq8U0Sw7akc3W8ikICw01PrY/Hk/StfOHeT7OfOkTt16Tz0H/L1Onzopmd9q/UyvhRK+Fu7O1mk69AtV31GDYMoSTSR5wRp2j12d10NSV+ggfgGlnxzjcahmwXYhwLj/z2fHUbgQQGadvmZv8ctVKtZy6AAnXr4S+ShYq+hTvxpzTduLBiuKuTuRRjuzEtmL5LkHbwRoDBFzBDqaISCjKhTZcGxeeeUVvSGjLV++vMydO1eDN/ZHG7qjzxcTZOVov0ZNQdQgnylTJr0AOXXqlLaT0xMffThQq6yzZ8+h7cvz582VLZs3ybKVa6zZdFTZc+SQXAEB+vvqVSvl2tWrUrJUaa2lOXLksHwwoK+Uf7WC5MyVy1pVjqr4z8dO0OrwK1euWC+2jFqPAf366AVBjhw5tdPbiOFD9KKqWYsnTSSUONzZMlUDpn/dD8Tdy08iQp60Hbv7JNPqbnRQi7GTWkp/a6DHcK3I7bP0WCmK1MMVgdzf/zPGHYrPS0Ws+4TfOq8d2hBw0RHNGAKGnuRGVfmt9V9KmoodxTtTPuu5uHl6i7vPk+RCx31bLOKZ9iV5fPey3P1tpnilzSbJ81f7D94telElug5rcUFA9Pf31x7m6Hx2+vRpbetGpn3hwgW9j4CNjmroYb527Vo5fvy4td0bHcm+//57zb7RYxwdytB2jezcUe+++2RykBYtWsjevXv1+LNnz9aLAsCx0YaNdvK///5bDh48qLUBY8fG3j6X1F2/dk06tm8jRQsFSt1a1bTKHIG7WnX77Ck2CMDfzpgm1V6rKMWLFJB+fd6XevXfkF+WLLeW+Xb6N9o80bN7kA41M2593u9hLXPx4gXt9IbzeLtVM0mXPr1s3rbTWmtDiUPIodVa/Xx98SAdAmbcHhx3fEw+gqd/vQ8l/OZZnTTl2qIPtEOZf4MhWq1tuLF8uFxb0EuHdoVePKS/42YIPrxWx5nf2fKN3bnc2fZvZ0kMMbu9ZapcmRMkt36dIN5ZC+rzuHk899woUVWbO3OLjy1btkiDBg00gUJt6eLF/070ZNToIAagmQ3fKWhWxfe3LXRMRpxBcohmNTSBGjWqBnRkRtMpamvRvDl69Oho57Jw4UIdaYQyaP7FMOj4nsvTuNSnC23S+AP1799fq76Rxb300ktSrVo1fbMfPnwoR48e1cwYs3LhjUHb+TvvvKP7oy0cbeyYCOazzz7TzBlvcKdO9tW2cUmfPr32Mu/bt6/2akfmVrx4cR2SBjgWznPMmDFaBjUL+OP17NlTXlRTps2IV/mH4Ra7+5hwZdPW7XHuY9s2HpvZc+bF6zzo+cgWtDhB9vHNXlxvccnSZlqc29GW/TTJXq6oN3q+jd4hISFSrFgxHf0TU9MogiySKsQHdCTGKCDEBHQoNppNEbgvX76sTa2oXW3fvr2OWELtLSBxQ98qBNspU6ZocobnQ6BHOdi+fbt2eEYSh87T2BejoPbv3y+FCxd2+Fye+vZYcAlAiQo+IKjqvXrzbpzNA0Sxebnnkud9CuSiIsMeyKVprXRkyLN8/xjfY+t/PyfJU8b/OCH370m1V3I4dR5ubm6yaNEiDZqAMIeMvHfv3tKnTx99DMdFUyeGC6MmFTWxBQsWlD179ujIJUDfKQwXRs0u9kf/rA8//FCb5YzO1BjBhCwfiSM0b95cLySQKBrQbIskDwHfkXNJctXmRETkYpyd1/yfzDvqHBjo6BpfaFJFwEXGbMCFBToWo5kV8BMZtBG4AeUxPfOuXbusZTDPh+0oKGTMaDa9ffu2tYzt8xhljOdx5FwcweBNRESJts0b7coIbsYN1dHxZXRgRXZrC/eNbfhpOy8EYPQTZvK0LRPTMWyfI7Yyttufdi5Jrs2biIheLJgS27ba/EUbVhsbZt5ERJRoU28EbtubM8E78z/DUa9evWr3OO4b2/DTmIzLgBEs6IFuWyamY9g+R2xlbLc/7VwcweBNRERJem7zgIAADYyYgtuA9nO0ZWMuEMDPO3fu6HoVBowswoRSxqRbKIMRT+iJbkDPdCychdUPjTK2z2OUMZ7HkXNxBIM3ERGZxpnOas7Mhx4cHKzTV+NmdAzD71g5EL3PMVx3xIgRukokhnhhkSr0+jZ6pGM+EKxfgamtsZYFptLGvB7o/Y1ygOm70VkN478xVwgmDZswYYLd9NZY+Aq91LHGBXqgY7pvzAmCYz15P55+Lo5gmzcREbn83OZ79+7V6bYNRkDFglAYgoUFqDCEC+OxkWFXrFhRg6ztuGpMvY0gi7lD0Mu8SZMmOh7bgA5zmPwL84dgqm5MGobJVowx3vDqq6/q2G5M/vXBBx/ostIYSmaM8QZHzuWp7w/HeSc+HOdNz4rjvCmxjPPefPC8pHBinHfw/XtSpUj2Zz6PpIrV5kRERC6G1eZERGQaZzufJWSHtaSIwZuIiEzjTOczYz+KHYM3ERG5fIe1Fw2DNxERmYfR2xQM3kREZBq2eZuDwZuIiEzDNm9zcKgYERGRi2HmTUREpmGTtzkYvImIyDyM3qZg8CYiItOww5o5GLyJiMg07LBmDgZvIiIyDWvNzcHe5kRERC6GmTcREZmHqbcpGLyJiMg07LBmDgZvIiIyDTusmYPBm4iITMNac3MweBMRkXkYvU3B3uZEREQuhpk3ERGZhh3WzMHgTURE5nGywxpjd9wYvImIyDRs8jYHgzcREZmH0dsUDN5ERGQatnmbg8GbiIhMw0lazMGhYkRERC6GmTcREZmGTd7mYPAmIiLzMHqbgsGbiIhMww5r5mDwJiIicxNvZzqsmXEySQiDNxERmYa15uZgb3MiIiIXw8ybiIhMw3He5mDwJiIiE7Hi3AwM3kREZBpm3uZg8CYiItMw7zYHgzcREZmGmbc52NuciIjIxTDzJiIi03CGNXMweBMRkXnY6G0KBm8iIjINY7c5GLyJiMg07LBmDgZvIiIyDdu8zcHe5kRE5NKGDh0qbm5udrf8+fNbtz969EiCgoIkffr0kiJFCmnSpIlcvXrV7hjnzp2TevXqSbJkySRjxozSt29fefz4sV2ZTZs2SYkSJcTHx0fy5s0rM2fOjHYukyZNkly5comvr6+ULVtWdu/ebcprZvAmIiLzG72ducVDoUKF5PLly9bbtm3brNvef/99WbZsmSxcuFA2b94sly5dksaNG1u3R0REaOAOCwuT7du3y6xZszQwDx482Frm9OnTWqZq1apy4MAB6dmzp3Tq1EnWrFljLTN//nzp1auXDBkyRPbv3y/FihWTWrVqybVr1yShuVksFkuCH5Weyb179yR16tRy9eZdSZUq1fM+HXJBL/dc8rxPgVxUZNgDuTStldy9+2zfP8b32KmLNyWlE8e5f++e5H4pvUPnMXToUFm8eLEG1aiwf4YMGWTu3LnStGlTfezo0aNSoEAB2bFjh5QrV05WrVol9evX16CeKVMmLTNlyhTp37+/XL9+Xby9vfX3FStWyKFDh6zHbtGihdy5c0dWr16t95Fply5dWiZOnKj3IyMjJXv27PLee+/JgAEDJCEx8yYiItM7rDlzMy4CbG+hoaExPs/x48cla9askjt3bnnrrbe0Ghz27dsn4eHhUr16dWtZVKnnyJFDgzfgZ5EiRayBG5Ax4/kOHz5sLWN7DKOMcQxk7Xgu2zLu7u563yiTkBi8iYjoP+iyFr//jHpzZK7I4I3bqFGjoj0DMl5UcyMDnjx5slZxV6pUSe7fvy9XrlzRzDlNmjR2+yBQYxvgp23gNrYb2+IqgwD/8OFDuXHjhla/x1TGOEZCYm9zIiJKtEPFzp8/b1dtjs5iUdWpU8f6e9GiRTWY58yZUxYsWCB+fn6SFDHzJiKiRAuB2/YWU/COCll2vnz55MSJE5I5c2at0kbbtC30Nsc2wM+ovc+N+08rg3PCBYK/v794eHjEWMY4RkJi8CYioiQlODhYTp48KVmyZJGSJUuKl5eXrF+/3rr92LFj2iZevnx5vY+fBw8etOsVvm7dOg3MBQsWtJaxPYZRxjgGqubxXLZl0GEN940yCYnV5kRE5NIzrPXp00caNGigVeXoMY6hWsiCW7Zsqe3kHTt21CFc6dKl04CM3t8IqOhpDjVr1tQg3bp1axk9erS2UQ8aNEjHhhuZfteuXbUXeb9+/aRDhw6yYcMGrZZHD3QDnqNt27ZSqlQpKVOmjIwfP15CQkKkffv2ktAYvImIyKVnWLtw4YIG6ps3b+qwsIoVK8rOnTv1dxg3bpz2/MbkLOitjl7iX3/9tXV/BPrly5dLt27dNKgnT55cg/Dw4cOtZQICAjRQY8z4hAkTJFu2bDJ9+nQ9lqF58+Y6tAzjw3EBULx4ce1EF7UTW0LgOO9EiOO86VlxnDcllnHe56/eduo42D97prTPfB5JFTNvIiIyDVcVMweDdyJkVIZghiEiZ7Mnomf57CRYpSyjtykYvBMhTCwAeQOyP+9TIaIX+HsI1d6UODF4J0KY4g8TE6RMmVJXx6EY2sKyZ482eQORI/j5iRsybgRufA8lBC4Jag4G70QIvSLRk5HiZkzaQOQMfn5il5AZ938xVOxFxOBNRESmYZO3ORi8iYjIPIzepmDwJpeDGY8wg5IjcxwTRcXPz3+Lbd7m4CQtRESU4IxJWq7ccG6SFeyf2T81J2mJBTNvIiIyzf3795zqfIb9KHYM3kRElOCwyhaWwnz5GearwP44DkXHanMiIjLFo0ePdC1tZyFw+/r6Jug5JRUM3vSf2LRpk1StWlVu374tadKked6nQ0Tk0tyf9wlQ0rJjxw5dXq9evXrP+1TIBbRr105nEcQNWVbevHl1GcbHjx8/71MjStQYvClBzZgxQxe637Jli1y6dOl5nw65gNq1a8vly5fl+PHj0rt3bxk6dKiMGTMmWrlnqX4lSmoYvCnBBAcHy/z583VBe2TeM2fOjFbmt99+k6JFi2o7Vrly5eTQoUPWbWfPnpUGDRpI2rRpJXny5FKoUCFZuXKldTvK1qlTR1KkSKGL27du3Vpu3Lhh3f7aa69J9+7dpV+/fpIuXTrt7IJAYOvOnTvyzjvv6P44h8KFC8vy5cut27dt2yaVKlUSPz8/nf8axwsJCTHh3SIDxlvjb5UzZ0797FSvXl2WLl2qWXmjRo3kk08+0Xm2AwMDtTzmJG/WrJk2v+Dv3LBhQzlz5oxdE02ZMmX0M4QyFSpU0M+WYcmSJVKiRAn9++fOnVuGDRtml+mjFmD69Ony5ptvSrJkyeTll1/W87F1+PBhqV+/vg5hwhoE+MycPHnSuh37FyhQQJ8jf/788vXXX5v8LtKLhsGbEsyCBQv0iwpfsm+//bZ8++230ZYV7Nu3r3zxxReyZ88eyZAhgwbr8PBw3RYUFCShoaGatR88eFA+++wzDdRG0H399dfllVdekb1798rq1avl6tWr+iVua9asWfqlvWvXLhk9erRWwa5bt063RUZGavDHBcQPP/wgR44ckU8//VSr+QFfvsgCmzRpIn/++adeiCCYv/vuu//RO0iACycjy16/fr0cO3ZM/4a4yMJnpVatWhowt27dqn9LfEbwd8M+CMII+FWqVNG/IZpxunTpYl3gB/u0adNGevTooX//qVOn6kUmLhBsIaDjs4Vj1K1bV9566y25deuWbrt48aJUrlxZLzo2bNgg+/btkw4dOlgvAObMmSODBw/WY/71118ycuRI+eijj/SzSZRg0GGNKCG8+uqrlvHjx+vv4eHhFn9/f8vGjRv1Pn7i4zZv3jxr+Zs3b1r8/Pws8+fP1/tFihSxDB06NMZjf/zxx5aaNWvaPXb+/Hk95rFjx/R+lSpVLBUrVrQrU7p0aUv//v319zVr1ljc3d2t5aPq2LGjpUuXLnaPbd26Vfd5+PBhvN8Perq2bdtaGjZsqL9HRkZa1q1bZ/Hx8bH06dNHt2XKlMkSGhpqLT979mxLYGCgljVgOz5H+PviM4XPxKZNm2J8vmrVqllGjhxp9xiOmSVLFut97D9o0CDr/eDgYH1s1apVen/gwIGWgIAAS1hYWIzPkSdPHsvcuXOjfX7Lly8fz3eHKHYc500JAtnR7t27ZdGiRXrf09NTmjdvrm3gqM42lC9f3vo7qjyRpSM7AVRRo9p07dq1WnWKDBhV7PDHH3/Ixo0brZm4LWTM+fLl09+N8oYsWbLItWvX9PcDBw7oam1G2ajwHMi0kDkZ8F2OjP306dNaDUoJDxk1/q7IqvFet2rVSps7UBNTpEgRu3G++BudOHFCM++oQ5LwOahZs6ZWtyM7r1Gjhn6OkEHjc2Dsj2zdNtOOiIjQ/R88eKDV5FE/R6jJQfW47ecI1eReXl7RXguaWHAeHTt2lM6dO1sfR1bOtbEpITF4U4JAkMYXlO0awAh8qFqcOHGiQ8fo1KmTfumuWLFCA/ioUaO0ih0d4NCejip2VKVHZXwxQ9QvVFSXIiAY1bFxwXOgPRwXEVHlyJHDoddA8YchhJMnT9Ygjc8PLvxsA2fUv1HJkiXtLrAMaIaB7777Tv+GaFpB08egQYO02h19LLA/qsQbN24cbX/b8cTOfo5wfJg2bZqULVvWbpvRPEOUEBi86ZkhaH///fcaaJH52EL7448//qht4bBz505rIMSY77///tsuo0Unsa5du+pt4MCB+iWI4I0ORj///LPkypXL7ss9PpBNXbhwQZ8zpuwbz4F2UAxXov8OArSj7zn+RgjIGTNmjHO+a/SNwA2fIdT2zJ07V4M39kct0bP8jfE5Qvs1agqiBnl0hMQFyKlTp7SdnMgs7LBGCVLtiUCMqkL03ra9oeobWbkBHcjQCQk9x1G96e/vrwEeevbsKWvWrNEq6v3792s1uRHYUYWKDkMtW7bUzm6omkTZ9u3ba7WnI9CJCR2NcE7IxPA8q1at0gwN+vfvL9u3b9cOaqgaxdAl9Exmh7XEAwERnxn0MEfnM/wN0bscmTYuzHAfARsd1dDDHDU4+DsanyN0JMOFJrJv9BhHk828efM0O3cUPg9YNKNFixbaeRLHnz17tl4UAI6NWqMvv/xSLxTR+RK1AWPHjjXtfaEXD4M3PTMEZ7QtxtSmh0CJLzi0JQN6d6OnL6o+r1y5IsuWLbO2aSIII0jjixa9h5EdG0NskM2grRJlkN2jLRTBHkOB3N0d/xgjey9durReBBQsWFCHlRnBHxnV5s2b9QsXbZrI3PBlb9sUQM8X2qQxGgG1N6j6xmcFF41os0Ymju1Hjx7Vzx0+P+hpjs8UmkMAzTK42ERQx+cA2fi4ceN0mJqj0qdPr73MUUWOC0J8llFDZGThaP7BUDEEbHxOUQY92gMCAkx7X+jFw+lRiYiIXAwzbyIiIhfD4E1ERORiGLyJiIhcDIM3ERGRi2HwJiIicjEM3kRERC6GwZuIiMjFMHgTERG5GAZvIheHaWaNKWYBq7hh9rn/GqYpxQIeWHudiMzF4E1kYlBFMMMNU8BiMQzM7Y6FXMz0yy+/yMcff+xQWQZcItfEVcWITIQ52jHHdWhoqKxcuVLn2cYc2Fg8w1ZYWJjdutXPAuukE1HSxsybyERYzzxz5sy68EW3bt10AZelS5daq7o/+eQTXfgkMDBQy58/f16aNWumC64gCGP1rDNnzliPh0VUevXqpduxQAYWVom6PEHUanNcOGDFNCy3ivNBDQAWk8FxsZY2pE2bVjNwnBdg7WqsjIXFNLB+dbFixeSnn36yex5cjGDxD2zHcWzPk4jMxeBN9B9CoEOWDVgaFctIYnlSrHSF9aGx6lXKlCl1uUusopYiRQrN3o19sGY6Vqj69ttvZdu2bbpM6qJFi+J8zjZt2uia6liiEktgTp06VY+LYI5V1gDncfnyZZkwYYLeR+DG0plTpkzRpTPff/99efvtt3XVNeMiA6t6NWjQQJdPxUpaAwYMMPndIyIrrCpGRAmvbdu2loYNG+rvkZGRlnXr1ll8fHwsffr00W2ZMmWyhIaGWsvPnj3bEhgYqGUN2O7n52dZs2aN3s+SJYtl9OjR1u3h4eGWbNmyWZ8HqlSpYunRo4f+fuzYMaTl+twx2bhxo26/ffu29bFHjx5ZkiVLZtm+fbtd2Y4dO1patmypvw8cONBSsGBBu+39+/ePdiwiMgfbvIlMhIwaWS6yalRFt2rVSoYOHapt31jr2bad+48//pATJ05o5m0La1WfPHlS7t69q9lx2bJlrds8PT2lVKlS0arODciKPTw8dE1pR+EcHjx4IDVq1LB7HNk/1jgHZPC25wHly5d3+DmI6NkweBOZCG3BkydP1iCNtm0EW0Py5MntygYHB0vJkiVlzpw50Y6TIUMGp6vp4wvnAStWrJCXXnrJbhvazIno+WPwJjIRAjQ6iDmiRIkSMn/+fMmYMaOkSpUqxjJZsmSRXbt2SeXKlfU+hp3t27dP940Jsntk/GirRme5qIzMHx3hDAULFtQgfe7cuVgz9gIFCmjHO1s7d+506HUS0bNjhzWiROKtt94Sf39/7WGODmunT5/Wcdjdu3eXCxcuaJkePXrIp59+KosXL5ajR4/K//73vzjHaOfKlUvatm0rHTp00H2MYy5YsEC3oxc8epmjev/69euadaPavk+fPtpJbdasWVplv3//fvnqq6/0PnTt2lWOHz8uffv21c5uc+fO1Y50RPTfYPAmSiSSJUsmW7ZskRw5cmhPbmS3HTt21DZvIxPv3bu3tG7dWgMy2pgRaN988804j4tq+6ZNm2qgz58/v3Tu3FlCQkJ0G6rFhw0bpj3FM2XKJO+++64+jklePvroI+11jvNAj3dUo2PoGOAc0VMdFwQYRoZe6SNHjjT9PSKiJ9zQa+2f34mIiMgFMPMmIiJyMQzeRERELobBm4iIyMUweBMREbkYBm8iIiIXw+BNRETkYhi8iYiIXAyDNxERkYth8CYiInIxDN5EREQuhsGbiIhIXMv/A6GJdj+VWbvAAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred = (oof >= 0.5).astype(int)\n",
        "cm = confusion_matrix(y, y_pred)\n",
        "print(\"Confusion matrix (OOF, threshold=0.5)\")\n",
        "print(\"Rows: true, Cols: predicted |  Absence   Presence\")\n",
        "print(cm)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "plt.colorbar()\n",
        "plt.xticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.yticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
        "plt.title(\"Confusion matrix (OOF)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission saved (4-model blend): submission.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>630000</th>\n",
              "      <td>630000</td>\n",
              "      <td>0.960015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630001</th>\n",
              "      <td>630001</td>\n",
              "      <td>0.048189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630002</th>\n",
              "      <td>630002</td>\n",
              "      <td>0.967365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630003</th>\n",
              "      <td>630003</td>\n",
              "      <td>0.046922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630004</th>\n",
              "      <td>630004</td>\n",
              "      <td>0.158595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630005</th>\n",
              "      <td>630005</td>\n",
              "      <td>0.966422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630006</th>\n",
              "      <td>630006</td>\n",
              "      <td>0.046348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630007</th>\n",
              "      <td>630007</td>\n",
              "      <td>0.607360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630008</th>\n",
              "      <td>630008</td>\n",
              "      <td>0.967981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630009</th>\n",
              "      <td>630009</td>\n",
              "      <td>0.049236</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  Heart Disease\n",
              "id                           \n",
              "630000  630000       0.960015\n",
              "630001  630001       0.048189\n",
              "630002  630002       0.967365\n",
              "630003  630003       0.046922\n",
              "630004  630004       0.158595\n",
              "630005  630005       0.966422\n",
              "630006  630006       0.046348\n",
              "630007  630007       0.607360\n",
              "630008  630008       0.967981\n",
              "630009  630009       0.049236"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub = pd.DataFrame({\"id\": test[\"id\"], \"Heart Disease\": test_proba})\n",
        "sub.to_csv(OUTPUT_DIR / \"submission.csv\", index=False)\n",
        "print(f\"Submission saved ({N_STACK_MODELS}-model blend): {OUTPUT_DIR / 'submission.csv'}\")\n",
        "sub.head(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
