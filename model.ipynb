{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicting Heart Disease\n",
        "\n",
        "## Score: .95375"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict, KFold\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import catboost as cb\n",
        "from catboost import CatBoostClassifier\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "DATA_DIR = Path(\"playground-series-s6e2\")\n",
        "OUTPUT_DIR = Path(\".\")\n",
        "n_splits = 5\n",
        "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (630000, 15)\n",
            "Test: (270000, 14)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Chest pain type</th>\n",
              "      <th>BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FBS over 120</th>\n",
              "      <th>EKG results</th>\n",
              "      <th>Max HR</th>\n",
              "      <th>Exercise angina</th>\n",
              "      <th>ST depression</th>\n",
              "      <th>Slope of ST</th>\n",
              "      <th>Number of vessels fluro</th>\n",
              "      <th>Thallium</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>152</td>\n",
              "      <td>239</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>325</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>160</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>134</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>140</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Presence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  Age  Sex  Chest pain type   BP  Cholesterol  FBS over 120  EKG results  \\\n",
              "0   0   58    1                4  152          239             0            0   \n",
              "1   1   52    1                1  125          325             0            2   \n",
              "2   2   56    0                2  160          188             0            2   \n",
              "3   3   44    0                3  134          229             0            2   \n",
              "4   4   58    1                4  140          234             0            2   \n",
              "\n",
              "   Max HR  Exercise angina  ST depression  Slope of ST  \\\n",
              "0     158                1            3.6            2   \n",
              "1     171                0            0.0            1   \n",
              "2     151                0            0.0            1   \n",
              "3     150                0            1.0            2   \n",
              "4     125                1            3.8            2   \n",
              "\n",
              "   Number of vessels fluro  Thallium Heart Disease  \n",
              "0                        2         7      Presence  \n",
              "1                        0         3       Absence  \n",
              "2                        0         3       Absence  \n",
              "3                        0         3       Absence  \n",
              "4                        3         3      Presence  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR / \"test.csv\")\n",
        "print(f\"Train: {train.shape}\")\n",
        "print(f\"Test: {test.shape}\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features: 32 columns\n",
            "Target distribution: {0: 347546, 1: 282454}\n"
          ]
        }
      ],
      "source": [
        "target_col = \"Heart Disease\"\n",
        "id_col = \"id\"\n",
        "feature_cols = [c for c in train.columns if c not in (id_col, target_col)]\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(train[target_col])\n",
        "\n",
        "X_train = train[feature_cols].copy()\n",
        "X_test = test[feature_cols].copy()\n",
        "\n",
        "for col in feature_cols:\n",
        "    if X_train[col].isna().any() or X_test[col].isna().any():\n",
        "        med = X_train[col].median()\n",
        "        X_train[col] = X_train[col].fillna(med)\n",
        "        X_test[col] = X_test[col].fillna(med)\n",
        "\n",
        "X_train[\"chol_exercise\"] = X_train[\"Cholesterol\"] * X_train[\"Exercise angina\"]\n",
        "X_test[\"chol_exercise\"] = X_test[\"Cholesterol\"] * X_test[\"Exercise angina\"]\n",
        "X_train[\"st_slope\"] = X_train[\"ST depression\"] * X_train[\"Slope of ST\"]\n",
        "X_test[\"st_slope\"] = X_test[\"ST depression\"] * X_test[\"Slope of ST\"]\n",
        "X_train[\"hr_age\"] = X_train[\"Max HR\"] * X_train[\"Age\"]\n",
        "X_test[\"hr_age\"] = X_test[\"Max HR\"] * X_test[\"Age\"]\n",
        "X_train[\"bp_age\"] = X_train[\"BP\"] * X_train[\"Age\"]\n",
        "X_test[\"bp_age\"] = X_test[\"BP\"] * X_test[\"Age\"]\n",
        "\n",
        "te_cols = [\"Chest pain type\", \"Slope of ST\", \"Thallium\"]\n",
        "global_mean = float(y.mean())\n",
        "m = 20\n",
        "for col in te_cols:\n",
        "    agg = pd.DataFrame({\"_y\": y}).groupby(X_train[col])[\"_y\"].agg([\"mean\", \"count\"])\n",
        "    smoothed = (agg[\"count\"] * agg[\"mean\"] + m * global_mean) / (agg[\"count\"] + m)\n",
        "    X_train[col + \"_te\"] = X_train[col].map(smoothed).fillna(global_mean)\n",
        "    X_test[col + \"_te\"] = X_test[col].map(smoothed).fillna(global_mean)\n",
        "\n",
        "scaler_feat = StandardScaler()\n",
        "X_tr_s = scaler_feat.fit_transform(X_train)\n",
        "X_te_s = scaler_feat.transform(X_test)\n",
        "kmeans = KMeans(n_clusters=12, random_state=42, n_init=10)\n",
        "kmeans.fit(X_tr_s)\n",
        "for i in range(kmeans.n_clusters):\n",
        "    d_tr = np.linalg.norm(X_tr_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    d_te = np.linalg.norm(X_te_s - kmeans.cluster_centers_[i], axis=1)\n",
        "    X_train[f\"dist_c{i}\"] = d_tr\n",
        "    X_test[f\"dist_c{i}\"] = d_te\n",
        "\n",
        "print(f\"Features: {len(X_train.columns)} columns\")\n",
        "print(f\"Target distribution: {pd.Series(y).value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best OOF AUC: 0.95507, params: {'depth': 6, 'lr': 0.05, 'min_data_in_leaf': 15}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\"depth\": [4, 5, 6], \"lr\": [0.03, 0.04, 0.05], \"min_data_in_leaf\": [15, 25, 35]}\n",
        "n_est = 800\n",
        "best_auc, best_params = 0, None\n",
        "for depth in param_grid[\"depth\"]:\n",
        "    for lr in param_grid[\"lr\"]:\n",
        "        for min_leaf in param_grid[\"min_data_in_leaf\"]:\n",
        "            m = cb.CatBoostClassifier(iterations=n_est, depth=depth, learning_rate=lr, min_data_in_leaf=min_leaf, subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "            oof = cross_val_predict(m, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "            auc = roc_auc_score(y, oof)\n",
        "            if auc > best_auc:\n",
        "                best_auc, best_params = auc, {\"depth\": depth, \"lr\": lr, \"min_data_in_leaf\": min_leaf}\n",
        "print(f\"Best OOF AUC: {best_auc:.5f}, params: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV AUC: 0.95517 (blend w_xgb=0.4)\n"
          ]
        }
      ],
      "source": [
        "model = cb.CatBoostClassifier(iterations=n_est, depth=best_params[\"depth\"], learning_rate=best_params[\"lr\"], min_data_in_leaf=best_params[\"min_data_in_leaf\"], subsample=0.75, colsample_bylevel=0.75, random_seed=42, verbose=0)\n",
        "oof_cb = cross_val_predict(model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=n_est, max_depth=5, learning_rate=0.05, min_child_weight=20, subsample=0.75, colsample_bytree=0.75, random_state=42, eval_metric=\"auc\")\n",
        "oof_xgb = cross_val_predict(xgb_model, X_train, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "best_w, best_auc = 0.0, roc_auc_score(y, oof_cb)\n",
        "for w in [0, 0.1, 0.2, 0.3, 0.4]:\n",
        "    oof_blend = (1 - w) * oof_cb + w * oof_xgb\n",
        "    auc = roc_auc_score(y, oof_blend)\n",
        "    if auc > best_auc:\n",
        "        best_auc, best_w = auc, w\n",
        "oof = (1 - best_w) * oof_cb + best_w * oof_xgb\n",
        "print(f\"CV AUC: {best_auc:.5f} (blend w_xgb={best_w})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train, y)\n",
        "xgb_model.fit(X_train, y)\n",
        "test_cb = model.predict_proba(X_test)[:, 1]\n",
        "test_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
        "test_proba = (1 - best_w) * test_cb + best_w * test_xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher model using 13 shared columns from original dataset\n",
            "Adversarial AUC (train vs test): 0.50147\n",
            "Sample weights (train-like vs test-like) -> min=0.350, max=2.793, mean=1.000\n",
            "FOLD 1/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90656\n",
            "[1918]\tvalidation_0-auc:0.95594\n",
            "FOLD 2/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90619\n",
            "[1999]\tvalidation_0-auc:0.95512\n",
            "FOLD 3/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90469\n",
            "[1950]\tvalidation_0-auc:0.95473\n",
            "FOLD 4/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90561\n",
            "[1999]\tvalidation_0-auc:0.95546\n",
            "FOLD 5/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90538\n",
            "[1999]\tvalidation_0-auc:0.95455\n",
            "FOLD 6/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90684\n",
            "[1806]\tvalidation_0-auc:0.95663\n",
            "FOLD 7/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90538\n",
            "[1996]\tvalidation_0-auc:0.95557\n",
            "FOLD 1/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716753\ttest: 0.6716050\tbest: 0.6716050 (0)\ttotal: 148ms\tremaining: 4m 56s\n",
            "1999:\tlearn: 0.2677064\ttest: 0.2659247\tbest: 0.2659247 (1999)\ttotal: 4m 30s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2659247341\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 2/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716424\ttest: 0.6715131\tbest: 0.6715131 (0)\ttotal: 138ms\tremaining: 4m 34s\n",
            "1999:\tlearn: 0.2672700\ttest: 0.2683280\tbest: 0.2683280 (1999)\ttotal: 4m 40s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2683279696\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 3/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716187\ttest: 0.6716489\tbest: 0.6716489 (0)\ttotal: 144ms\tremaining: 4m 47s\n",
            "1999:\tlearn: 0.2670727\ttest: 0.2694491\tbest: 0.2694491 (1999)\ttotal: 4m 23s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2694490865\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 4/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716309\ttest: 0.6716115\tbest: 0.6716115 (0)\ttotal: 151ms\tremaining: 5m 1s\n",
            "1999:\tlearn: 0.2675434\ttest: 0.2672440\tbest: 0.2672440 (1999)\ttotal: 4m 22s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2672439847\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 5/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6718844\ttest: 0.6718587\tbest: 0.6718587 (0)\ttotal: 130ms\tremaining: 4m 20s\n",
            "1999:\tlearn: 0.2670140\ttest: 0.2703260\tbest: 0.2703257 (1995)\ttotal: 4m 21s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2703257293\n",
            "bestIteration = 1995\n",
            "\n",
            "Shrink model to first 1996 iterations.\n",
            "FOLD 6/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716368\ttest: 0.6715745\tbest: 0.6715745 (0)\ttotal: 148ms\tremaining: 4m 56s\n",
            "1999:\tlearn: 0.2680555\ttest: 0.2639368\tbest: 0.2639367 (1998)\ttotal: 4m 23s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2639367359\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 7/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6716372\ttest: 0.6716530\tbest: 0.6716530 (0)\ttotal: 150ms\tremaining: 4m 59s\n",
            "1999:\tlearn: 0.2676482\ttest: 0.2670100\tbest: 0.2670100 (1999)\ttotal: 4m 20s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2670099979\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 1/7 - LGBMClassifier\n",
            "FOLD 2/7 - LGBMClassifier\n",
            "FOLD 3/7 - LGBMClassifier\n",
            "FOLD 4/7 - LGBMClassifier\n",
            "FOLD 5/7 - LGBMClassifier\n",
            "FOLD 6/7 - LGBMClassifier\n",
            "FOLD 7/7 - LGBMClassifier\n",
            "FOLD 1/7 - HistGradientBoostingClassifier\n",
            "FOLD 2/7 - HistGradientBoostingClassifier\n",
            "FOLD 3/7 - HistGradientBoostingClassifier\n",
            "FOLD 4/7 - HistGradientBoostingClassifier\n",
            "FOLD 5/7 - HistGradientBoostingClassifier\n",
            "FOLD 6/7 - HistGradientBoostingClassifier\n",
            "FOLD 7/7 - HistGradientBoostingClassifier\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955426\n",
            "XGBClassifier CV AUC mean: 0.955432, std: +-0.00067\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955531\n",
            "CatBoostClassifier CV AUC mean: 0.955534, std: +-0.00069\n",
            "\n",
            "LGBMClassifier OOF AUC: 0.954902\n",
            "LGBMClassifier CV AUC mean: 0.954905, std: +-0.00068\n",
            "\n",
            "HistGradientBoostingClassifier OOF AUC: 0.955272\n",
            "HistGradientBoostingClassifier CV AUC mean: 0.955278, std: +-0.00069\n",
            "\n",
            "Stack (LR meta, 4 models) OOF AUC: 0.955543\n",
            "FOLD 1/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88833\n",
            "[1916]\tvalidation_0-auc:0.95470\n",
            "FOLD 2/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88937\n",
            "[1896]\tvalidation_0-auc:0.95583\n",
            "FOLD 3/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89012\n",
            "[1999]\tvalidation_0-auc:0.95562\n",
            "FOLD 4/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.89183\n",
            "[1740]\tvalidation_0-auc:0.95589\n",
            "FOLD 5/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88989\n",
            "[1999]\tvalidation_0-auc:0.95526\n",
            "FOLD 6/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88999\n",
            "[1990]\tvalidation_0-auc:0.95527\n",
            "FOLD 7/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.88759\n",
            "[1999]\tvalidation_0-auc:0.95542\n",
            "FOLD 1/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6718004\ttest: 0.6717736\tbest: 0.6717736 (0)\ttotal: 118ms\tremaining: 3m 56s\n",
            "1999:\tlearn: 0.2671851\ttest: 0.2696225\tbest: 0.2696225 (1999)\ttotal: 4m 26s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2696224877\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 2/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6718689\ttest: 0.6717551\tbest: 0.6717551 (0)\ttotal: 146ms\tremaining: 4m 52s\n",
            "1999:\tlearn: 0.2677478\ttest: 0.2664742\tbest: 0.2664742 (1999)\ttotal: 4m 34s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2664741748\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 3/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6718226\ttest: 0.6718335\tbest: 0.6718335 (0)\ttotal: 147ms\tremaining: 4m 54s\n",
            "1999:\tlearn: 0.2676806\ttest: 0.2670409\tbest: 0.2670409 (1999)\ttotal: 4m 27s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2670409445\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 4/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6718784\ttest: 0.6717159\tbest: 0.6717159 (0)\ttotal: 131ms\tremaining: 4m 21s\n",
            "1999:\tlearn: 0.2678646\ttest: 0.2660403\tbest: 0.2660403 (1999)\ttotal: 4m 29s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2660403102\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 5/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6718150\ttest: 0.6718208\tbest: 0.6718208 (0)\ttotal: 129ms\tremaining: 4m 18s\n",
            "1999:\tlearn: 0.2674861\ttest: 0.2678695\tbest: 0.2678695 (1999)\ttotal: 4m 27s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.267869454\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 6/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6718295\ttest: 0.6717608\tbest: 0.6717608 (0)\ttotal: 143ms\tremaining: 4m 46s\n",
            "1999:\tlearn: 0.2675984\ttest: 0.2677367\tbest: 0.2677367 (1999)\ttotal: 4m 33s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2677366819\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 7/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6718169\ttest: 0.6718397\tbest: 0.6718397 (0)\ttotal: 150ms\tremaining: 5m\n",
            "1999:\tlearn: 0.2675738\ttest: 0.2674891\tbest: 0.2674891 (1998)\ttotal: 4m 30s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2674891385\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 1/7 - LGBMClassifier\n",
            "FOLD 2/7 - LGBMClassifier\n",
            "FOLD 3/7 - LGBMClassifier\n",
            "FOLD 4/7 - LGBMClassifier\n",
            "FOLD 5/7 - LGBMClassifier\n",
            "FOLD 6/7 - LGBMClassifier\n",
            "FOLD 7/7 - LGBMClassifier\n",
            "FOLD 1/7 - HistGradientBoostingClassifier\n",
            "FOLD 2/7 - HistGradientBoostingClassifier\n",
            "FOLD 3/7 - HistGradientBoostingClassifier\n",
            "FOLD 4/7 - HistGradientBoostingClassifier\n",
            "FOLD 5/7 - HistGradientBoostingClassifier\n",
            "FOLD 6/7 - HistGradientBoostingClassifier\n",
            "FOLD 7/7 - HistGradientBoostingClassifier\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955425\n",
            "XGBClassifier CV AUC mean: 0.955429, std: +-0.00038\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955526\n",
            "CatBoostClassifier CV AUC mean: 0.955530, std: +-0.00036\n",
            "\n",
            "LGBMClassifier OOF AUC: 0.954946\n",
            "LGBMClassifier CV AUC mean: 0.954950, std: +-0.00031\n",
            "\n",
            "HistGradientBoostingClassifier OOF AUC: 0.955289\n",
            "HistGradientBoostingClassifier CV AUC mean: 0.955294, std: +-0.00032\n",
            "\n",
            "Stack (LR meta, 4 models) OOF AUC: 0.955536\n",
            "FOLD 1/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90555\n",
            "[1894]\tvalidation_0-auc:0.95679\n",
            "FOLD 2/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90425\n",
            "[1999]\tvalidation_0-auc:0.95577\n",
            "FOLD 3/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90307\n",
            "[1791]\tvalidation_0-auc:0.95515\n",
            "FOLD 4/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90280\n",
            "[1999]\tvalidation_0-auc:0.95503\n",
            "FOLD 5/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90249\n",
            "[1891]\tvalidation_0-auc:0.95532\n",
            "FOLD 6/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90154\n",
            "[1813]\tvalidation_0-auc:0.95489\n",
            "FOLD 7/7 - XGBClassifier\n",
            "[0]\tvalidation_0-auc:0.90298\n",
            "[1641]\tvalidation_0-auc:0.95514\n",
            "FOLD 1/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6720995\ttest: 0.6718583\tbest: 0.6718583 (0)\ttotal: 140ms\tremaining: 4m 39s\n",
            "1999:\tlearn: 0.2680749\ttest: 0.2637373\tbest: 0.2637373 (1999)\ttotal: 4m 33s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2637372584\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 2/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6720029\ttest: 0.6719700\tbest: 0.6719700 (0)\ttotal: 159ms\tremaining: 5m 16s\n",
            "1999:\tlearn: 0.2677703\ttest: 0.2660610\tbest: 0.2660610 (1998)\ttotal: 4m 37s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2660609832\n",
            "bestIteration = 1998\n",
            "\n",
            "Shrink model to first 1999 iterations.\n",
            "FOLD 3/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6720094\ttest: 0.6720042\tbest: 0.6720042 (0)\ttotal: 158ms\tremaining: 5m 15s\n",
            "1999:\tlearn: 0.2673371\ttest: 0.2683766\tbest: 0.2683766 (1999)\ttotal: 4m 34s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2683765529\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 4/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6720430\ttest: 0.6720411\tbest: 0.6720411 (0)\ttotal: 155ms\tremaining: 5m 9s\n",
            "1999:\tlearn: 0.2672986\ttest: 0.2687761\tbest: 0.2687761 (1999)\ttotal: 4m 37s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2687761463\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 5/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6719902\ttest: 0.6719799\tbest: 0.6719799 (0)\ttotal: 172ms\tremaining: 5m 44s\n",
            "1999:\tlearn: 0.2674760\ttest: 0.2677809\tbest: 0.2677809 (1999)\ttotal: 4m 35s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2677808881\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 6/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6719580\ttest: 0.6720882\tbest: 0.6720882 (0)\ttotal: 156ms\tremaining: 5m 11s\n",
            "1999:\tlearn: 0.2672658\ttest: 0.2689781\tbest: 0.2689775 (1996)\ttotal: 4m 39s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2689775141\n",
            "bestIteration = 1996\n",
            "\n",
            "Shrink model to first 1997 iterations.\n",
            "FOLD 7/7 - CatBoostClassifier\n",
            "0:\tlearn: 0.6720243\ttest: 0.6719381\tbest: 0.6719381 (0)\ttotal: 146ms\tremaining: 4m 51s\n",
            "1999:\tlearn: 0.2673119\ttest: 0.2681105\tbest: 0.2681105 (1999)\ttotal: 4m 33s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.2681105243\n",
            "bestIteration = 1999\n",
            "\n",
            "FOLD 1/7 - LGBMClassifier\n",
            "FOLD 2/7 - LGBMClassifier\n",
            "FOLD 3/7 - LGBMClassifier\n",
            "FOLD 4/7 - LGBMClassifier\n",
            "FOLD 5/7 - LGBMClassifier\n",
            "FOLD 6/7 - LGBMClassifier\n",
            "FOLD 7/7 - LGBMClassifier\n",
            "FOLD 1/7 - HistGradientBoostingClassifier\n",
            "FOLD 2/7 - HistGradientBoostingClassifier\n",
            "FOLD 3/7 - HistGradientBoostingClassifier\n",
            "FOLD 4/7 - HistGradientBoostingClassifier\n",
            "FOLD 5/7 - HistGradientBoostingClassifier\n",
            "FOLD 6/7 - HistGradientBoostingClassifier\n",
            "FOLD 7/7 - HistGradientBoostingClassifier\n",
            "\n",
            "XGBClassifier OOF AUC: 0.955447\n",
            "XGBClassifier CV AUC mean: 0.955445, std: +-0.00061\n",
            "\n",
            "CatBoostClassifier OOF AUC: 0.955548\n",
            "CatBoostClassifier CV AUC mean: 0.955546, std: +-0.00059\n",
            "\n",
            "LGBMClassifier OOF AUC: 0.954956\n",
            "LGBMClassifier CV AUC mean: 0.954955, std: +-0.00062\n",
            "\n",
            "HistGradientBoostingClassifier OOF AUC: 0.955276\n",
            "HistGradientBoostingClassifier CV AUC mean: 0.955276, std: +-0.00062\n",
            "\n",
            "Stack (LR meta, 4 models) OOF AUC: 0.955551\n",
            "Submission: 4-model stack, 3-seed avg. test_proba shape: (270000,)\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import inspect\n",
        "\n",
        "SEED = 42\n",
        "NSPLITS = 7\n",
        "SEEDS = [42, 420, 69420] \n",
        "USE_LR_STACK = False\n",
        "DROP_BP_MAX_HR = False\n",
        "\n",
        "\n",
        "path = DATA_DIR\n",
        "dfs = []\n",
        "for fl in (\"train.csv\", \"test.csv\"):\n",
        "    df = pd.read_csv(path / fl, index_col=0)\n",
        "    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns.tolist()]\n",
        "    dfs.append(df)\n",
        "train, test = dfs\n",
        "\n",
        "ystr = train.columns[-1]\n",
        "base_features = [c for c in train.columns if c != ystr]\n",
        "\n",
        "cols2comb = [\n",
        "    \"exercise_angina\", \"thallium\", \"chest_pain_type\",\n",
        "    \"slope_of_st\", \"sex\", \"st_depression\", \"number_of_vessels_fluro\",\n",
        "    \"ekg_results\", \"fbs_over_120\",\n",
        "]\n",
        "\n",
        "statmetrics = [\"mean\", \"count\"]\n",
        "\n",
        "X = train.drop(columns=ystr)\n",
        "y = (train[ystr] == \"Presence\").astype(int)\n",
        "\n",
        "X_test = test.copy()\n",
        "\n",
        "orig_path = DATA_DIR.parent / \"original-data\" / \"Heart_Disease_Prediction.csv\"\n",
        "orig_df = pd.read_csv(orig_path)\n",
        "orig_df.columns = [c.strip().lower().replace(\" \", \"_\") for c in orig_df.columns]\n",
        "orig_ystr = orig_df.columns[-1]\n",
        "orig_X = orig_df.drop(columns=orig_ystr)\n",
        "orig_y = (orig_df[orig_ystr] == \"Presence\").astype(int)\n",
        "\n",
        "common_cols = sorted(set(orig_X.columns) & set(X.columns))\n",
        "print(f\"Teacher model using {len(common_cols)} shared columns from original dataset\")\n",
        "\n",
        "teacher = cb.CatBoostClassifier(\n",
        "    iterations=400,\n",
        "    depth=4,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.9,\n",
        "    colsample_bylevel=0.9,\n",
        "    random_seed=SEED,\n",
        "    verbose=0,\n",
        ")\n",
        "teacher.fit(orig_X[common_cols], orig_y)\n",
        "\n",
        "X[\"teacher_pred\"] = teacher.predict_proba(X[common_cols])[:, 1]\n",
        "X_test[\"teacher_pred\"] = teacher.predict_proba(X_test[common_cols])[:, 1]\n",
        "\n",
        "adv_X = pd.concat([X, X_test], axis=0).reset_index(drop=True)\n",
        "adv_y = np.concatenate([\n",
        "    np.zeros(len(X), dtype=int),\n",
        "    np.ones(len(X_test), dtype=int),\n",
        "])\n",
        "adv_skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "oof_adv = np.zeros(len(adv_y), dtype=float)\n",
        "for tr_adv, val_adv in adv_skf.split(adv_X, adv_y):\n",
        "    adv_clf = lgb.LGBMClassifier(\n",
        "        objective=\"binary\",\n",
        "        metric=\"auc\",\n",
        "        learning_rate=0.05,\n",
        "        n_estimators=400,\n",
        "        num_leaves=31,\n",
        "        feature_fraction=0.9,\n",
        "        bagging_fraction=0.9,\n",
        "        bagging_freq=1,\n",
        "        min_data_in_leaf=30,\n",
        "        random_state=SEED,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    adv_clf.fit(adv_X.iloc[tr_adv], adv_y[tr_adv])\n",
        "    oof_adv[val_adv] = adv_clf.predict_proba(adv_X.iloc[val_adv])[:, 1]\n",
        "\n",
        "auc_adv = roc_auc_score(adv_y, oof_adv)\n",
        "print(f\"Adversarial AUC (train vs test): {auc_adv:.5f}\")\n",
        "\n",
        "p_test_train = oof_adv[: len(X)]\n",
        "eps = 1e-3\n",
        "w_train = p_test_train / (1.0 - p_test_train + eps)\n",
        "w_train = w_train / w_train.mean()\n",
        "print(\n",
        "    f\"Sample weights (train-like vs test-like) -> min={w_train.min():.3f}, max={w_train.max():.3f}, mean={w_train.mean():.3f}\"\n",
        ")\n",
        "\n",
        "\n",
        "def get_cat_feature_indices(X_):\n",
        "    return [i for i, c in enumerate(X_.columns) if c.startswith(\"CAT_\")]\n",
        "\n",
        "\n",
        "def fe_foldwise(X_tr, X_val, y_tr):\n",
        "    X_tr = X_tr.copy()\n",
        "    X_val = X_val.copy()\n",
        "\n",
        "    temp = pd.concat([X_tr, y_tr], axis=1)\n",
        "\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"age>55\"] = (df[\"age\"] > 55).astype(int)\n",
        "        for col in df.columns:\n",
        "            if col == \"teacher_pred\":\n",
        "                continue\n",
        "            colname = f\"CAT_{col}\"\n",
        "            df[colname] = df[col].astype(str).astype(\"category\")\n",
        "\n",
        "    for df in [X_tr, X_val]:\n",
        "        df[\"chest_pain_type_bin\"] = (df[\"chest_pain_type\"] >= 3).astype(int)\n",
        "        df[\"st_depression_bin\"] = (df[\"st_depression\"] >= 2).astype(int)\n",
        "        df[\"number_of_vessels_fluro_bin\"] = (df[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "        df[\"hr_age\"] = df[\"max_hr\"] * df[\"age\"]\n",
        "        df[\"bp_age\"] = df[\"bp\"] * df[\"age\"]\n",
        "        df[\"st_slope\"] = df[\"st_depression\"] * df[\"slope_of_st\"]\n",
        "        df[\"chol_exercise\"] = df[\"cholesterol\"] * df[\"exercise_angina\"]\n",
        "        pred_max = (220 - df[\"age\"]).clip(lower=10)\n",
        "        df[\"max_hr_pct_pred\"] = df[\"max_hr\"] / pred_max\n",
        "        df[\"risk_sum\"] = df[\"number_of_vessels_fluro\"] + df[\"thallium\"] + df[\"exercise_angina\"]\n",
        "        df[\"vessels_thallium\"] = df[\"number_of_vessels_fluro\"] * df[\"thallium\"]\n",
        "        df[\"age_chol\"] = df[\"age\"] * df[\"cholesterol\"]\n",
        "        df[\"risk_age\"] = df[\"risk_sum\"] * df[\"age\"]\n",
        "        df[\"teacher_pred_sq\"] = df[\"teacher_pred\"] ** 2\n",
        "\n",
        "    global_mean = float(y_tr.mean())\n",
        "    m_smooth = 10\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            cname = f\"target_{bf}_{s}\"\n",
        "            X_tr[cname] = X_tr[bf].map(stats[s])\n",
        "            X_val[cname] = X_val[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_tr[f\"target_{bf}_smooth\"] = X_tr[bf].map(smoothed).fillna(global_mean)\n",
        "        X_val[f\"target_{bf}_smooth\"] = X_val[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_tr[c2].max(), X_val[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_tr[cname] = (\n",
        "                (X_tr[c1] + 1 + (X_tr[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "            X_val[cname] = (\n",
        "                (X_val[c1] + 1 + (X_val[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    if DROP_BP_MAX_HR:\n",
        "        X_tr = X_tr.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "        X_val = X_val.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "    return X_tr, X_val\n",
        "\n",
        "\n",
        "def fe_test(X_test_, X_train_, y_train_):\n",
        "    X_test_ = X_test_.copy()\n",
        "    temp = pd.concat([X_train_, y_train_], axis=1)\n",
        "\n",
        "    X_test_[\"age>55\"] = (X_test_[\"age\"] > 55).astype(int)\n",
        "    for col in X_test_.columns:\n",
        "        if col == \"teacher_pred\":\n",
        "            continue\n",
        "        colname = f\"CAT_{col}\"\n",
        "        X_test_[colname] = X_test_[col].astype(str).astype(\"category\")\n",
        "\n",
        "    X_test_[\"chest_pain_type_bin\"] = (X_test_[\"chest_pain_type\"] >= 3).astype(int)\n",
        "    X_test_[\"st_depression_bin\"] = (X_test_[\"st_depression\"] >= 2).astype(int)\n",
        "    X_test_[\"number_of_vessels_fluro_bin\"] = (X_test_[\"number_of_vessels_fluro\"] >= 2).astype(int)\n",
        "    X_test_[\"hr_age\"] = X_test_[\"max_hr\"] * X_test_[\"age\"]\n",
        "    X_test_[\"bp_age\"] = X_test_[\"bp\"] * X_test_[\"age\"]\n",
        "    X_test_[\"st_slope\"] = X_test_[\"st_depression\"] * X_test_[\"slope_of_st\"]\n",
        "    X_test_[\"chol_exercise\"] = X_test_[\"cholesterol\"] * X_test_[\"exercise_angina\"]\n",
        "    pred_max = (220 - X_test_[\"age\"]).clip(lower=10)\n",
        "    X_test_[\"max_hr_pct_pred\"] = X_test_[\"max_hr\"] / pred_max\n",
        "    X_test_[\"risk_sum\"] = X_test_[\"number_of_vessels_fluro\"] + X_test_[\"thallium\"] + X_test_[\"exercise_angina\"]\n",
        "    X_test_[\"vessels_thallium\"] = X_test_[\"number_of_vessels_fluro\"] * X_test_[\"thallium\"]\n",
        "    X_test_[\"age_chol\"] = X_test_[\"age\"] * X_test_[\"cholesterol\"]\n",
        "    X_test_[\"risk_age\"] = X_test_[\"risk_sum\"] * X_test_[\"age\"]\n",
        "    X_test_[\"teacher_pred_sq\"] = X_test_[\"teacher_pred\"] ** 2\n",
        "\n",
        "    global_mean = float(y_train_.mean())\n",
        "    m_smooth = 10\n",
        "    for bf in base_features:\n",
        "        stats = temp.groupby(bf)[ystr].agg(statmetrics)\n",
        "        for s in statmetrics:\n",
        "            X_test_[f\"target_{bf}_{s}\"] = X_test_[bf].map(stats[s])\n",
        "        smoothed = (stats[\"count\"] * stats[\"mean\"] + m_smooth * global_mean) / (stats[\"count\"] + m_smooth)\n",
        "        X_test_[f\"target_{bf}_smooth\"] = X_test_[bf].map(smoothed).fillna(global_mean)\n",
        "\n",
        "    for i, c1 in enumerate(cols2comb[:-1]):\n",
        "        for c2 in cols2comb[i + 1 :]:\n",
        "            m2 = max(X_train_[c2].max(), X_test_[c2].max()) + 1\n",
        "            cname = f\"{c1}_{c2}\"\n",
        "            X_test_[cname] = (\n",
        "                (X_test_[c1] + 1 + (X_test_[c2] + 1) / (m2 + 1)) * (m2 + 1)\n",
        "            ).astype(\"int16\")\n",
        "\n",
        "    if DROP_BP_MAX_HR:\n",
        "        X_test_ = X_test_.drop(columns=[\"bp\", \"max_hr\"], errors=\"ignore\")\n",
        "    return X_test_\n",
        "\n",
        "\n",
        "xgboost_params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"auc\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"max_depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"colsample_bytree\": 0.9,\n",
        "    \"n_estimators\": 2000,\n",
        "    \"min_child_weight\": 10,\n",
        "    \"gamma\": 1,\n",
        "    \"reg_lambda\": 0.01,\n",
        "    \"reg_alpha\": 1.5,\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"n_jobs\": -1,\n",
        "    \"random_state\": SEED,\n",
        "    \"early_stopping_rounds\": 100,\n",
        "    \"enable_categorical\": True,\n",
        "}\n",
        "\n",
        "catboost_params = {\n",
        "    \"loss_function\": \"Logloss\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"depth\": 2,\n",
        "    \"subsample\": 0.9,\n",
        "    \"iterations\": 2000,\n",
        "    \"min_data_in_leaf\": 1,\n",
        "    \"l2_leaf_reg\": 1.002,\n",
        "    \"thread_count\": -1,\n",
        "    \"random_seed\": SEED,\n",
        "    \"early_stopping_rounds\": 100,\n",
        "    \"bootstrap_type\": \"Bernoulli\",\n",
        "}\n",
        "\n",
        "lgbm_params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"metric\": \"auc\",\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"n_estimators\": 1200,\n",
        "    \"num_leaves\": 20,\n",
        "    \"feature_fraction\": 0.9,\n",
        "    \"bagging_fraction\": 0.9,\n",
        "    \"bagging_freq\": 1,\n",
        "    \"min_data_in_leaf\": 30,\n",
        "    \"random_state\": SEED,\n",
        "    \"n_jobs\": -1,\n",
        "    \"verbose\": -1,\n",
        "}\n",
        "hgb_params = {\n",
        "    \"max_iter\": 2000,\n",
        "    \"learning_rate\": 0.02,\n",
        "    \"max_depth\": 6,\n",
        "    \"early_stopping\": True,\n",
        "    \"n_iter_no_change\": 80,\n",
        "    \"validation_fraction\": 0.1,\n",
        "    \"random_state\": SEED,\n",
        "}\n",
        "models = {\n",
        "    XGBClassifier: xgboost_params,\n",
        "    CatBoostClassifier: catboost_params,\n",
        "    LGBMClassifier: lgbm_params,\n",
        "    HistGradientBoostingClassifier: hgb_params,\n",
        "}\n",
        "\n",
        "oof_list, test_proba_list = [], []\n",
        "for SEED in SEEDS:\n",
        "    teacher = cb.CatBoostClassifier(\n",
        "        iterations=400, depth=4, learning_rate=0.05, subsample=0.9,\n",
        "        colsample_bylevel=0.9, random_seed=SEED, verbose=0,\n",
        "    )\n",
        "    teacher.fit(orig_X[common_cols], orig_y)\n",
        "    X[\"teacher_pred\"] = teacher.predict_proba(X[common_cols])[:, 1]\n",
        "    X_test[\"teacher_pred\"] = teacher.predict_proba(X_test[common_cols])[:, 1]\n",
        "    adv_skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "    oof_adv = np.zeros(len(adv_y), dtype=float)\n",
        "    for tr_adv, val_adv in adv_skf.split(adv_X, adv_y):\n",
        "        adv_clf = lgb.LGBMClassifier(\n",
        "            objective=\"binary\", metric=\"auc\", learning_rate=0.05, n_estimators=400,\n",
        "            num_leaves=31, feature_fraction=0.9, bagging_fraction=0.9, bagging_freq=1,\n",
        "            min_data_in_leaf=30, random_state=SEED, n_jobs=-1,\n",
        "        )\n",
        "        adv_clf.fit(adv_X.iloc[tr_adv], adv_y[tr_adv])\n",
        "        oof_adv[val_adv] = adv_clf.predict_proba(adv_X.iloc[val_adv])[:, 1]\n",
        "    p_test_train = oof_adv[: len(X)]\n",
        "    w_train = p_test_train / (1.0 - p_test_train + 1e-3)\n",
        "    w_train = w_train / w_train.mean()\n",
        "    w_train = np.clip(w_train, 0.3, 3.0)\n",
        "    w_train = w_train / w_train.mean()\n",
        "    xgboost_params = {**xgboost_params, \"random_state\": SEED}\n",
        "    catboost_params = {**catboost_params, \"random_seed\": SEED}\n",
        "    lgbm_params = {**lgbm_params, \"random_state\": SEED}\n",
        "    hgb_params_s = {**hgb_params, \"random_state\": SEED}\n",
        "    models_run = {\n",
        "        XGBClassifier: xgboost_params,\n",
        "        CatBoostClassifier: catboost_params,\n",
        "        LGBMClassifier: lgbm_params,\n",
        "        HistGradientBoostingClassifier: hgb_params_s,\n",
        "    }\n",
        "    kf = StratifiedKFold(n_splits=NSPLITS, shuffle=True, random_state=SEED)\n",
        "    oof_train_model = {}\n",
        "    oof_test_model = {}\n",
        "    cv_auc_model = defaultdict(list)\n",
        "    for modelClass, param in models_run.items():\n",
        "        model_name = modelClass.__name__\n",
        "        oof_train = np.zeros(len(X))\n",
        "        oof_test = np.zeros(len(X_test))\n",
        "\n",
        "        for fold, (tr, val) in enumerate(kf.split(X, y)):\n",
        "            print(f\"FOLD {fold + 1}/{NSPLITS} - {model_name}\")\n",
        "\n",
        "            X_tr_raw, X_val_raw = X.iloc[tr], X.iloc[val]\n",
        "            y_tr, y_val = y.iloc[tr], y.iloc[val]\n",
        "\n",
        "            X_tr, X_val = fe_foldwise(X_tr_raw, X_val_raw, y_tr)\n",
        "\n",
        "            model = modelClass(**param)\n",
        "            if model_name == \"HistGradientBoostingClassifier\":\n",
        "                X_tr_fit = X_tr.select_dtypes(include=[np.number])\n",
        "                X_val_fit = X_val.select_dtypes(include=[np.number])\n",
        "                model.fit(X_tr_fit, y_tr, sample_weight=w_train[tr])\n",
        "                oof_train[val] = model.predict_proba(X_val_fit)[:, 1]\n",
        "                X_test_fe = fe_test(X_test, X_tr_raw, y_tr)\n",
        "                X_test_fit = X_test_fe.select_dtypes(include=[np.number])\n",
        "                oof_test += model.predict_proba(X_test_fit)[:, 1] / NSPLITS\n",
        "            else:\n",
        "                fit_kwargs = {\n",
        "                    \"X\": X_tr,\n",
        "                    \"y\": y_tr,\n",
        "                    \"eval_set\": [(X_val, y_val)],\n",
        "                    \"sample_weight\": w_train[tr],\n",
        "                }\n",
        "                if model_name != \"LGBMClassifier\":\n",
        "                    fit_kwargs[\"verbose\"] = 2000\n",
        "                if \"cat_features\" in inspect.signature(model.fit).parameters:\n",
        "                    cat_features = get_cat_feature_indices(X_tr)\n",
        "                    fit_kwargs[\"cat_features\"] = cat_features\n",
        "                model.fit(**fit_kwargs)\n",
        "                oof_train[val] = model.predict_proba(X_val)[:, 1]\n",
        "                X_test_fe = fe_test(X_test, X_tr_raw, y_tr)\n",
        "                oof_test += model.predict_proba(X_test_fe)[:, 1] / NSPLITS\n",
        "            cv_auc_model[model_name].append(roc_auc_score(y[val], oof_train[val]))\n",
        "\n",
        "        oof_train_model[model_name] = oof_train\n",
        "        oof_test_model[model_name] = oof_test\n",
        "\n",
        "    for modelClass in models_run.keys():\n",
        "        model_name = modelClass.__name__\n",
        "        print(f\"\\n{model_name} OOF AUC: {roc_auc_score(y, oof_train_model[model_name]):.6f}\")\n",
        "        print(\n",
        "            f\"{model_name} CV AUC mean: {np.mean(cv_auc_model[model_name]):.6f}, std: +-{np.std(cv_auc_model[model_name]):.5f}\"\n",
        "        )\n",
        "\n",
        "    X_oof_tr = pd.DataFrame.from_dict(oof_train_model)\n",
        "    X_oof_test = pd.DataFrame.from_dict(oof_test_model)\n",
        "    cols = list(X_oof_tr.columns)\n",
        "    use_meta = USE_LR_STACK or len(cols) >= 3\n",
        "    if use_meta:\n",
        "        meta = LogisticRegression(max_iter=500, random_state=SEED, class_weight=\"balanced\")\n",
        "        meta.fit(X_oof_tr, y, sample_weight=w_train)\n",
        "        oof_tr_final = pd.Series(meta.predict_proba(X_oof_tr)[:, 1], index=X_oof_tr.index)\n",
        "        oof_test_final = pd.Series(meta.predict_proba(X_oof_test)[:, 1], index=X_oof_test.index)\n",
        "        stack_auc = roc_auc_score(y, oof_tr_final)\n",
        "        print(f\"\\nStack (LR meta, {len(cols)} models) OOF AUC: {stack_auc:.6f}\")\n",
        "        oof_list.append(oof_tr_final.values)\n",
        "        test_proba_list.append(oof_test_final.values)\n",
        "    else:\n",
        "        a, b = X_oof_tr[cols[0]], X_oof_tr[cols[1]]\n",
        "        best_w, best_auc = 0.5, 0.0\n",
        "        for w in np.linspace(0, 1, 21):\n",
        "            blend = w * a + (1 - w) * b\n",
        "            auc = roc_auc_score(y, blend)\n",
        "            if auc > best_auc:\n",
        "                best_auc, best_w = auc, w\n",
        "        oof_tr_final = best_w * X_oof_tr[cols[0]] + (1 - best_w) * X_oof_tr[cols[1]]\n",
        "        oof_test_final = best_w * X_oof_test[cols[0]] + (1 - best_w) * X_oof_test[cols[1]]\n",
        "        print(f\"\\nBlend weight {cols[0]}={best_w:.2f}, {cols[1]}={1-best_w:.2f} -> OOF AUC: {best_auc:.6f}\")\n",
        "        oof_list.append(oof_tr_final.values)\n",
        "        test_proba_list.append(oof_test_final.values)\n",
        "\n",
        "oof = np.mean(oof_list, axis=0)\n",
        "test_proba = np.mean(test_proba_list, axis=0)\n",
        "N_STACK_MODELS = len(oof_train_model)\n",
        "print(f\"Submission: {N_STACK_MODELS}-model stack, {len(SEEDS)}-seed avg. test_proba shape: {test_proba.shape}\")\n",
        "\n",
        "test[\"id\"] = test.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix (OOF, threshold=0.5)\n",
            "Rows: true, Cols: predicted |  Absence   Presence\n",
            "[[311912  35634]\n",
            " [ 34355 248099]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred = (oof >= 0.5).astype(int)\n",
        "cm = confusion_matrix(y, y_pred)\n",
        "print(\"Confusion matrix (OOF, threshold=0.5)\")\n",
        "print(\"Rows: true, Cols: predicted |  Absence   Presence\")\n",
        "print(cm)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "plt.colorbar()\n",
        "plt.xticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.yticks([0, 1], [\"Absence\", \"Presence\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
        "plt.title(\"Confusion matrix (OOF)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission saved (4-model blend): submission.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Heart Disease</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>630000</th>\n",
              "      <td>630000</td>\n",
              "      <td>0.959315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630001</th>\n",
              "      <td>630001</td>\n",
              "      <td>0.048322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630002</th>\n",
              "      <td>630002</td>\n",
              "      <td>0.967382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630003</th>\n",
              "      <td>630003</td>\n",
              "      <td>0.046923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630004</th>\n",
              "      <td>630004</td>\n",
              "      <td>0.152322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630005</th>\n",
              "      <td>630005</td>\n",
              "      <td>0.966494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630006</th>\n",
              "      <td>630006</td>\n",
              "      <td>0.046428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630007</th>\n",
              "      <td>630007</td>\n",
              "      <td>0.608843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630008</th>\n",
              "      <td>630008</td>\n",
              "      <td>0.968039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630009</th>\n",
              "      <td>630009</td>\n",
              "      <td>0.049230</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  Heart Disease\n",
              "id                           \n",
              "630000  630000       0.959315\n",
              "630001  630001       0.048322\n",
              "630002  630002       0.967382\n",
              "630003  630003       0.046923\n",
              "630004  630004       0.152322\n",
              "630005  630005       0.966494\n",
              "630006  630006       0.046428\n",
              "630007  630007       0.608843\n",
              "630008  630008       0.968039\n",
              "630009  630009       0.049230"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub = pd.DataFrame({\"id\": test[\"id\"], \"Heart Disease\": test_proba})\n",
        "sub.to_csv(OUTPUT_DIR / \"submission.csv\", index=False)\n",
        "print(f\"Submission saved ({N_STACK_MODELS}-model blend): {OUTPUT_DIR / 'submission.csv'}\")\n",
        "sub.head(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
